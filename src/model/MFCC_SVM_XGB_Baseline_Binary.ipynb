{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MFCC_SVM_XGB_Baseline_Binary.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhVWp_3AHD9p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "34ed48eb-5223-44ae-f6ed-9fcc584a88c4"
      },
      "source": [
        "# Import all required Files\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import wave\n",
        "import sys\n",
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import xgboost as xgb\n",
        "from  sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import GridSearchCV \n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import sklearn.naive_bayes as nb\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import BaggingClassifier,GradientBoostingClassifier\n",
        "from sklearn.neighbors import kd_tree\n",
        "import seaborn as sn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.kd_tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7Ue0YVXIMNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load per cycle data frame\n",
        "import pickle\n",
        "folder = \"/content/drive/My Drive/Respiratory_Sound_Database/Respiratory_Sound_Database/\" \n",
        "filename = folder + 'w_c_dataset.pickle'\n",
        "infile = open(filename,'rb')\n",
        "[sound,sr,lengths,times,labels] = pickle.load(infile)\n",
        "infile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miT8fDk0JOsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# This fucntion splits sounds into cycles\n",
        "def split_sounds(sounds,times,labels):\n",
        "    s=[]\n",
        "    l=[]\n",
        "    for i,sound in enumerate(sounds):\n",
        "        for t,label in zip(times[i],labels[i]):\n",
        "            s.append(sound[int(t[0]):int(t[1])])\n",
        "            if label==0:\n",
        "                a=np.array([1,0,0,0])\n",
        "            if label==1:\n",
        "                a=np.array([0,1,0,0])\n",
        "            if label==2:\n",
        "                a=np.array([0,0,1,0])    \n",
        "            if label==3:\n",
        "                a=np.array([0,0,0,1])\n",
        "            l.append(a)\n",
        "    return s,l\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ6kqdXTIPlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract MFCC Features\n",
        "# Then take their mean and standard deviation and stack them up\n",
        "import librosa\n",
        "def extract_feature(cycle_number,X,sample_rate):\n",
        "    n_fft=int(sample_rate*0.025)\n",
        "    hop_length=int(sample_rate*0.01)\n",
        "    mfcc = librosa.feature.mfcc(y=X, sr=sample_rate,n_fft=n_fft,hop_length=hop_length,\n",
        "                                         n_mfcc=50)\n",
        "    mean_mfcc = np.mean(mfcc.T,axis=0)\n",
        "    std_mfcc = np.std(mfcc.T,axis=0)\n",
        "    return np.vstack((mean_mfcc,std_mfcc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOF-4qgkJWdb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[data,label]=split_sounds(sound,times,labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB7wazSlJgHn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f28b0a01-52c2-4bd8-a783-547d25ff5088"
      },
      "source": [
        "# Form the train data for SVM\n",
        "dataset = []\n",
        "for cycle_number,d in enumerate(data):\n",
        "    a = extract_feature(cycle_number+1,d,sr[0])\n",
        "    dataset.append(a)\n",
        "data=np.asarray(dataset)\n",
        "print(data.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6898, 2, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTqMQh2mIyjO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "32749de2-eee0-4793-bdb7-47f9c1d91153"
      },
      "source": [
        "# Form the labels\n",
        "data = data.reshape([6898,data.shape[1]*data.shape[2],])\n",
        "print(data.shape)\n",
        "\n",
        "label=np.asarray(label)\n",
        "a=np.zeros(label.shape[0])\n",
        "for i in range(label.shape[0]):\n",
        "    for j in range(label.shape[1]):\n",
        "        if label[i][j]==1:\n",
        "            a[i]=j\n",
        "\n",
        "# Form the labels for binary classification\n",
        "#bin_labels = []\n",
        "#for label in a:\n",
        "#    if label == 0:\n",
        "#        bin_labels.append(0)\n",
        "#    else:\n",
        "#        bin_labels.append(1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6898, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Bv6eeY0KK72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Standardize the data\n",
        "scaler=StandardScaler()\n",
        "x_train,x_test,y_train,y_test = sklearn.model_selection.train_test_split(data,a,test_size=0.3, random_state=42,stratify=a)\n",
        "scaler.fit(x_train)\n",
        "x_train=scaler.transform(x_train)\n",
        "x_test=scaler.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXNmcQ2AKWKp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "cb440683-be61-4e83-afb0-841316a2ee19"
      },
      "source": [
        "\n",
        "# Grid-Search to find the best fit SVM Model\n",
        "Cs = [2**(-2),2**(-1), 1,2**(1),2**(2),2**(3),2**(4),2**(5),2**(6),2**(7),2**(8),2**(9),2**(10)]\n",
        "gamma = [2**(-7),2**(-6),2**(-5),2**(-4),2**(-3),2**(-2),2**(-1),2**(0),2**(1),2**(2),2**(3)]\n",
        "\n",
        "\n",
        "param_grid = {'C': Cs,  \n",
        "                'gamma': gamma, \n",
        "                'kernel': ['rbf'],\n",
        "                'decision_function_shape':['ov'],\n",
        "                'class_weight': ['balanced']}  \n",
        "\n",
        "grid1 = GridSearchCV(SVC(), param_grid,cv=3,n_jobs=-1, verbose = 3) \n",
        "\n",
        "# fitting the model for grid search \n",
        "grid1.fit(x_train, y_train)\n",
        "\n",
        "# print best parameter after tuning \n",
        "print(\"Best Parameters after tuning:\")\n",
        "print(grid1.best_params_) \n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(\"Best selected Model: \") \n",
        "print(grid1.best_estimator_)\n",
        "\n",
        "grid_predictions = grid1.predict(x_test) \n",
        "\n",
        "# print classification report\n",
        "print(\"Classification Report: \") \n",
        "print(classification_report(y_test, grid_predictions))\n",
        "print(\"Classification Accuracy: \")\n",
        "print(accuracy_score(y_test,grid_predictions))\n",
        "\n",
        "print(\"Confusion Matrix is as Follows: \")\n",
        "print(sklearn.metrics.confusion_matrix(y_test,grid_predictions))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 143 candidates, totalling 429 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  5.3min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed: 12.2min\n",
            "[Parallel(n_jobs=-1)]: Done 429 out of 429 | elapsed: 18.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best Parameters after tuning:\n",
            "{'C': 8, 'class_weight': 'balanced', 'decision_function_shape': 'ov', 'gamma': 0.03125, 'kernel': 'rbf'}\n",
            "Best selected Model: \n",
            "SVC(C=8, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ov', degree=3, gamma=0.03125, kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n",
            "Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      0.84      0.82      1093\n",
            "         1.0       0.70      0.74      0.72       559\n",
            "         2.0       0.75      0.56      0.65       266\n",
            "         3.0       0.59      0.51      0.55       152\n",
            "\n",
            "    accuracy                           0.76      2070\n",
            "   macro avg       0.71      0.66      0.68      2070\n",
            "weighted avg       0.75      0.76      0.75      2070\n",
            "\n",
            "Classification Accuracy: \n",
            "0.755072463768116\n",
            "Confusion Matrix is as Follows: \n",
            "[[922 132  31   8]\n",
            " [120 414   2  23]\n",
            " [ 78  16 150  22]\n",
            " [ 32  27  16  77]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUTd6ampQZZ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3a2fd7ca-a900-420e-a948-a05c638fc4cd"
      },
      "source": [
        "# Running XgBoost\n",
        "import xgboost as xgb\n",
        "\n",
        "print('Training XGB Classifier from new features:')\n",
        "xgb_model = xgb.XGBClassifier(max_depth=40,num_class=2, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, objective='multi:softmax', eta=0.3, silent=0, subsample=0.8).fit(x_train, y_train)\n",
        "\n",
        "xgb_pred = xgb_model.predict(x_test)\n",
        "print(accuracy_score(y_test,xgb_pred))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training XGB Classifier from new features:\n",
            "0.721256038647343\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g125i8ebbYA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}