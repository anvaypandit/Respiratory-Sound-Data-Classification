{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Demographic_SVM_XGB_ANN.ipynb","provenance":[],"authorship_tag":"ABX9TyP05ZIkhkrLto80NtMmQxRS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"_mR3Sn-6-yq8","colab_type":"code","outputId":"1f219931-99af-4944-f4dc-83be3084ae50","executionInfo":{"status":"ok","timestamp":1588537593853,"user_tz":300,"elapsed":3211,"user":{"displayName":"Shu-Hao Yeh","photoUrl":"","userId":"02698211427086926082"}},"colab":{"base_uri":"https://localhost:8080/","height":222}},"source":["# Set up the mount of the google drive.\n","!pip install librosa"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.22.2.post1)\n","Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.2)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.8)\n","Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.18.3)\n","Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.48.0)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.12.0)\n","Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.14.1)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.4.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (46.1.3)\n","Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.31.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CZB43LbJEYXU","colab_type":"code","outputId":"7544e1a1-c78f-4539-e3a8-ba40a4d22705","executionInfo":{"status":"ok","timestamp":1588537613619,"user_tz":300,"elapsed":17418,"user":{"displayName":"Shu-Hao Yeh","photoUrl":"","userId":"02698211427086926082"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F1o2n8Y-EaDy","colab_type":"code","outputId":"63dc46cf-2dba-4587-a702-4e4b0cb79df5","executionInfo":{"status":"ok","timestamp":1588537621286,"user_tz":300,"elapsed":2861,"user":{"displayName":"Shu-Hao Yeh","photoUrl":"","userId":"02698211427086926082"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import sklearn\n","import pandas as pd\n","import wave\n","import sys\n","import os\n","import librosa\n","import librosa.display\n","import xgboost as xgb\n","from  sklearn.preprocessing import StandardScaler,MinMaxScaler\n","from sklearn.cluster import KMeans\n","from sklearn.model_selection import GridSearchCV \n","from sklearn.metrics import accuracy_score, f1_score, classification_report\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","import sklearn.naive_bayes as nb\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import BaggingClassifier,GradientBoostingClassifier\n","from sklearn.neighbors import kd_tree\n","import seaborn as sn\n","from sklearn.metrics import confusion_matrix\n","from collections import Counter\n","from sklearn.datasets import make_classification\n","from imblearn.over_sampling import SMOTE\n","from sklearn.model_selection import train_test_split"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n","/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.kd_tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n","  warnings.warn(message, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n","  \"(https://pypi.org/project/six/).\", FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n","  warnings.warn(message, FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qL6ZX08fEaZl","colab_type":"code","outputId":"b354fa76-8698-4e99-9ae8-d3928014311c","executionInfo":{"status":"ok","timestamp":1588537625819,"user_tz":300,"elapsed":1859,"user":{"displayName":"Shu-Hao Yeh","photoUrl":"","userId":"02698211427086926082"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n","from keras.utils import to_categorical\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","\n","from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, accuracy_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from datetime import datetime"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"PybNPfqjEdAZ","colab_type":"code","colab":{}},"source":["import pandas as pd\n","demographic = pd.read_csv('/content/drive/My Drive/CSCE 666/Project/respiratory-sound-database/select_patient_complete_COPD_info.csv', header=None)\n","demographic_data = demographic.values\n","patient_disease_labels = demographic_data[:, -1]\n","#demographic_data = demographic_data[0:, 1:-1] # Remove the id column (the first column)\n","select_patient_ids = list(demographic_data[:, 0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0myfit3yIEV1","colab_type":"code","outputId":"f841b5cb-35d8-44e8-bcfa-0410b9caa8c1","executionInfo":{"status":"ok","timestamp":1588537630879,"user_tz":300,"elapsed":587,"user":{"displayName":"Shu-Hao Yeh","photoUrl":"","userId":"02698211427086926082"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["print(len(demographic_data))\n","print(type(demographic_data))\n","print(demographic_data[0, :])\n","print(demographic_data.shape[1]  )\n","print(demographic_data[[1,3,4],:])\n","print(select_patient_ids)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["117\n","<class 'numpy.ndarray'>\n","[101.      3.      0.     19.386   0.   ]\n","5\n","[[102.      0.75    0.     18.39    0.   ]\n"," [104.     70.      0.     28.47    1.   ]\n"," [105.      7.      0.     17.558   0.   ]]\n","[101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 218.0, 219.0, 220.0, 221.0, 224.0, 225.0, 226.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8AHwBnwSOSEL","colab_type":"code","colab":{}},"source":["\"\"\"\n","# 8 disease classification\n","def updatelabel(labels): \n","    l=[]\n","    for label in labels:\n","      if label == 0:\n","        a = np.array([1, 0, 0, 0, 0, 0, 0, 0])\n","      elif label == 1:\n","        a = np.array([0, 1, 0, 0, 0, 0, 0, 0])\n","      elif label == 2:\n","        a = np.array([0, 0, 1, 0, 0, 0, 0, 0])\n","      elif label == 3:\n","        a = np.array([0, 0, 0, 1, 0, 0, 0, 0])  \n","      elif label == 4:\n","        a = np.array([0, 0, 0, 0, 1, 0, 0, 0])  \n","      elif label == 5:\n","        a = np.array([0, 0, 0, 0, 0, 1, 0, 0])\n","      elif label == 6:\n","        a = np.array([0, 0, 0, 0, 0, 0, 1, 0])\n","      else:\n","        a = np.array([0, 0, 0, 0, 0, 0, 0, 1])\n","      l.append(a)\n","    return l\n","  \"\"\"\n","# COPD vs. non-COPD\n","def updatelabel(labels):\n","    l=[]\n","    for label in labels:\n","      if label == 0:\n","        a = np.array([1, 0])\n","      if label == 1:\n","        a = np.array([0, 1]) \n","      l.append(a)\n","    return l"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KBI3OgaWPaIH","colab_type":"code","outputId":"668a2af4-d2e6-4d32-e642-f14162f5281d","executionInfo":{"status":"ok","timestamp":1588537636356,"user_tz":300,"elapsed":542,"user":{"displayName":"Shu-Hao Yeh","photoUrl":"","userId":"02698211427086926082"}},"colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["print(patient_disease_labels)\n","\n","new_patient_disease_labels = updatelabel(patient_disease_labels)\n","print(len(new_patient_disease_labels))\n","print(new_patient_disease_labels)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0.\n"," 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0.\n"," 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1.\n"," 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0.\n"," 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0.]\n","117\n","[array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([1, 0]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([1, 0]), array([0, 1]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([1, 0]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([0, 1]), array([1, 0]), array([0, 1]), array([0, 1]), array([1, 0]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([0, 1]), array([1, 0]), array([0, 1]), array([0, 1]), array([1, 0]), array([0, 1]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([1, 0]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0])]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ETAhOkL6SeW6","colab_type":"code","outputId":"869e102e-019f-41d8-b5eb-99eed0b60474","executionInfo":{"status":"ok","timestamp":1588537638348,"user_tz":300,"elapsed":424,"user":{"displayName":"Shu-Hao Yeh","photoUrl":"","userId":"02698211427086926082"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["print(demographic_data[0])\n","print(demographic_data[0, 1:-1])\n","print(len(demographic_data))\n","print(demographic_data[0, 0])\n","print(demographic_data[0, -1])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[101.      3.      0.     19.386   0.   ]\n","[ 3.     0.    19.386]\n","117\n","101.0\n","0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cCP6TprLSHNB","colab_type":"code","colab":{}},"source":["# Extract features\n","featset = demographic_data[0:, 1:-1] # Remove the id column (the first column)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dc93LhdzaCNV","colab_type":"code","outputId":"cb9d480b-db5e-4649-a434-3e781e7e119b","executionInfo":{"status":"ok","timestamp":1588537642261,"user_tz":300,"elapsed":201,"user":{"displayName":"Shu-Hao Yeh","photoUrl":"","userId":"02698211427086926082"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#print(featset[0])\n","print(len(featset))\n","print(len(featset[0]))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["117\n","3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fpG0lW0JU1cl","colab_type":"code","outputId":"c4db6a08-a4d0-4026-abed-2d02cba562b9","executionInfo":{"status":"ok","timestamp":1588537644411,"user_tz":300,"elapsed":424,"user":{"displayName":"Shu-Hao Yeh","photoUrl":"","userId":"02698211427086926082"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["new_patient_disease_labels = np.asarray(new_patient_disease_labels)\n","a = np.zeros(new_patient_disease_labels.shape[0])\n","for i in range(new_patient_disease_labels.shape[0]):\n","    for j in range(new_patient_disease_labels.shape[1]):\n","        if new_patient_disease_labels[i][j]==1:\n","            a[i]=j\n","\n","# COnvert to binary for the binary classification problem\n","bin_label =np.zeros(new_patient_disease_labels.shape[0])\n","for index,l in enumerate(a):\n","    if l == 0:\n","        bin_label[index] = l\n","    else:\n","        bin_label[index] = 1\n","\n","unique, counts = np.unique(bin_label, return_counts=True)\n","\n","print(np.asarray((unique, counts)).T)\n","\n","\n","# One-hot encode labels\n","le = LabelEncoder()\n","i_labels = le.fit_transform(bin_label)\n","oh_labels = to_categorical(i_labels)\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[[ 0. 55.]\n"," [ 1. 62.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1JnFvQSyU85z","colab_type":"code","colab":{}},"source":["scaler=StandardScaler()\n","x_train,x_test,y_train,y_test = sklearn.model_selection.train_test_split(featset, i_labels,test_size=0.3, random_state=42,stratify=i_labels)\n","scaler.fit(x_train)\n","x_train=scaler.transform(x_train)\n","x_test=scaler.transform(x_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OSH7GCC_U_D3","colab_type":"code","outputId":"727976fa-147c-48d5-8dc0-14b6c258af60","executionInfo":{"status":"ok","timestamp":1588537650235,"user_tz":300,"elapsed":1799,"user":{"displayName":"Shu-Hao Yeh","photoUrl":"","userId":"02698211427086926082"}},"colab":{"base_uri":"https://localhost:8080/","height":376}},"source":["# SVM\n","Cs = [2**(-2),2**(-1), 1,2**(1),2**(2),2**(3),2**(4),2**(5),2**(6),2**(7),2**(8),2**(9),2**(10)]\n","gamma = [2**(-7),2**(-6),2**(-5),2**(-4),2**(-3),2**(-2),2**(-1),2**(0),2**(1),2**(2),2**(3)]\n","\n","\n","param_grid = {'C': Cs,  \n","                'gamma': gamma, \n","                'kernel': ['rbf'],\n","                'decision_function_shape':['ov'],\n","                'class_weight': ['balanced']}  \n","grid1 = GridSearchCV(SVC(), param_grid,cv=3,n_jobs=-1, verbose = 3) \n","\n","# fitting the model for grid search \n","grid1.fit(x_train, y_train)\n","\n","# print best parameter after tuning \n","print(grid1.best_params_) \n","# print how our model looks after hyper-parameter tuning \n","print(grid1.best_estimator_)\n","\n","grid_predictions = grid1.predict(x_test) \n","\n","# print classification report \n","print(classification_report(y_test, grid_predictions))\n","print(accuracy_score(y_test,grid_predictions))\n","\n","print(sklearn.metrics.confusion_matrix(y_test,grid_predictions))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Fitting 3 folds for each of 143 candidates, totalling 429 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done 102 tasks      | elapsed:    1.0s\n"],"name":"stderr"},{"output_type":"stream","text":["{'C': 0.25, 'class_weight': 'balanced', 'decision_function_shape': 'ov', 'gamma': 0.03125, 'kernel': 'rbf'}\n","SVC(C=0.25, break_ties=False, cache_size=200, class_weight='balanced',\n","    coef0=0.0, decision_function_shape='ov', degree=3, gamma=0.03125,\n","    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n","    shrinking=True, tol=0.001, verbose=False)\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.76      0.87        17\n","           1       0.83      1.00      0.90        19\n","\n","    accuracy                           0.89        36\n","   macro avg       0.91      0.88      0.89        36\n","weighted avg       0.91      0.89      0.89        36\n","\n","0.8888888888888888\n","[[13  4]\n"," [ 0 19]]\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done 429 out of 429 | elapsed:    1.5s finished\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"k_tR4scTVD5D","colab_type":"code","outputId":"34f3506d-abaa-45c5-f899-12a9c3534d10","executionInfo":{"status":"ok","timestamp":1588537654652,"user_tz":300,"elapsed":1113,"user":{"displayName":"Shu-Hao Yeh","photoUrl":"","userId":"02698211427086926082"}},"colab":{"base_uri":"https://localhost:8080/","height":205}},"source":["# XgBoost\n","import xgboost as xgb\n","\n","print('Training XGB Classifier from new features:')\n","xgb_model = xgb.XGBClassifier(max_depth=3,num_class=2, n_estimators=15, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, objective='multi:softmax', eta=0.3, silent=0, subsample=0.8).fit(x_train, y_train)\n","\n","xgb_pred = xgb_model.predict(x_test)\n","# print classification report \n","print(classification_report(y_test, xgb_pred))\n","print(accuracy_score(y_test,xgb_pred))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Training XGB Classifier from new features:\n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.76      0.81        17\n","           1       0.81      0.89      0.85        19\n","\n","    accuracy                           0.83        36\n","   macro avg       0.84      0.83      0.83        36\n","weighted avg       0.84      0.83      0.83        36\n","\n","0.8333333333333334\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kqNQmV3oVO41","colab_type":"code","outputId":"876ec3ff-9b53-4e3e-dec9-45aeeb61a3b6","executionInfo":{"status":"ok","timestamp":1588537713961,"user_tz":300,"elapsed":47615,"user":{"displayName":"Shu-Hao Yeh","photoUrl":"","userId":"02698211427086926082"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# ANN\n","\n","# One hot the labels\n","le = LabelEncoder()\n","\n","y_test = to_categorical(y_test, 2)\n","y_train = to_categorical(y_train, 2)\n","\n","# Custom model for classification\n","model = Sequential()\n","\n","model.add(Dense(3, activation='relu', input_shape=(3,),kernel_initializer='random_normal'))\n","model.add(Dropout(0.2))\n","model.add(Dense(2, activation='sigmoid')) \n","\n","# Compile the model\n","model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam') \n","\n","model.summary()\n","\n","#train model\n","num_epochs = 1000\n","num_batch_size = 128\n","\n","\n","\n","callbacks = [\n","    ModelCheckpoint(\n","        filepath = '/content/drive/My Drive/CSCE 666/Project/Eric\\'s Notebooks/saved_models/Demographic_ANN_Binary_{epoch:02d}.h5',\n","        save_best_only=True,\n","        monitor='val_accuracy',\n","        verbose=1)\n","]\n","start = datetime.now()\n","\n","model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs,\n","          validation_data=(x_test, y_test), callbacks=callbacks, verbose=1)\n","\n","\n","duration = datetime.now() - start\n","print(\"Training completed in time: \", duration)\n","\n","# Calculate pre-training accuracy \n","score = model.evaluate(x_test, y_test, verbose=1)\n","accuracy = 100*score[1]\n","\n","print(\"Pre-training accuracy: %.4f%%\" % accuracy)\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 3)                 12        \n","_________________________________________________________________\n","dropout (Dropout)            (None, 3)                 0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 2)                 8         \n","=================================================================\n","Total params: 20\n","Trainable params: 20\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.7048 - accuracy: 0.4691\n","Epoch 00001: val_accuracy improved from -inf to 0.22222, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/Demographic_ANN_Binary_01.h5\n","1/1 [==============================] - 0s 427ms/step - loss: 0.7048 - accuracy: 0.4691 - val_loss: 0.7052 - val_accuracy: 0.2222\n","Epoch 2/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.7036 - accuracy: 0.3210\n","Epoch 00002: val_accuracy did not improve from 0.22222\n","1/1 [==============================] - 0s 28ms/step - loss: 0.7036 - accuracy: 0.3210 - val_loss: 0.7047 - val_accuracy: 0.2222\n","Epoch 3/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.7038 - accuracy: 0.3580\n","Epoch 00003: val_accuracy did not improve from 0.22222\n","1/1 [==============================] - 0s 28ms/step - loss: 0.7038 - accuracy: 0.3580 - val_loss: 0.7042 - val_accuracy: 0.2222\n","Epoch 4/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.7019 - accuracy: 0.3827\n","Epoch 00004: val_accuracy improved from 0.22222 to 0.25000, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/Demographic_ANN_Binary_04.h5\n","1/1 [==============================] - 0s 47ms/step - loss: 0.7019 - accuracy: 0.3827 - val_loss: 0.7037 - val_accuracy: 0.2500\n","Epoch 5/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.7026 - accuracy: 0.3580\n","Epoch 00005: val_accuracy did not improve from 0.25000\n","1/1 [==============================] - 0s 28ms/step - loss: 0.7026 - accuracy: 0.3580 - val_loss: 0.7032 - val_accuracy: 0.2500\n","Epoch 6/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6989 - accuracy: 0.3827\n","Epoch 00006: val_accuracy did not improve from 0.25000\n","1/1 [==============================] - 0s 26ms/step - loss: 0.6989 - accuracy: 0.3827 - val_loss: 0.7028 - val_accuracy: 0.2500\n","Epoch 7/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.7011 - accuracy: 0.3333\n","Epoch 00007: val_accuracy did not improve from 0.25000\n","1/1 [==============================] - 0s 28ms/step - loss: 0.7011 - accuracy: 0.3333 - val_loss: 0.7023 - val_accuracy: 0.2500\n","Epoch 8/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.7007 - accuracy: 0.3457\n","Epoch 00008: val_accuracy did not improve from 0.25000\n","1/1 [==============================] - 0s 27ms/step - loss: 0.7007 - accuracy: 0.3457 - val_loss: 0.7019 - val_accuracy: 0.2500\n","Epoch 9/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.7004 - accuracy: 0.3086\n","Epoch 00009: val_accuracy did not improve from 0.25000\n","1/1 [==============================] - 0s 27ms/step - loss: 0.7004 - accuracy: 0.3086 - val_loss: 0.7014 - val_accuracy: 0.2500\n","Epoch 10/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6999 - accuracy: 0.2840\n","Epoch 00010: val_accuracy did not improve from 0.25000\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6999 - accuracy: 0.2840 - val_loss: 0.7010 - val_accuracy: 0.2500\n","Epoch 11/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6995 - accuracy: 0.2716\n","Epoch 00011: val_accuracy improved from 0.25000 to 0.30556, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/Demographic_ANN_Binary_11.h5\n","1/1 [==============================] - 0s 46ms/step - loss: 0.6995 - accuracy: 0.2716 - val_loss: 0.7005 - val_accuracy: 0.3056\n","Epoch 12/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6970 - accuracy: 0.3827\n","Epoch 00012: val_accuracy did not improve from 0.30556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.6970 - accuracy: 0.3827 - val_loss: 0.7002 - val_accuracy: 0.2500\n","Epoch 13/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6975 - accuracy: 0.3457\n","Epoch 00013: val_accuracy did not improve from 0.30556\n","1/1 [==============================] - 0s 35ms/step - loss: 0.6975 - accuracy: 0.3457 - val_loss: 0.6998 - val_accuracy: 0.2778\n","Epoch 14/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6982 - accuracy: 0.3086\n","Epoch 00014: val_accuracy did not improve from 0.30556\n","1/1 [==============================] - 0s 26ms/step - loss: 0.6982 - accuracy: 0.3086 - val_loss: 0.6994 - val_accuracy: 0.2500\n","Epoch 15/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6973 - accuracy: 0.3704\n","Epoch 00015: val_accuracy did not improve from 0.30556\n","1/1 [==============================] - 0s 36ms/step - loss: 0.6973 - accuracy: 0.3704 - val_loss: 0.6991 - val_accuracy: 0.2500\n","Epoch 16/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6965 - accuracy: 0.4198\n","Epoch 00016: val_accuracy improved from 0.30556 to 0.33333, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/Demographic_ANN_Binary_16.h5\n","1/1 [==============================] - 0s 57ms/step - loss: 0.6965 - accuracy: 0.4198 - val_loss: 0.6987 - val_accuracy: 0.3333\n","Epoch 17/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6951 - accuracy: 0.4568\n","Epoch 00017: val_accuracy improved from 0.33333 to 0.36111, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/Demographic_ANN_Binary_17.h5\n","1/1 [==============================] - 0s 47ms/step - loss: 0.6951 - accuracy: 0.4568 - val_loss: 0.6984 - val_accuracy: 0.3611\n","Epoch 18/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6961 - accuracy: 0.4321\n","Epoch 00018: val_accuracy improved from 0.36111 to 0.41667, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/Demographic_ANN_Binary_18.h5\n","1/1 [==============================] - 0s 52ms/step - loss: 0.6961 - accuracy: 0.4321 - val_loss: 0.6980 - val_accuracy: 0.4167\n","Epoch 19/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6945 - accuracy: 0.5309\n","Epoch 00019: val_accuracy did not improve from 0.41667\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6945 - accuracy: 0.5309 - val_loss: 0.6977 - val_accuracy: 0.3889\n","Epoch 20/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6940 - accuracy: 0.5185\n","Epoch 00020: val_accuracy did not improve from 0.41667\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6940 - accuracy: 0.5185 - val_loss: 0.6974 - val_accuracy: 0.3889\n","Epoch 21/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6951 - accuracy: 0.5062\n","Epoch 00021: val_accuracy did not improve from 0.41667\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6951 - accuracy: 0.5062 - val_loss: 0.6970 - val_accuracy: 0.3889\n","Epoch 22/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.5556\n","Epoch 00022: val_accuracy did not improve from 0.41667\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6934 - accuracy: 0.5556 - val_loss: 0.6967 - val_accuracy: 0.4167\n","Epoch 23/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6941 - accuracy: 0.4691\n","Epoch 00023: val_accuracy did not improve from 0.41667\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6941 - accuracy: 0.4691 - val_loss: 0.6964 - val_accuracy: 0.4167\n","Epoch 24/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5185\n","Epoch 00024: val_accuracy did not improve from 0.41667\n","1/1 [==============================] - 0s 30ms/step - loss: 0.6932 - accuracy: 0.5185 - val_loss: 0.6961 - val_accuracy: 0.4167\n","Epoch 25/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5185\n","Epoch 00025: val_accuracy did not improve from 0.41667\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6932 - accuracy: 0.5185 - val_loss: 0.6958 - val_accuracy: 0.4167\n","Epoch 26/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6920 - accuracy: 0.5802\n","Epoch 00026: val_accuracy improved from 0.41667 to 0.44444, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/Demographic_ANN_Binary_26.h5\n","1/1 [==============================] - 0s 47ms/step - loss: 0.6920 - accuracy: 0.5802 - val_loss: 0.6957 - val_accuracy: 0.4444\n","Epoch 27/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6921 - accuracy: 0.5432\n","Epoch 00027: val_accuracy did not improve from 0.44444\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6921 - accuracy: 0.5432 - val_loss: 0.6955 - val_accuracy: 0.4444\n","Epoch 28/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6919 - accuracy: 0.5556\n","Epoch 00028: val_accuracy did not improve from 0.44444\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6919 - accuracy: 0.5556 - val_loss: 0.6954 - val_accuracy: 0.4444\n","Epoch 29/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6921 - accuracy: 0.5679\n","Epoch 00029: val_accuracy did not improve from 0.44444\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6921 - accuracy: 0.5679 - val_loss: 0.6952 - val_accuracy: 0.4444\n","Epoch 30/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6918 - accuracy: 0.5556\n","Epoch 00030: val_accuracy did not improve from 0.44444\n","1/1 [==============================] - 0s 26ms/step - loss: 0.6918 - accuracy: 0.5556 - val_loss: 0.6951 - val_accuracy: 0.4167\n","Epoch 31/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6913 - accuracy: 0.5679\n","Epoch 00031: val_accuracy did not improve from 0.44444\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6913 - accuracy: 0.5679 - val_loss: 0.6950 - val_accuracy: 0.4167\n","Epoch 32/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6914 - accuracy: 0.5432\n","Epoch 00032: val_accuracy did not improve from 0.44444\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6914 - accuracy: 0.5432 - val_loss: 0.6948 - val_accuracy: 0.4444\n","Epoch 33/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6911 - accuracy: 0.5432\n","Epoch 00033: val_accuracy did not improve from 0.44444\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6911 - accuracy: 0.5432 - val_loss: 0.6947 - val_accuracy: 0.4444\n","Epoch 34/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6903 - accuracy: 0.6173\n","Epoch 00034: val_accuracy did not improve from 0.44444\n","1/1 [==============================] - 0s 33ms/step - loss: 0.6903 - accuracy: 0.6173 - val_loss: 0.6946 - val_accuracy: 0.4167\n","Epoch 35/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6908 - accuracy: 0.5802\n","Epoch 00035: val_accuracy did not improve from 0.44444\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6908 - accuracy: 0.5802 - val_loss: 0.6945 - val_accuracy: 0.4167\n","Epoch 36/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6914 - accuracy: 0.5556\n","Epoch 00036: val_accuracy did not improve from 0.44444\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6914 - accuracy: 0.5556 - val_loss: 0.6944 - val_accuracy: 0.4444\n","Epoch 37/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6907 - accuracy: 0.5926\n","Epoch 00037: val_accuracy improved from 0.44444 to 0.47222, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/Demographic_ANN_Binary_37.h5\n","1/1 [==============================] - 0s 47ms/step - loss: 0.6907 - accuracy: 0.5926 - val_loss: 0.6943 - val_accuracy: 0.4722\n","Epoch 38/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6889 - accuracy: 0.6667\n","Epoch 00038: val_accuracy did not improve from 0.47222\n","1/1 [==============================] - 0s 36ms/step - loss: 0.6889 - accuracy: 0.6667 - val_loss: 0.6943 - val_accuracy: 0.4722\n","Epoch 39/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6898 - accuracy: 0.6173\n","Epoch 00039: val_accuracy did not improve from 0.47222\n","1/1 [==============================] - 0s 30ms/step - loss: 0.6898 - accuracy: 0.6173 - val_loss: 0.6942 - val_accuracy: 0.4722\n","Epoch 40/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6898 - accuracy: 0.6173\n","Epoch 00040: val_accuracy did not improve from 0.47222\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6898 - accuracy: 0.6173 - val_loss: 0.6941 - val_accuracy: 0.4722\n","Epoch 41/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6893 - accuracy: 0.6420\n","Epoch 00041: val_accuracy did not improve from 0.47222\n","1/1 [==============================] - 0s 26ms/step - loss: 0.6893 - accuracy: 0.6420 - val_loss: 0.6941 - val_accuracy: 0.4722\n","Epoch 42/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6899 - accuracy: 0.5802\n","Epoch 00042: val_accuracy did not improve from 0.47222\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6899 - accuracy: 0.5802 - val_loss: 0.6940 - val_accuracy: 0.4722\n","Epoch 43/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6888 - accuracy: 0.6543\n","Epoch 00043: val_accuracy improved from 0.47222 to 0.52778, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/Demographic_ANN_Binary_43.h5\n","1/1 [==============================] - 0s 49ms/step - loss: 0.6888 - accuracy: 0.6543 - val_loss: 0.6940 - val_accuracy: 0.5278\n","Epoch 44/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6893 - accuracy: 0.5926\n","Epoch 00044: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6893 - accuracy: 0.5926 - val_loss: 0.6939 - val_accuracy: 0.5278\n","Epoch 45/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6888 - accuracy: 0.6296\n","Epoch 00045: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.6888 - accuracy: 0.6296 - val_loss: 0.6938 - val_accuracy: 0.5278\n","Epoch 46/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6896 - accuracy: 0.5926\n","Epoch 00046: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6896 - accuracy: 0.5926 - val_loss: 0.6938 - val_accuracy: 0.5278\n","Epoch 47/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6880 - accuracy: 0.6543\n","Epoch 00047: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.6880 - accuracy: 0.6543 - val_loss: 0.6937 - val_accuracy: 0.5278\n","Epoch 48/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6886 - accuracy: 0.6543\n","Epoch 00048: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.6886 - accuracy: 0.6543 - val_loss: 0.6937 - val_accuracy: 0.5278\n","Epoch 49/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6881 - accuracy: 0.6173\n","Epoch 00049: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6881 - accuracy: 0.6173 - val_loss: 0.6936 - val_accuracy: 0.5278\n","Epoch 50/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6882 - accuracy: 0.6296\n","Epoch 00050: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6882 - accuracy: 0.6296 - val_loss: 0.6936 - val_accuracy: 0.5278\n","Epoch 51/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6875 - accuracy: 0.6296\n","Epoch 00051: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6875 - accuracy: 0.6296 - val_loss: 0.6935 - val_accuracy: 0.5278\n","Epoch 52/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6882 - accuracy: 0.6173\n","Epoch 00052: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6882 - accuracy: 0.6173 - val_loss: 0.6935 - val_accuracy: 0.5278\n","Epoch 53/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6872 - accuracy: 0.6543\n","Epoch 00053: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 38ms/step - loss: 0.6872 - accuracy: 0.6543 - val_loss: 0.6934 - val_accuracy: 0.5278\n","Epoch 54/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6864 - accuracy: 0.6667\n","Epoch 00054: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6864 - accuracy: 0.6667 - val_loss: 0.6934 - val_accuracy: 0.5278\n","Epoch 55/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6859 - accuracy: 0.6790\n","Epoch 00055: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6859 - accuracy: 0.6790 - val_loss: 0.6933 - val_accuracy: 0.5278\n","Epoch 56/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6869 - accuracy: 0.6543\n","Epoch 00056: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6869 - accuracy: 0.6543 - val_loss: 0.6932 - val_accuracy: 0.5278\n","Epoch 57/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6866 - accuracy: 0.6173\n","Epoch 00057: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6866 - accuracy: 0.6173 - val_loss: 0.6931 - val_accuracy: 0.5278\n","Epoch 58/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6846 - accuracy: 0.6914\n","Epoch 00058: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6846 - accuracy: 0.6914 - val_loss: 0.6930 - val_accuracy: 0.5278\n","Epoch 59/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6857 - accuracy: 0.6420\n","Epoch 00059: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6857 - accuracy: 0.6420 - val_loss: 0.6929 - val_accuracy: 0.5278\n","Epoch 60/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6840 - accuracy: 0.6914\n","Epoch 00060: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 32ms/step - loss: 0.6840 - accuracy: 0.6914 - val_loss: 0.6928 - val_accuracy: 0.5278\n","Epoch 61/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6847 - accuracy: 0.7160\n","Epoch 00061: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6847 - accuracy: 0.7160 - val_loss: 0.6927 - val_accuracy: 0.5278\n","Epoch 62/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6862 - accuracy: 0.6173\n","Epoch 00062: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 34ms/step - loss: 0.6862 - accuracy: 0.6173 - val_loss: 0.6925 - val_accuracy: 0.5278\n","Epoch 63/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6846 - accuracy: 0.6543\n","Epoch 00063: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 26ms/step - loss: 0.6846 - accuracy: 0.6543 - val_loss: 0.6924 - val_accuracy: 0.5278\n","Epoch 64/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6840 - accuracy: 0.6790\n","Epoch 00064: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6840 - accuracy: 0.6790 - val_loss: 0.6922 - val_accuracy: 0.5278\n","Epoch 65/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6844 - accuracy: 0.6790\n","Epoch 00065: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.6844 - accuracy: 0.6790 - val_loss: 0.6921 - val_accuracy: 0.5278\n","Epoch 66/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6835 - accuracy: 0.6790\n","Epoch 00066: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 26ms/step - loss: 0.6835 - accuracy: 0.6790 - val_loss: 0.6919 - val_accuracy: 0.5278\n","Epoch 67/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6854 - accuracy: 0.6296\n","Epoch 00067: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 32ms/step - loss: 0.6854 - accuracy: 0.6296 - val_loss: 0.6917 - val_accuracy: 0.5278\n","Epoch 68/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6838 - accuracy: 0.6667\n","Epoch 00068: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 26ms/step - loss: 0.6838 - accuracy: 0.6667 - val_loss: 0.6915 - val_accuracy: 0.5278\n","Epoch 69/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6820 - accuracy: 0.6790\n","Epoch 00069: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6820 - accuracy: 0.6790 - val_loss: 0.6913 - val_accuracy: 0.5278\n","Epoch 70/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6826 - accuracy: 0.6543\n","Epoch 00070: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6826 - accuracy: 0.6543 - val_loss: 0.6910 - val_accuracy: 0.5278\n","Epoch 71/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6823 - accuracy: 0.6543\n","Epoch 00071: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6823 - accuracy: 0.6543 - val_loss: 0.6908 - val_accuracy: 0.5278\n","Epoch 72/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6809 - accuracy: 0.7160\n","Epoch 00072: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 32ms/step - loss: 0.6809 - accuracy: 0.7160 - val_loss: 0.6905 - val_accuracy: 0.5278\n","Epoch 73/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6812 - accuracy: 0.7037\n","Epoch 00073: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 26ms/step - loss: 0.6812 - accuracy: 0.7037 - val_loss: 0.6902 - val_accuracy: 0.5278\n","Epoch 74/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6804 - accuracy: 0.7160\n","Epoch 00074: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6804 - accuracy: 0.7160 - val_loss: 0.6899 - val_accuracy: 0.5278\n","Epoch 75/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6793 - accuracy: 0.7284\n","Epoch 00075: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6793 - accuracy: 0.7284 - val_loss: 0.6896 - val_accuracy: 0.5278\n","Epoch 76/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6799 - accuracy: 0.6790\n","Epoch 00076: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6799 - accuracy: 0.6790 - val_loss: 0.6893 - val_accuracy: 0.5278\n","Epoch 77/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6775 - accuracy: 0.7160\n","Epoch 00077: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.6775 - accuracy: 0.7160 - val_loss: 0.6889 - val_accuracy: 0.5278\n","Epoch 78/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6809 - accuracy: 0.6914\n","Epoch 00078: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6809 - accuracy: 0.6914 - val_loss: 0.6886 - val_accuracy: 0.5278\n","Epoch 79/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6800 - accuracy: 0.7037\n","Epoch 00079: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6800 - accuracy: 0.7037 - val_loss: 0.6883 - val_accuracy: 0.5278\n","Epoch 80/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6783 - accuracy: 0.7160\n","Epoch 00080: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.6783 - accuracy: 0.7160 - val_loss: 0.6879 - val_accuracy: 0.5278\n","Epoch 81/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6796 - accuracy: 0.6667\n","Epoch 00081: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 33ms/step - loss: 0.6796 - accuracy: 0.6667 - val_loss: 0.6876 - val_accuracy: 0.5278\n","Epoch 82/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6757 - accuracy: 0.7160\n","Epoch 00082: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6757 - accuracy: 0.7160 - val_loss: 0.6872 - val_accuracy: 0.5278\n","Epoch 83/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6742 - accuracy: 0.7407\n","Epoch 00083: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.6742 - accuracy: 0.7407 - val_loss: 0.6868 - val_accuracy: 0.5278\n","Epoch 84/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6742 - accuracy: 0.7284\n","Epoch 00084: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6742 - accuracy: 0.7284 - val_loss: 0.6865 - val_accuracy: 0.5278\n","Epoch 85/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6787 - accuracy: 0.7037\n","Epoch 00085: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6787 - accuracy: 0.7037 - val_loss: 0.6861 - val_accuracy: 0.5278\n","Epoch 86/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6767 - accuracy: 0.7160\n","Epoch 00086: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.6767 - accuracy: 0.7160 - val_loss: 0.6857 - val_accuracy: 0.5278\n","Epoch 87/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6772 - accuracy: 0.6790\n","Epoch 00087: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.6772 - accuracy: 0.6790 - val_loss: 0.6853 - val_accuracy: 0.5278\n","Epoch 88/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6726 - accuracy: 0.7654\n","Epoch 00088: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.6726 - accuracy: 0.7654 - val_loss: 0.6850 - val_accuracy: 0.5278\n","Epoch 89/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6707 - accuracy: 0.7901\n","Epoch 00089: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.6707 - accuracy: 0.7901 - val_loss: 0.6846 - val_accuracy: 0.5278\n","Epoch 90/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6748 - accuracy: 0.7407\n","Epoch 00090: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 34ms/step - loss: 0.6748 - accuracy: 0.7407 - val_loss: 0.6842 - val_accuracy: 0.5278\n","Epoch 91/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6702 - accuracy: 0.7778\n","Epoch 00091: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 33ms/step - loss: 0.6702 - accuracy: 0.7778 - val_loss: 0.6837 - val_accuracy: 0.5278\n","Epoch 92/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6712 - accuracy: 0.7654\n","Epoch 00092: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6712 - accuracy: 0.7654 - val_loss: 0.6833 - val_accuracy: 0.5278\n","Epoch 93/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6689 - accuracy: 0.7654\n","Epoch 00093: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.6689 - accuracy: 0.7654 - val_loss: 0.6829 - val_accuracy: 0.5278\n","Epoch 94/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6736 - accuracy: 0.7284\n","Epoch 00094: val_accuracy did not improve from 0.52778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6736 - accuracy: 0.7284 - val_loss: 0.6825 - val_accuracy: 0.5278\n","Epoch 95/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6704 - accuracy: 0.7901\n","Epoch 00095: val_accuracy improved from 0.52778 to 0.55556, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/Demographic_ANN_Binary_95.h5\n","1/1 [==============================] - 0s 60ms/step - loss: 0.6704 - accuracy: 0.7901 - val_loss: 0.6820 - val_accuracy: 0.5556\n","Epoch 96/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6651 - accuracy: 0.8272\n","Epoch 00096: val_accuracy did not improve from 0.55556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6651 - accuracy: 0.8272 - val_loss: 0.6816 - val_accuracy: 0.5556\n","Epoch 97/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6687 - accuracy: 0.7778\n","Epoch 00097: val_accuracy improved from 0.55556 to 0.58333, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/Demographic_ANN_Binary_97.h5\n","1/1 [==============================] - 0s 46ms/step - loss: 0.6687 - accuracy: 0.7778 - val_loss: 0.6812 - val_accuracy: 0.5833\n","Epoch 98/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6690 - accuracy: 0.7654\n","Epoch 00098: val_accuracy improved from 0.58333 to 0.63889, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/Demographic_ANN_Binary_98.h5\n","1/1 [==============================] - 0s 45ms/step - loss: 0.6690 - accuracy: 0.7654 - val_loss: 0.6807 - val_accuracy: 0.6389\n","Epoch 99/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6676 - accuracy: 0.8148\n","Epoch 00099: val_accuracy did not improve from 0.63889\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6676 - accuracy: 0.8148 - val_loss: 0.6803 - val_accuracy: 0.6389\n","Epoch 100/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6673 - accuracy: 0.8025\n","Epoch 00100: val_accuracy improved from 0.63889 to 0.66667, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/Demographic_ANN_Binary_100.h5\n","1/1 [==============================] - 0s 54ms/step - loss: 0.6673 - accuracy: 0.8025 - val_loss: 0.6798 - val_accuracy: 0.6667\n","Epoch 101/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6699 - accuracy: 0.7037\n","Epoch 00101: val_accuracy improved from 0.66667 to 0.69444, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/Demographic_ANN_Binary_101.h5\n","1/1 [==============================] - 0s 48ms/step - loss: 0.6699 - accuracy: 0.7037 - val_loss: 0.6794 - val_accuracy: 0.6944\n","Epoch 102/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6634 - accuracy: 0.8272\n","Epoch 00102: val_accuracy improved from 0.69444 to 0.72222, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/Demographic_ANN_Binary_102.h5\n","1/1 [==============================] - 0s 48ms/step - loss: 0.6634 - accuracy: 0.8272 - val_loss: 0.6789 - val_accuracy: 0.7222\n","Epoch 103/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6641 - accuracy: 0.8272\n","Epoch 00103: val_accuracy did not improve from 0.72222\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6641 - accuracy: 0.8272 - val_loss: 0.6785 - val_accuracy: 0.7222\n","Epoch 104/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6645 - accuracy: 0.8025\n","Epoch 00104: val_accuracy did not improve from 0.72222\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6645 - accuracy: 0.8025 - val_loss: 0.6780 - val_accuracy: 0.7222\n","Epoch 105/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6628 - accuracy: 0.8272\n","Epoch 00105: val_accuracy did not improve from 0.72222\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6628 - accuracy: 0.8272 - val_loss: 0.6775 - val_accuracy: 0.7222\n","Epoch 106/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6639 - accuracy: 0.8148\n","Epoch 00106: val_accuracy did not improve from 0.72222\n","1/1 [==============================] - 0s 33ms/step - loss: 0.6639 - accuracy: 0.8148 - val_loss: 0.6771 - val_accuracy: 0.7222\n","Epoch 107/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6667 - accuracy: 0.7901\n","Epoch 00107: val_accuracy did not improve from 0.72222\n","1/1 [==============================] - 0s 30ms/step - loss: 0.6667 - accuracy: 0.7901 - val_loss: 0.6766 - val_accuracy: 0.7222\n","Epoch 108/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6600 - accuracy: 0.8025\n","Epoch 00108: val_accuracy did not improve from 0.72222\n","1/1 [==============================] - 0s 34ms/step - loss: 0.6600 - accuracy: 0.8025 - val_loss: 0.6761 - val_accuracy: 0.7222\n","Epoch 109/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6620 - accuracy: 0.7778\n","Epoch 00109: val_accuracy did not improve from 0.72222\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6620 - accuracy: 0.7778 - val_loss: 0.6757 - val_accuracy: 0.7222\n","Epoch 110/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6600 - accuracy: 0.8025\n","Epoch 00110: val_accuracy did not improve from 0.72222\n","1/1 [==============================] - 0s 32ms/step - loss: 0.6600 - accuracy: 0.8025 - val_loss: 0.6752 - val_accuracy: 0.7222\n","Epoch 111/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6597 - accuracy: 0.8148\n","Epoch 00111: val_accuracy improved from 0.72222 to 0.75000, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/Demographic_ANN_Binary_111.h5\n","1/1 [==============================] - 0s 54ms/step - loss: 0.6597 - accuracy: 0.8148 - val_loss: 0.6748 - val_accuracy: 0.7500\n","Epoch 112/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6576 - accuracy: 0.7778\n","Epoch 00112: val_accuracy did not improve from 0.75000\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6576 - accuracy: 0.7778 - val_loss: 0.6743 - val_accuracy: 0.7500\n","Epoch 113/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6591 - accuracy: 0.7901\n","Epoch 00113: val_accuracy did not improve from 0.75000\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6591 - accuracy: 0.7901 - val_loss: 0.6738 - val_accuracy: 0.7500\n","Epoch 114/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6565 - accuracy: 0.8148\n","Epoch 00114: val_accuracy did not improve from 0.75000\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6565 - accuracy: 0.8148 - val_loss: 0.6733 - val_accuracy: 0.7500\n","Epoch 115/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6566 - accuracy: 0.8025\n","Epoch 00115: val_accuracy did not improve from 0.75000\n","1/1 [==============================] - 0s 26ms/step - loss: 0.6566 - accuracy: 0.8025 - val_loss: 0.6729 - val_accuracy: 0.7500\n","Epoch 116/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6606 - accuracy: 0.7531\n","Epoch 00116: val_accuracy did not improve from 0.75000\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6606 - accuracy: 0.7531 - val_loss: 0.6724 - val_accuracy: 0.7500\n","Epoch 117/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6647 - accuracy: 0.7531\n","Epoch 00117: val_accuracy did not improve from 0.75000\n","1/1 [==============================] - 0s 30ms/step - loss: 0.6647 - accuracy: 0.7531 - val_loss: 0.6719 - val_accuracy: 0.7500\n","Epoch 118/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6580 - accuracy: 0.7778\n","Epoch 00118: val_accuracy did not improve from 0.75000\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6580 - accuracy: 0.7778 - val_loss: 0.6714 - val_accuracy: 0.7500\n","Epoch 119/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6533 - accuracy: 0.8025\n","Epoch 00119: val_accuracy improved from 0.75000 to 0.77778, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/Demographic_ANN_Binary_119.h5\n","1/1 [==============================] - 0s 75ms/step - loss: 0.6533 - accuracy: 0.8025 - val_loss: 0.6709 - val_accuracy: 0.7778\n","Epoch 120/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6548 - accuracy: 0.7901\n","Epoch 00120: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6548 - accuracy: 0.7901 - val_loss: 0.6704 - val_accuracy: 0.7778\n","Epoch 121/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6544 - accuracy: 0.7531\n","Epoch 00121: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6544 - accuracy: 0.7531 - val_loss: 0.6699 - val_accuracy: 0.7778\n","Epoch 122/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6528 - accuracy: 0.7901\n","Epoch 00122: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6528 - accuracy: 0.7901 - val_loss: 0.6694 - val_accuracy: 0.7778\n","Epoch 123/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6538 - accuracy: 0.8148\n","Epoch 00123: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6538 - accuracy: 0.8148 - val_loss: 0.6689 - val_accuracy: 0.7778\n","Epoch 124/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6499 - accuracy: 0.8025\n","Epoch 00124: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6499 - accuracy: 0.8025 - val_loss: 0.6684 - val_accuracy: 0.7778\n","Epoch 125/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6514 - accuracy: 0.8272\n","Epoch 00125: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6514 - accuracy: 0.8272 - val_loss: 0.6679 - val_accuracy: 0.7778\n","Epoch 126/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6474 - accuracy: 0.8519\n","Epoch 00126: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6474 - accuracy: 0.8519 - val_loss: 0.6673 - val_accuracy: 0.7778\n","Epoch 127/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6479 - accuracy: 0.8395\n","Epoch 00127: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6479 - accuracy: 0.8395 - val_loss: 0.6668 - val_accuracy: 0.7778\n","Epoch 128/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6538 - accuracy: 0.8025\n","Epoch 00128: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 33ms/step - loss: 0.6538 - accuracy: 0.8025 - val_loss: 0.6663 - val_accuracy: 0.7778\n","Epoch 129/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6516 - accuracy: 0.7901\n","Epoch 00129: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 37ms/step - loss: 0.6516 - accuracy: 0.7901 - val_loss: 0.6658 - val_accuracy: 0.7778\n","Epoch 130/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6544 - accuracy: 0.8395\n","Epoch 00130: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6544 - accuracy: 0.8395 - val_loss: 0.6653 - val_accuracy: 0.7778\n","Epoch 131/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6466 - accuracy: 0.8395\n","Epoch 00131: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.6466 - accuracy: 0.8395 - val_loss: 0.6647 - val_accuracy: 0.7778\n","Epoch 132/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6542 - accuracy: 0.8272\n","Epoch 00132: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 34ms/step - loss: 0.6542 - accuracy: 0.8272 - val_loss: 0.6642 - val_accuracy: 0.7778\n","Epoch 133/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6492 - accuracy: 0.8148\n","Epoch 00133: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6492 - accuracy: 0.8148 - val_loss: 0.6637 - val_accuracy: 0.7778\n","Epoch 134/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6420 - accuracy: 0.8519\n","Epoch 00134: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.6420 - accuracy: 0.8519 - val_loss: 0.6631 - val_accuracy: 0.7778\n","Epoch 135/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6469 - accuracy: 0.8519\n","Epoch 00135: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.6469 - accuracy: 0.8519 - val_loss: 0.6626 - val_accuracy: 0.7778\n","Epoch 136/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6427 - accuracy: 0.8519\n","Epoch 00136: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6427 - accuracy: 0.8519 - val_loss: 0.6621 - val_accuracy: 0.7778\n","Epoch 137/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6511 - accuracy: 0.8642\n","Epoch 00137: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6511 - accuracy: 0.8642 - val_loss: 0.6615 - val_accuracy: 0.7778\n","Epoch 138/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6424 - accuracy: 0.8642\n","Epoch 00138: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6424 - accuracy: 0.8642 - val_loss: 0.6610 - val_accuracy: 0.7778\n","Epoch 139/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6431 - accuracy: 0.8272\n","Epoch 00139: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 35ms/step - loss: 0.6431 - accuracy: 0.8272 - val_loss: 0.6604 - val_accuracy: 0.7778\n","Epoch 140/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6392 - accuracy: 0.8765\n","Epoch 00140: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 32ms/step - loss: 0.6392 - accuracy: 0.8765 - val_loss: 0.6599 - val_accuracy: 0.7778\n","Epoch 141/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6379 - accuracy: 0.8642\n","Epoch 00141: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6379 - accuracy: 0.8642 - val_loss: 0.6593 - val_accuracy: 0.7778\n","Epoch 142/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6425 - accuracy: 0.8395\n","Epoch 00142: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6425 - accuracy: 0.8395 - val_loss: 0.6587 - val_accuracy: 0.7778\n","Epoch 143/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6391 - accuracy: 0.9012\n","Epoch 00143: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6391 - accuracy: 0.9012 - val_loss: 0.6582 - val_accuracy: 0.7778\n","Epoch 144/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6362 - accuracy: 0.8642\n","Epoch 00144: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6362 - accuracy: 0.8642 - val_loss: 0.6576 - val_accuracy: 0.7778\n","Epoch 145/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6475 - accuracy: 0.8642\n","Epoch 00145: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6475 - accuracy: 0.8642 - val_loss: 0.6571 - val_accuracy: 0.7778\n","Epoch 146/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6331 - accuracy: 0.8642\n","Epoch 00146: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.6331 - accuracy: 0.8642 - val_loss: 0.6565 - val_accuracy: 0.7778\n","Epoch 147/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6311 - accuracy: 0.8889\n","Epoch 00147: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 33ms/step - loss: 0.6311 - accuracy: 0.8889 - val_loss: 0.6559 - val_accuracy: 0.7778\n","Epoch 148/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6406 - accuracy: 0.8272\n","Epoch 00148: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 34ms/step - loss: 0.6406 - accuracy: 0.8272 - val_loss: 0.6554 - val_accuracy: 0.7778\n","Epoch 149/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6367 - accuracy: 0.9136\n","Epoch 00149: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.6367 - accuracy: 0.9136 - val_loss: 0.6548 - val_accuracy: 0.7778\n","Epoch 150/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6384 - accuracy: 0.8272\n","Epoch 00150: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.6384 - accuracy: 0.8272 - val_loss: 0.6543 - val_accuracy: 0.7778\n","Epoch 151/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6329 - accuracy: 0.8519\n","Epoch 00151: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.6329 - accuracy: 0.8519 - val_loss: 0.6537 - val_accuracy: 0.7778\n","Epoch 152/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6416 - accuracy: 0.8148\n","Epoch 00152: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6416 - accuracy: 0.8148 - val_loss: 0.6531 - val_accuracy: 0.7778\n","Epoch 153/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6275 - accuracy: 0.8642\n","Epoch 00153: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6275 - accuracy: 0.8642 - val_loss: 0.6526 - val_accuracy: 0.7778\n","Epoch 154/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6276 - accuracy: 0.8519\n","Epoch 00154: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6276 - accuracy: 0.8519 - val_loss: 0.6520 - val_accuracy: 0.7778\n","Epoch 155/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6265 - accuracy: 0.8519\n","Epoch 00155: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6265 - accuracy: 0.8519 - val_loss: 0.6514 - val_accuracy: 0.7778\n","Epoch 156/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6359 - accuracy: 0.8272\n","Epoch 00156: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.6359 - accuracy: 0.8272 - val_loss: 0.6509 - val_accuracy: 0.7778\n","Epoch 157/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6267 - accuracy: 0.8519\n","Epoch 00157: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6267 - accuracy: 0.8519 - val_loss: 0.6503 - val_accuracy: 0.7778\n","Epoch 158/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6356 - accuracy: 0.8272\n","Epoch 00158: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 32ms/step - loss: 0.6356 - accuracy: 0.8272 - val_loss: 0.6497 - val_accuracy: 0.7778\n","Epoch 159/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6297 - accuracy: 0.8642\n","Epoch 00159: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6297 - accuracy: 0.8642 - val_loss: 0.6492 - val_accuracy: 0.7778\n","Epoch 160/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6320 - accuracy: 0.8519\n","Epoch 00160: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 33ms/step - loss: 0.6320 - accuracy: 0.8519 - val_loss: 0.6486 - val_accuracy: 0.7778\n","Epoch 161/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6342 - accuracy: 0.8395\n","Epoch 00161: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6342 - accuracy: 0.8395 - val_loss: 0.6480 - val_accuracy: 0.7778\n","Epoch 162/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6217 - accuracy: 0.8519\n","Epoch 00162: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6217 - accuracy: 0.8519 - val_loss: 0.6475 - val_accuracy: 0.7778\n","Epoch 163/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6209 - accuracy: 0.8519\n","Epoch 00163: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6209 - accuracy: 0.8519 - val_loss: 0.6469 - val_accuracy: 0.7778\n","Epoch 164/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6219 - accuracy: 0.8025\n","Epoch 00164: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6219 - accuracy: 0.8025 - val_loss: 0.6463 - val_accuracy: 0.7778\n","Epoch 165/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6272 - accuracy: 0.8642\n","Epoch 00165: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6272 - accuracy: 0.8642 - val_loss: 0.6457 - val_accuracy: 0.7778\n","Epoch 166/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6160 - accuracy: 0.8765\n","Epoch 00166: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6160 - accuracy: 0.8765 - val_loss: 0.6452 - val_accuracy: 0.7778\n","Epoch 167/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6281 - accuracy: 0.8148\n","Epoch 00167: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6281 - accuracy: 0.8148 - val_loss: 0.6446 - val_accuracy: 0.7778\n","Epoch 168/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6250 - accuracy: 0.8519\n","Epoch 00168: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 32ms/step - loss: 0.6250 - accuracy: 0.8519 - val_loss: 0.6440 - val_accuracy: 0.7778\n","Epoch 169/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6219 - accuracy: 0.8148\n","Epoch 00169: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6219 - accuracy: 0.8148 - val_loss: 0.6434 - val_accuracy: 0.7778\n","Epoch 170/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6303 - accuracy: 0.8148\n","Epoch 00170: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6303 - accuracy: 0.8148 - val_loss: 0.6428 - val_accuracy: 0.7778\n","Epoch 171/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6251 - accuracy: 0.8395\n","Epoch 00171: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 26ms/step - loss: 0.6251 - accuracy: 0.8395 - val_loss: 0.6423 - val_accuracy: 0.7778\n","Epoch 172/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6239 - accuracy: 0.8765\n","Epoch 00172: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.6239 - accuracy: 0.8765 - val_loss: 0.6417 - val_accuracy: 0.7778\n","Epoch 173/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6227 - accuracy: 0.8642\n","Epoch 00173: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.6227 - accuracy: 0.8642 - val_loss: 0.6411 - val_accuracy: 0.7778\n","Epoch 174/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6110 - accuracy: 0.8148\n","Epoch 00174: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6110 - accuracy: 0.8148 - val_loss: 0.6405 - val_accuracy: 0.7778\n","Epoch 175/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6176 - accuracy: 0.8395\n","Epoch 00175: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.6176 - accuracy: 0.8395 - val_loss: 0.6399 - val_accuracy: 0.7778\n","Epoch 176/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6150 - accuracy: 0.8272\n","Epoch 00176: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.6150 - accuracy: 0.8272 - val_loss: 0.6393 - val_accuracy: 0.7778\n","Epoch 177/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6042 - accuracy: 0.8642\n","Epoch 00177: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 32ms/step - loss: 0.6042 - accuracy: 0.8642 - val_loss: 0.6387 - val_accuracy: 0.7778\n","Epoch 178/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6176 - accuracy: 0.8642\n","Epoch 00178: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6176 - accuracy: 0.8642 - val_loss: 0.6381 - val_accuracy: 0.7778\n","Epoch 179/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6110 - accuracy: 0.8765\n","Epoch 00179: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6110 - accuracy: 0.8765 - val_loss: 0.6374 - val_accuracy: 0.7778\n","Epoch 180/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6238 - accuracy: 0.8272\n","Epoch 00180: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6238 - accuracy: 0.8272 - val_loss: 0.6368 - val_accuracy: 0.7778\n","Epoch 181/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6066 - accuracy: 0.8395\n","Epoch 00181: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6066 - accuracy: 0.8395 - val_loss: 0.6362 - val_accuracy: 0.7778\n","Epoch 182/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6139 - accuracy: 0.8519\n","Epoch 00182: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6139 - accuracy: 0.8519 - val_loss: 0.6356 - val_accuracy: 0.7778\n","Epoch 183/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6251 - accuracy: 0.8272\n","Epoch 00183: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 38ms/step - loss: 0.6251 - accuracy: 0.8272 - val_loss: 0.6350 - val_accuracy: 0.7778\n","Epoch 184/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6075 - accuracy: 0.8765\n","Epoch 00184: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6075 - accuracy: 0.8765 - val_loss: 0.6344 - val_accuracy: 0.7778\n","Epoch 185/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6132 - accuracy: 0.8519\n","Epoch 00185: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 26ms/step - loss: 0.6132 - accuracy: 0.8519 - val_loss: 0.6338 - val_accuracy: 0.7778\n","Epoch 186/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6119 - accuracy: 0.8765\n","Epoch 00186: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6119 - accuracy: 0.8765 - val_loss: 0.6332 - val_accuracy: 0.7778\n","Epoch 187/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6104 - accuracy: 0.8148\n","Epoch 00187: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.6104 - accuracy: 0.8148 - val_loss: 0.6326 - val_accuracy: 0.7778\n","Epoch 188/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5964 - accuracy: 0.8765\n","Epoch 00188: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.5964 - accuracy: 0.8765 - val_loss: 0.6320 - val_accuracy: 0.7778\n","Epoch 189/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6111 - accuracy: 0.7901\n","Epoch 00189: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6111 - accuracy: 0.7901 - val_loss: 0.6314 - val_accuracy: 0.7778\n","Epoch 190/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6211 - accuracy: 0.8272\n","Epoch 00190: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 32ms/step - loss: 0.6211 - accuracy: 0.8272 - val_loss: 0.6308 - val_accuracy: 0.7778\n","Epoch 191/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6002 - accuracy: 0.8272\n","Epoch 00191: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6002 - accuracy: 0.8272 - val_loss: 0.6301 - val_accuracy: 0.7778\n","Epoch 192/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5882 - accuracy: 0.8889\n","Epoch 00192: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.5882 - accuracy: 0.8889 - val_loss: 0.6295 - val_accuracy: 0.7778\n","Epoch 193/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6018 - accuracy: 0.8765\n","Epoch 00193: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 26ms/step - loss: 0.6018 - accuracy: 0.8765 - val_loss: 0.6289 - val_accuracy: 0.7778\n","Epoch 194/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6030 - accuracy: 0.8642\n","Epoch 00194: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6030 - accuracy: 0.8642 - val_loss: 0.6283 - val_accuracy: 0.7778\n","Epoch 195/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6025 - accuracy: 0.8889\n","Epoch 00195: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.6025 - accuracy: 0.8889 - val_loss: 0.6277 - val_accuracy: 0.7778\n","Epoch 196/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5990 - accuracy: 0.8272\n","Epoch 00196: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 34ms/step - loss: 0.5990 - accuracy: 0.8272 - val_loss: 0.6271 - val_accuracy: 0.7778\n","Epoch 197/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6098 - accuracy: 0.8025\n","Epoch 00197: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6098 - accuracy: 0.8025 - val_loss: 0.6264 - val_accuracy: 0.7778\n","Epoch 198/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5905 - accuracy: 0.8519\n","Epoch 00198: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5905 - accuracy: 0.8519 - val_loss: 0.6258 - val_accuracy: 0.7778\n","Epoch 199/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5943 - accuracy: 0.8395\n","Epoch 00199: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.5943 - accuracy: 0.8395 - val_loss: 0.6252 - val_accuracy: 0.7778\n","Epoch 200/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6076 - accuracy: 0.8395\n","Epoch 00200: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.6076 - accuracy: 0.8395 - val_loss: 0.6246 - val_accuracy: 0.7778\n","Epoch 201/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5998 - accuracy: 0.8148\n","Epoch 00201: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5998 - accuracy: 0.8148 - val_loss: 0.6240 - val_accuracy: 0.7778\n","Epoch 202/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5982 - accuracy: 0.8519\n","Epoch 00202: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.5982 - accuracy: 0.8519 - val_loss: 0.6233 - val_accuracy: 0.7778\n","Epoch 203/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5931 - accuracy: 0.8765\n","Epoch 00203: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5931 - accuracy: 0.8765 - val_loss: 0.6227 - val_accuracy: 0.7778\n","Epoch 204/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5806 - accuracy: 0.9012\n","Epoch 00204: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 33ms/step - loss: 0.5806 - accuracy: 0.9012 - val_loss: 0.6221 - val_accuracy: 0.7778\n","Epoch 205/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6048 - accuracy: 0.8148\n","Epoch 00205: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 36ms/step - loss: 0.6048 - accuracy: 0.8148 - val_loss: 0.6215 - val_accuracy: 0.7778\n","Epoch 206/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5897 - accuracy: 0.8519\n","Epoch 00206: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 33ms/step - loss: 0.5897 - accuracy: 0.8519 - val_loss: 0.6209 - val_accuracy: 0.7778\n","Epoch 207/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6001 - accuracy: 0.8148\n","Epoch 00207: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 26ms/step - loss: 0.6001 - accuracy: 0.8148 - val_loss: 0.6203 - val_accuracy: 0.7778\n","Epoch 208/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6016 - accuracy: 0.8272\n","Epoch 00208: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.6016 - accuracy: 0.8272 - val_loss: 0.6196 - val_accuracy: 0.7778\n","Epoch 209/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5853 - accuracy: 0.8765\n","Epoch 00209: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.5853 - accuracy: 0.8765 - val_loss: 0.6190 - val_accuracy: 0.7778\n","Epoch 210/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6033 - accuracy: 0.8519\n","Epoch 00210: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.6033 - accuracy: 0.8519 - val_loss: 0.6184 - val_accuracy: 0.7778\n","Epoch 211/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5959 - accuracy: 0.8272\n","Epoch 00211: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5959 - accuracy: 0.8272 - val_loss: 0.6179 - val_accuracy: 0.7778\n","Epoch 212/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5796 - accuracy: 0.8642\n","Epoch 00212: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.5796 - accuracy: 0.8642 - val_loss: 0.6172 - val_accuracy: 0.7778\n","Epoch 213/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5761 - accuracy: 0.8519\n","Epoch 00213: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5761 - accuracy: 0.8519 - val_loss: 0.6166 - val_accuracy: 0.7778\n","Epoch 214/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5886 - accuracy: 0.8395\n","Epoch 00214: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.5886 - accuracy: 0.8395 - val_loss: 0.6160 - val_accuracy: 0.7778\n","Epoch 215/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5916 - accuracy: 0.8395\n","Epoch 00215: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5916 - accuracy: 0.8395 - val_loss: 0.6154 - val_accuracy: 0.7778\n","Epoch 216/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.6076 - accuracy: 0.8272\n","Epoch 00216: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 35ms/step - loss: 0.6076 - accuracy: 0.8272 - val_loss: 0.6148 - val_accuracy: 0.7778\n","Epoch 217/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5967 - accuracy: 0.8765\n","Epoch 00217: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.5967 - accuracy: 0.8765 - val_loss: 0.6141 - val_accuracy: 0.7778\n","Epoch 218/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5753 - accuracy: 0.8642\n","Epoch 00218: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5753 - accuracy: 0.8642 - val_loss: 0.6135 - val_accuracy: 0.7778\n","Epoch 219/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5808 - accuracy: 0.8765\n","Epoch 00219: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.5808 - accuracy: 0.8765 - val_loss: 0.6128 - val_accuracy: 0.7778\n","Epoch 220/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5851 - accuracy: 0.8395\n","Epoch 00220: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.5851 - accuracy: 0.8395 - val_loss: 0.6122 - val_accuracy: 0.7778\n","Epoch 221/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5746 - accuracy: 0.8395\n","Epoch 00221: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.5746 - accuracy: 0.8395 - val_loss: 0.6116 - val_accuracy: 0.7778\n","Epoch 222/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5954 - accuracy: 0.8642\n","Epoch 00222: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.5954 - accuracy: 0.8642 - val_loss: 0.6109 - val_accuracy: 0.7778\n","Epoch 223/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5801 - accuracy: 0.8519\n","Epoch 00223: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.5801 - accuracy: 0.8519 - val_loss: 0.6103 - val_accuracy: 0.7778\n","Epoch 224/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5688 - accuracy: 0.8765\n","Epoch 00224: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.5688 - accuracy: 0.8765 - val_loss: 0.6096 - val_accuracy: 0.7778\n","Epoch 225/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5850 - accuracy: 0.8519\n","Epoch 00225: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 35ms/step - loss: 0.5850 - accuracy: 0.8519 - val_loss: 0.6090 - val_accuracy: 0.7778\n","Epoch 226/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5843 - accuracy: 0.8148\n","Epoch 00226: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.5843 - accuracy: 0.8148 - val_loss: 0.6084 - val_accuracy: 0.7778\n","Epoch 227/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5727 - accuracy: 0.8519\n","Epoch 00227: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 26ms/step - loss: 0.5727 - accuracy: 0.8519 - val_loss: 0.6077 - val_accuracy: 0.7778\n","Epoch 228/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5702 - accuracy: 0.8765\n","Epoch 00228: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.5702 - accuracy: 0.8765 - val_loss: 0.6071 - val_accuracy: 0.7778\n","Epoch 229/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5747 - accuracy: 0.8642\n","Epoch 00229: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.5747 - accuracy: 0.8642 - val_loss: 0.6065 - val_accuracy: 0.7778\n","Epoch 230/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5762 - accuracy: 0.8519\n","Epoch 00230: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.5762 - accuracy: 0.8519 - val_loss: 0.6059 - val_accuracy: 0.7778\n","Epoch 231/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5650 - accuracy: 0.8272\n","Epoch 00231: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.5650 - accuracy: 0.8272 - val_loss: 0.6052 - val_accuracy: 0.7778\n","Epoch 232/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5596 - accuracy: 0.8642\n","Epoch 00232: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.5596 - accuracy: 0.8642 - val_loss: 0.6046 - val_accuracy: 0.7778\n","Epoch 233/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5805 - accuracy: 0.8395\n","Epoch 00233: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.5805 - accuracy: 0.8395 - val_loss: 0.6040 - val_accuracy: 0.7778\n","Epoch 234/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5948 - accuracy: 0.8148\n","Epoch 00234: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.5948 - accuracy: 0.8148 - val_loss: 0.6034 - val_accuracy: 0.7778\n","Epoch 235/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5752 - accuracy: 0.8519\n","Epoch 00235: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 33ms/step - loss: 0.5752 - accuracy: 0.8519 - val_loss: 0.6028 - val_accuracy: 0.7778\n","Epoch 236/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5588 - accuracy: 0.8642\n","Epoch 00236: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5588 - accuracy: 0.8642 - val_loss: 0.6022 - val_accuracy: 0.7778\n","Epoch 237/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5710 - accuracy: 0.8642\n","Epoch 00237: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5710 - accuracy: 0.8642 - val_loss: 0.6016 - val_accuracy: 0.7778\n","Epoch 238/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5695 - accuracy: 0.8519\n","Epoch 00238: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5695 - accuracy: 0.8519 - val_loss: 0.6009 - val_accuracy: 0.7778\n","Epoch 239/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5782 - accuracy: 0.8519\n","Epoch 00239: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.5782 - accuracy: 0.8519 - val_loss: 0.6003 - val_accuracy: 0.7778\n","Epoch 240/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5688 - accuracy: 0.8765\n","Epoch 00240: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.5688 - accuracy: 0.8765 - val_loss: 0.5997 - val_accuracy: 0.7778\n","Epoch 241/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5692 - accuracy: 0.8519\n","Epoch 00241: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5692 - accuracy: 0.8519 - val_loss: 0.5991 - val_accuracy: 0.7778\n","Epoch 242/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5757 - accuracy: 0.8395\n","Epoch 00242: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.5757 - accuracy: 0.8395 - val_loss: 0.5985 - val_accuracy: 0.7778\n","Epoch 243/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5524 - accuracy: 0.8642\n","Epoch 00243: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.5524 - accuracy: 0.8642 - val_loss: 0.5979 - val_accuracy: 0.7778\n","Epoch 244/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5576 - accuracy: 0.8642\n","Epoch 00244: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 35ms/step - loss: 0.5576 - accuracy: 0.8642 - val_loss: 0.5972 - val_accuracy: 0.7778\n","Epoch 245/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5691 - accuracy: 0.8395\n","Epoch 00245: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.5691 - accuracy: 0.8395 - val_loss: 0.5966 - val_accuracy: 0.7778\n","Epoch 246/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5778 - accuracy: 0.8395\n","Epoch 00246: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5778 - accuracy: 0.8395 - val_loss: 0.5960 - val_accuracy: 0.7778\n","Epoch 247/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5473 - accuracy: 0.8765\n","Epoch 00247: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5473 - accuracy: 0.8765 - val_loss: 0.5954 - val_accuracy: 0.7778\n","Epoch 248/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5550 - accuracy: 0.8889\n","Epoch 00248: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.5550 - accuracy: 0.8889 - val_loss: 0.5948 - val_accuracy: 0.7778\n","Epoch 249/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5599 - accuracy: 0.8519\n","Epoch 00249: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.5599 - accuracy: 0.8519 - val_loss: 0.5942 - val_accuracy: 0.7778\n","Epoch 250/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5714 - accuracy: 0.8765\n","Epoch 00250: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5714 - accuracy: 0.8765 - val_loss: 0.5935 - val_accuracy: 0.7778\n","Epoch 251/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5668 - accuracy: 0.8395\n","Epoch 00251: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5668 - accuracy: 0.8395 - val_loss: 0.5929 - val_accuracy: 0.7778\n","Epoch 252/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5581 - accuracy: 0.8519\n","Epoch 00252: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.5581 - accuracy: 0.8519 - val_loss: 0.5923 - val_accuracy: 0.7778\n","Epoch 253/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5529 - accuracy: 0.8889\n","Epoch 00253: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.5529 - accuracy: 0.8889 - val_loss: 0.5917 - val_accuracy: 0.7778\n","Epoch 254/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5492 - accuracy: 0.8642\n","Epoch 00254: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 32ms/step - loss: 0.5492 - accuracy: 0.8642 - val_loss: 0.5911 - val_accuracy: 0.7778\n","Epoch 255/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5585 - accuracy: 0.8765\n","Epoch 00255: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5585 - accuracy: 0.8765 - val_loss: 0.5905 - val_accuracy: 0.7778\n","Epoch 256/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5536 - accuracy: 0.8519\n","Epoch 00256: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.5536 - accuracy: 0.8519 - val_loss: 0.5899 - val_accuracy: 0.7778\n","Epoch 257/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5669 - accuracy: 0.8519\n","Epoch 00257: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.5669 - accuracy: 0.8519 - val_loss: 0.5893 - val_accuracy: 0.7778\n","Epoch 258/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5468 - accuracy: 0.8765\n","Epoch 00258: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.5468 - accuracy: 0.8765 - val_loss: 0.5887 - val_accuracy: 0.7778\n","Epoch 259/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5493 - accuracy: 0.8395\n","Epoch 00259: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.5493 - accuracy: 0.8395 - val_loss: 0.5881 - val_accuracy: 0.7778\n","Epoch 260/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5491 - accuracy: 0.8889\n","Epoch 00260: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 32ms/step - loss: 0.5491 - accuracy: 0.8889 - val_loss: 0.5874 - val_accuracy: 0.7778\n","Epoch 261/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5624 - accuracy: 0.8642\n","Epoch 00261: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5624 - accuracy: 0.8642 - val_loss: 0.5868 - val_accuracy: 0.7778\n","Epoch 262/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5577 - accuracy: 0.8395\n","Epoch 00262: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 36ms/step - loss: 0.5577 - accuracy: 0.8395 - val_loss: 0.5862 - val_accuracy: 0.7778\n","Epoch 263/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5479 - accuracy: 0.8642\n","Epoch 00263: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 32ms/step - loss: 0.5479 - accuracy: 0.8642 - val_loss: 0.5855 - val_accuracy: 0.7778\n","Epoch 264/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5645 - accuracy: 0.8519\n","Epoch 00264: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 34ms/step - loss: 0.5645 - accuracy: 0.8519 - val_loss: 0.5849 - val_accuracy: 0.7778\n","Epoch 265/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5477 - accuracy: 0.8889\n","Epoch 00265: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.5477 - accuracy: 0.8889 - val_loss: 0.5842 - val_accuracy: 0.7778\n","Epoch 266/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5487 - accuracy: 0.8642\n","Epoch 00266: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 27ms/step - loss: 0.5487 - accuracy: 0.8642 - val_loss: 0.5836 - val_accuracy: 0.7778\n","Epoch 267/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5551 - accuracy: 0.8395\n","Epoch 00267: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.5551 - accuracy: 0.8395 - val_loss: 0.5829 - val_accuracy: 0.7778\n","Epoch 268/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5472 - accuracy: 0.8765\n","Epoch 00268: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.5472 - accuracy: 0.8765 - val_loss: 0.5823 - val_accuracy: 0.7778\n","Epoch 269/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5426 - accuracy: 0.8642\n","Epoch 00269: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.5426 - accuracy: 0.8642 - val_loss: 0.5816 - val_accuracy: 0.7778\n","Epoch 270/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5232 - accuracy: 0.8889\n","Epoch 00270: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5232 - accuracy: 0.8889 - val_loss: 0.5810 - val_accuracy: 0.7778\n","Epoch 271/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5579 - accuracy: 0.8642\n","Epoch 00271: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5579 - accuracy: 0.8642 - val_loss: 0.5804 - val_accuracy: 0.7778\n","Epoch 272/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5703 - accuracy: 0.8395\n","Epoch 00272: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 40ms/step - loss: 0.5703 - accuracy: 0.8395 - val_loss: 0.5797 - val_accuracy: 0.7778\n","Epoch 273/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5354 - accuracy: 0.8765\n","Epoch 00273: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 45ms/step - loss: 0.5354 - accuracy: 0.8765 - val_loss: 0.5791 - val_accuracy: 0.7778\n","Epoch 274/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5398 - accuracy: 0.8889\n","Epoch 00274: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 42ms/step - loss: 0.5398 - accuracy: 0.8889 - val_loss: 0.5784 - val_accuracy: 0.7778\n","Epoch 275/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5364 - accuracy: 0.8765\n","Epoch 00275: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.5364 - accuracy: 0.8765 - val_loss: 0.5778 - val_accuracy: 0.7778\n","Epoch 276/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5557 - accuracy: 0.8519\n","Epoch 00276: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5557 - accuracy: 0.8519 - val_loss: 0.5772 - val_accuracy: 0.7778\n","Epoch 277/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5630 - accuracy: 0.8519\n","Epoch 00277: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 33ms/step - loss: 0.5630 - accuracy: 0.8519 - val_loss: 0.5765 - val_accuracy: 0.7778\n","Epoch 278/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5353 - accuracy: 0.8642\n","Epoch 00278: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.5353 - accuracy: 0.8642 - val_loss: 0.5759 - val_accuracy: 0.7778\n","Epoch 279/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5570 - accuracy: 0.8642\n","Epoch 00279: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 32ms/step - loss: 0.5570 - accuracy: 0.8642 - val_loss: 0.5752 - val_accuracy: 0.7778\n","Epoch 280/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5418 - accuracy: 0.8519\n","Epoch 00280: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 34ms/step - loss: 0.5418 - accuracy: 0.8519 - val_loss: 0.5746 - val_accuracy: 0.7778\n","Epoch 281/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5549 - accuracy: 0.8395\n","Epoch 00281: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 33ms/step - loss: 0.5549 - accuracy: 0.8395 - val_loss: 0.5739 - val_accuracy: 0.7778\n","Epoch 282/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5388 - accuracy: 0.8642\n","Epoch 00282: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 36ms/step - loss: 0.5388 - accuracy: 0.8642 - val_loss: 0.5733 - val_accuracy: 0.7778\n","Epoch 283/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5302 - accuracy: 0.8395\n","Epoch 00283: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 47ms/step - loss: 0.5302 - accuracy: 0.8395 - val_loss: 0.5727 - val_accuracy: 0.7778\n","Epoch 284/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5231 - accuracy: 0.8765\n","Epoch 00284: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 34ms/step - loss: 0.5231 - accuracy: 0.8765 - val_loss: 0.5721 - val_accuracy: 0.7778\n","Epoch 285/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5264 - accuracy: 0.8642\n","Epoch 00285: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.5264 - accuracy: 0.8642 - val_loss: 0.5714 - val_accuracy: 0.7778\n","Epoch 286/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5174 - accuracy: 0.9136\n","Epoch 00286: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.5174 - accuracy: 0.9136 - val_loss: 0.5708 - val_accuracy: 0.7778\n","Epoch 287/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5266 - accuracy: 0.8889\n","Epoch 00287: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 38ms/step - loss: 0.5266 - accuracy: 0.8889 - val_loss: 0.5702 - val_accuracy: 0.7778\n","Epoch 288/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5356 - accuracy: 0.8395\n","Epoch 00288: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.5356 - accuracy: 0.8395 - val_loss: 0.5696 - val_accuracy: 0.7778\n","Epoch 289/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5384 - accuracy: 0.8519\n","Epoch 00289: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.5384 - accuracy: 0.8519 - val_loss: 0.5690 - val_accuracy: 0.7778\n","Epoch 290/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5260 - accuracy: 0.8642\n","Epoch 00290: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.5260 - accuracy: 0.8642 - val_loss: 0.5683 - val_accuracy: 0.7778\n","Epoch 291/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5328 - accuracy: 0.8519\n","Epoch 00291: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.5328 - accuracy: 0.8519 - val_loss: 0.5677 - val_accuracy: 0.7778\n","Epoch 292/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5357 - accuracy: 0.8765\n","Epoch 00292: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 36ms/step - loss: 0.5357 - accuracy: 0.8765 - val_loss: 0.5671 - val_accuracy: 0.7778\n","Epoch 293/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5273 - accuracy: 0.8642\n","Epoch 00293: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 35ms/step - loss: 0.5273 - accuracy: 0.8642 - val_loss: 0.5664 - val_accuracy: 0.7778\n","Epoch 294/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5313 - accuracy: 0.8765\n","Epoch 00294: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.5313 - accuracy: 0.8765 - val_loss: 0.5658 - val_accuracy: 0.7778\n","Epoch 295/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5283 - accuracy: 0.8765\n","Epoch 00295: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.5283 - accuracy: 0.8765 - val_loss: 0.5652 - val_accuracy: 0.7778\n","Epoch 296/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5205 - accuracy: 0.8519\n","Epoch 00296: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.5205 - accuracy: 0.8519 - val_loss: 0.5646 - val_accuracy: 0.7778\n","Epoch 297/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5229 - accuracy: 0.8889\n","Epoch 00297: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 32ms/step - loss: 0.5229 - accuracy: 0.8889 - val_loss: 0.5640 - val_accuracy: 0.7778\n","Epoch 298/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5429 - accuracy: 0.8765\n","Epoch 00298: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.5429 - accuracy: 0.8765 - val_loss: 0.5634 - val_accuracy: 0.7778\n","Epoch 299/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5436 - accuracy: 0.8765\n","Epoch 00299: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 34ms/step - loss: 0.5436 - accuracy: 0.8765 - val_loss: 0.5628 - val_accuracy: 0.7778\n","Epoch 300/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5435 - accuracy: 0.8272\n","Epoch 00300: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.5435 - accuracy: 0.8272 - val_loss: 0.5622 - val_accuracy: 0.7778\n","Epoch 301/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5102 - accuracy: 0.8765\n","Epoch 00301: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.5102 - accuracy: 0.8765 - val_loss: 0.5616 - val_accuracy: 0.7778\n","Epoch 302/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5480 - accuracy: 0.8395\n","Epoch 00302: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 37ms/step - loss: 0.5480 - accuracy: 0.8395 - val_loss: 0.5610 - val_accuracy: 0.7778\n","Epoch 303/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5347 - accuracy: 0.8272\n","Epoch 00303: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.5347 - accuracy: 0.8272 - val_loss: 0.5604 - val_accuracy: 0.7778\n","Epoch 304/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5349 - accuracy: 0.8272\n","Epoch 00304: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.5349 - accuracy: 0.8272 - val_loss: 0.5598 - val_accuracy: 0.7778\n","Epoch 305/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5149 - accuracy: 0.8519\n","Epoch 00305: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.5149 - accuracy: 0.8519 - val_loss: 0.5592 - val_accuracy: 0.7778\n","Epoch 306/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5317 - accuracy: 0.8889\n","Epoch 00306: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.5317 - accuracy: 0.8889 - val_loss: 0.5587 - val_accuracy: 0.7778\n","Epoch 307/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5064 - accuracy: 0.8889\n","Epoch 00307: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.5064 - accuracy: 0.8889 - val_loss: 0.5581 - val_accuracy: 0.7778\n","Epoch 308/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5168 - accuracy: 0.8889\n","Epoch 00308: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.5168 - accuracy: 0.8889 - val_loss: 0.5575 - val_accuracy: 0.7778\n","Epoch 309/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5271 - accuracy: 0.8642\n","Epoch 00309: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5271 - accuracy: 0.8642 - val_loss: 0.5569 - val_accuracy: 0.7778\n","Epoch 310/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5299 - accuracy: 0.8765\n","Epoch 00310: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.5299 - accuracy: 0.8765 - val_loss: 0.5563 - val_accuracy: 0.7778\n","Epoch 311/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5203 - accuracy: 0.8642\n","Epoch 00311: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.5203 - accuracy: 0.8642 - val_loss: 0.5557 - val_accuracy: 0.7778\n","Epoch 312/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5182 - accuracy: 0.8642\n","Epoch 00312: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 38ms/step - loss: 0.5182 - accuracy: 0.8642 - val_loss: 0.5551 - val_accuracy: 0.7778\n","Epoch 313/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5024 - accuracy: 0.8519\n","Epoch 00313: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 33ms/step - loss: 0.5024 - accuracy: 0.8519 - val_loss: 0.5545 - val_accuracy: 0.7778\n","Epoch 314/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5268 - accuracy: 0.8272\n","Epoch 00314: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 38ms/step - loss: 0.5268 - accuracy: 0.8272 - val_loss: 0.5539 - val_accuracy: 0.7778\n","Epoch 315/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5000 - accuracy: 0.8642\n","Epoch 00315: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 34ms/step - loss: 0.5000 - accuracy: 0.8642 - val_loss: 0.5533 - val_accuracy: 0.7778\n","Epoch 316/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5131 - accuracy: 0.8765\n","Epoch 00316: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 33ms/step - loss: 0.5131 - accuracy: 0.8765 - val_loss: 0.5527 - val_accuracy: 0.7778\n","Epoch 317/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5176 - accuracy: 0.8395\n","Epoch 00317: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5176 - accuracy: 0.8395 - val_loss: 0.5521 - val_accuracy: 0.7778\n","Epoch 318/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4941 - accuracy: 0.8765\n","Epoch 00318: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4941 - accuracy: 0.8765 - val_loss: 0.5515 - val_accuracy: 0.7778\n","Epoch 319/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5221 - accuracy: 0.8765\n","Epoch 00319: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 32ms/step - loss: 0.5221 - accuracy: 0.8765 - val_loss: 0.5509 - val_accuracy: 0.7778\n","Epoch 320/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5253 - accuracy: 0.8765\n","Epoch 00320: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.5253 - accuracy: 0.8765 - val_loss: 0.5504 - val_accuracy: 0.7778\n","Epoch 321/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5186 - accuracy: 0.8765\n","Epoch 00321: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.5186 - accuracy: 0.8765 - val_loss: 0.5498 - val_accuracy: 0.7778\n","Epoch 322/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5104 - accuracy: 0.8765\n","Epoch 00322: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 36ms/step - loss: 0.5104 - accuracy: 0.8765 - val_loss: 0.5492 - val_accuracy: 0.7778\n","Epoch 323/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4906 - accuracy: 0.8889\n","Epoch 00323: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4906 - accuracy: 0.8889 - val_loss: 0.5486 - val_accuracy: 0.7778\n","Epoch 324/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4962 - accuracy: 0.8642\n","Epoch 00324: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 41ms/step - loss: 0.4962 - accuracy: 0.8642 - val_loss: 0.5480 - val_accuracy: 0.7778\n","Epoch 325/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5197 - accuracy: 0.8519\n","Epoch 00325: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 32ms/step - loss: 0.5197 - accuracy: 0.8519 - val_loss: 0.5474 - val_accuracy: 0.7778\n","Epoch 326/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5261 - accuracy: 0.8765\n","Epoch 00326: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.5261 - accuracy: 0.8765 - val_loss: 0.5469 - val_accuracy: 0.7778\n","Epoch 327/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5016 - accuracy: 0.8395\n","Epoch 00327: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5016 - accuracy: 0.8395 - val_loss: 0.5463 - val_accuracy: 0.7778\n","Epoch 328/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4878 - accuracy: 0.8642\n","Epoch 00328: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4878 - accuracy: 0.8642 - val_loss: 0.5457 - val_accuracy: 0.7778\n","Epoch 329/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4838 - accuracy: 0.8519\n","Epoch 00329: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4838 - accuracy: 0.8519 - val_loss: 0.5452 - val_accuracy: 0.7778\n","Epoch 330/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5125 - accuracy: 0.8642\n","Epoch 00330: val_accuracy did not improve from 0.77778\n","1/1 [==============================] - 0s 31ms/step - loss: 0.5125 - accuracy: 0.8642 - val_loss: 0.5446 - val_accuracy: 0.7778\n","Epoch 331/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4869 - accuracy: 0.8395\n","Epoch 00331: val_accuracy improved from 0.77778 to 0.80556, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/Demographic_ANN_Binary_331.h5\n","1/1 [==============================] - 0s 62ms/step - loss: 0.4869 - accuracy: 0.8395 - val_loss: 0.5440 - val_accuracy: 0.8056\n","Epoch 332/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4948 - accuracy: 0.8642\n","Epoch 00332: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4948 - accuracy: 0.8642 - val_loss: 0.5435 - val_accuracy: 0.8056\n","Epoch 333/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5136 - accuracy: 0.8272\n","Epoch 00333: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.5136 - accuracy: 0.8272 - val_loss: 0.5429 - val_accuracy: 0.8056\n","Epoch 334/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4857 - accuracy: 0.8765\n","Epoch 00334: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4857 - accuracy: 0.8765 - val_loss: 0.5423 - val_accuracy: 0.8056\n","Epoch 335/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4902 - accuracy: 0.8765\n","Epoch 00335: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4902 - accuracy: 0.8765 - val_loss: 0.5417 - val_accuracy: 0.8056\n","Epoch 336/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5101 - accuracy: 0.8765\n","Epoch 00336: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5101 - accuracy: 0.8765 - val_loss: 0.5412 - val_accuracy: 0.8056\n","Epoch 337/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4803 - accuracy: 0.8642\n","Epoch 00337: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4803 - accuracy: 0.8642 - val_loss: 0.5406 - val_accuracy: 0.8056\n","Epoch 338/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4812 - accuracy: 0.8889\n","Epoch 00338: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4812 - accuracy: 0.8889 - val_loss: 0.5400 - val_accuracy: 0.8056\n","Epoch 339/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5055 - accuracy: 0.8642\n","Epoch 00339: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.5055 - accuracy: 0.8642 - val_loss: 0.5395 - val_accuracy: 0.8056\n","Epoch 340/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4930 - accuracy: 0.8765\n","Epoch 00340: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4930 - accuracy: 0.8765 - val_loss: 0.5389 - val_accuracy: 0.8056\n","Epoch 341/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5327 - accuracy: 0.8272\n","Epoch 00341: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 35ms/step - loss: 0.5327 - accuracy: 0.8272 - val_loss: 0.5384 - val_accuracy: 0.8056\n","Epoch 342/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5106 - accuracy: 0.8395\n","Epoch 00342: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.5106 - accuracy: 0.8395 - val_loss: 0.5378 - val_accuracy: 0.8056\n","Epoch 343/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4850 - accuracy: 0.8642\n","Epoch 00343: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4850 - accuracy: 0.8642 - val_loss: 0.5372 - val_accuracy: 0.8056\n","Epoch 344/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4655 - accuracy: 0.8765\n","Epoch 00344: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 34ms/step - loss: 0.4655 - accuracy: 0.8765 - val_loss: 0.5367 - val_accuracy: 0.8056\n","Epoch 345/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5000 - accuracy: 0.8642\n","Epoch 00345: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.5000 - accuracy: 0.8642 - val_loss: 0.5361 - val_accuracy: 0.8056\n","Epoch 346/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5098 - accuracy: 0.8148\n","Epoch 00346: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.5098 - accuracy: 0.8148 - val_loss: 0.5356 - val_accuracy: 0.8056\n","Epoch 347/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4862 - accuracy: 0.8765\n","Epoch 00347: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4862 - accuracy: 0.8765 - val_loss: 0.5351 - val_accuracy: 0.8056\n","Epoch 348/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5030 - accuracy: 0.8765\n","Epoch 00348: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.5030 - accuracy: 0.8765 - val_loss: 0.5345 - val_accuracy: 0.8056\n","Epoch 349/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4916 - accuracy: 0.8765\n","Epoch 00349: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4916 - accuracy: 0.8765 - val_loss: 0.5340 - val_accuracy: 0.8056\n","Epoch 350/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4866 - accuracy: 0.8642\n","Epoch 00350: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 36ms/step - loss: 0.4866 - accuracy: 0.8642 - val_loss: 0.5335 - val_accuracy: 0.8056\n","Epoch 351/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4925 - accuracy: 0.8519\n","Epoch 00351: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4925 - accuracy: 0.8519 - val_loss: 0.5329 - val_accuracy: 0.8056\n","Epoch 352/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5134 - accuracy: 0.8395\n","Epoch 00352: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.5134 - accuracy: 0.8395 - val_loss: 0.5324 - val_accuracy: 0.8056\n","Epoch 353/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4840 - accuracy: 0.9259\n","Epoch 00353: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4840 - accuracy: 0.9259 - val_loss: 0.5319 - val_accuracy: 0.8056\n","Epoch 354/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4999 - accuracy: 0.8765\n","Epoch 00354: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4999 - accuracy: 0.8765 - val_loss: 0.5313 - val_accuracy: 0.8056\n","Epoch 355/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4945 - accuracy: 0.8272\n","Epoch 00355: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4945 - accuracy: 0.8272 - val_loss: 0.5308 - val_accuracy: 0.8056\n","Epoch 356/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5029 - accuracy: 0.8889\n","Epoch 00356: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.5029 - accuracy: 0.8889 - val_loss: 0.5303 - val_accuracy: 0.8056\n","Epoch 357/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4979 - accuracy: 0.8889\n","Epoch 00357: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4979 - accuracy: 0.8889 - val_loss: 0.5297 - val_accuracy: 0.8056\n","Epoch 358/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5026 - accuracy: 0.8765\n","Epoch 00358: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.5026 - accuracy: 0.8765 - val_loss: 0.5292 - val_accuracy: 0.8056\n","Epoch 359/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4891 - accuracy: 0.8889\n","Epoch 00359: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4891 - accuracy: 0.8889 - val_loss: 0.5287 - val_accuracy: 0.8056\n","Epoch 360/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4711 - accuracy: 0.9012\n","Epoch 00360: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 34ms/step - loss: 0.4711 - accuracy: 0.9012 - val_loss: 0.5282 - val_accuracy: 0.8056\n","Epoch 361/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4922 - accuracy: 0.8889\n","Epoch 00361: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4922 - accuracy: 0.8889 - val_loss: 0.5277 - val_accuracy: 0.8056\n","Epoch 362/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4863 - accuracy: 0.8765\n","Epoch 00362: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4863 - accuracy: 0.8765 - val_loss: 0.5272 - val_accuracy: 0.8056\n","Epoch 363/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5050 - accuracy: 0.8272\n","Epoch 00363: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.5050 - accuracy: 0.8272 - val_loss: 0.5268 - val_accuracy: 0.8056\n","Epoch 364/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4950 - accuracy: 0.8272\n","Epoch 00364: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4950 - accuracy: 0.8272 - val_loss: 0.5263 - val_accuracy: 0.8056\n","Epoch 365/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4730 - accuracy: 0.8765\n","Epoch 00365: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4730 - accuracy: 0.8765 - val_loss: 0.5258 - val_accuracy: 0.8056\n","Epoch 366/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5170 - accuracy: 0.8519\n","Epoch 00366: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 34ms/step - loss: 0.5170 - accuracy: 0.8519 - val_loss: 0.5253 - val_accuracy: 0.8056\n","Epoch 367/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4837 - accuracy: 0.8642\n","Epoch 00367: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 37ms/step - loss: 0.4837 - accuracy: 0.8642 - val_loss: 0.5248 - val_accuracy: 0.8056\n","Epoch 368/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4868 - accuracy: 0.8272\n","Epoch 00368: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4868 - accuracy: 0.8272 - val_loss: 0.5243 - val_accuracy: 0.8056\n","Epoch 369/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5018 - accuracy: 0.8642\n","Epoch 00369: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.5018 - accuracy: 0.8642 - val_loss: 0.5238 - val_accuracy: 0.8056\n","Epoch 370/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4850 - accuracy: 0.8765\n","Epoch 00370: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 38ms/step - loss: 0.4850 - accuracy: 0.8765 - val_loss: 0.5233 - val_accuracy: 0.8056\n","Epoch 371/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5021 - accuracy: 0.8395\n","Epoch 00371: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.5021 - accuracy: 0.8395 - val_loss: 0.5228 - val_accuracy: 0.8056\n","Epoch 372/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4757 - accuracy: 0.8889\n","Epoch 00372: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4757 - accuracy: 0.8889 - val_loss: 0.5224 - val_accuracy: 0.8056\n","Epoch 373/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4899 - accuracy: 0.8395\n","Epoch 00373: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4899 - accuracy: 0.8395 - val_loss: 0.5219 - val_accuracy: 0.8056\n","Epoch 374/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4912 - accuracy: 0.8395\n","Epoch 00374: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4912 - accuracy: 0.8395 - val_loss: 0.5214 - val_accuracy: 0.8056\n","Epoch 375/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4935 - accuracy: 0.8272\n","Epoch 00375: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4935 - accuracy: 0.8272 - val_loss: 0.5209 - val_accuracy: 0.8056\n","Epoch 376/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4806 - accuracy: 0.8765\n","Epoch 00376: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4806 - accuracy: 0.8765 - val_loss: 0.5204 - val_accuracy: 0.8056\n","Epoch 377/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4723 - accuracy: 0.8642\n","Epoch 00377: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4723 - accuracy: 0.8642 - val_loss: 0.5199 - val_accuracy: 0.8056\n","Epoch 378/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4936 - accuracy: 0.8519\n","Epoch 00378: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4936 - accuracy: 0.8519 - val_loss: 0.5194 - val_accuracy: 0.8056\n","Epoch 379/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4516 - accuracy: 0.9012\n","Epoch 00379: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 35ms/step - loss: 0.4516 - accuracy: 0.9012 - val_loss: 0.5190 - val_accuracy: 0.8056\n","Epoch 380/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4966 - accuracy: 0.8642\n","Epoch 00380: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4966 - accuracy: 0.8642 - val_loss: 0.5185 - val_accuracy: 0.8056\n","Epoch 381/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4895 - accuracy: 0.8148\n","Epoch 00381: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4895 - accuracy: 0.8148 - val_loss: 0.5180 - val_accuracy: 0.8056\n","Epoch 382/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4749 - accuracy: 0.8642\n","Epoch 00382: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4749 - accuracy: 0.8642 - val_loss: 0.5175 - val_accuracy: 0.8056\n","Epoch 383/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5037 - accuracy: 0.8519\n","Epoch 00383: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.5037 - accuracy: 0.8519 - val_loss: 0.5171 - val_accuracy: 0.8056\n","Epoch 384/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4890 - accuracy: 0.8395\n","Epoch 00384: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 35ms/step - loss: 0.4890 - accuracy: 0.8395 - val_loss: 0.5166 - val_accuracy: 0.8056\n","Epoch 385/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4724 - accuracy: 0.8519\n","Epoch 00385: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4724 - accuracy: 0.8519 - val_loss: 0.5161 - val_accuracy: 0.8056\n","Epoch 386/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4675 - accuracy: 0.8519\n","Epoch 00386: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4675 - accuracy: 0.8519 - val_loss: 0.5157 - val_accuracy: 0.8056\n","Epoch 387/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4867 - accuracy: 0.8395\n","Epoch 00387: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4867 - accuracy: 0.8395 - val_loss: 0.5152 - val_accuracy: 0.8056\n","Epoch 388/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4801 - accuracy: 0.8642\n","Epoch 00388: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4801 - accuracy: 0.8642 - val_loss: 0.5148 - val_accuracy: 0.8056\n","Epoch 389/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5057 - accuracy: 0.8395\n","Epoch 00389: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 37ms/step - loss: 0.5057 - accuracy: 0.8395 - val_loss: 0.5143 - val_accuracy: 0.8056\n","Epoch 390/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4918 - accuracy: 0.8395\n","Epoch 00390: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4918 - accuracy: 0.8395 - val_loss: 0.5138 - val_accuracy: 0.8056\n","Epoch 391/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4882 - accuracy: 0.8519\n","Epoch 00391: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 35ms/step - loss: 0.4882 - accuracy: 0.8519 - val_loss: 0.5134 - val_accuracy: 0.8056\n","Epoch 392/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4739 - accuracy: 0.8395\n","Epoch 00392: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4739 - accuracy: 0.8395 - val_loss: 0.5129 - val_accuracy: 0.8056\n","Epoch 393/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4884 - accuracy: 0.8519\n","Epoch 00393: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4884 - accuracy: 0.8519 - val_loss: 0.5124 - val_accuracy: 0.8056\n","Epoch 394/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4765 - accuracy: 0.8395\n","Epoch 00394: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4765 - accuracy: 0.8395 - val_loss: 0.5120 - val_accuracy: 0.8056\n","Epoch 395/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4693 - accuracy: 0.8642\n","Epoch 00395: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4693 - accuracy: 0.8642 - val_loss: 0.5115 - val_accuracy: 0.8056\n","Epoch 396/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4737 - accuracy: 0.8642\n","Epoch 00396: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4737 - accuracy: 0.8642 - val_loss: 0.5111 - val_accuracy: 0.8056\n","Epoch 397/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4974 - accuracy: 0.8272\n","Epoch 00397: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4974 - accuracy: 0.8272 - val_loss: 0.5106 - val_accuracy: 0.8056\n","Epoch 398/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4660 - accuracy: 0.8642\n","Epoch 00398: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4660 - accuracy: 0.8642 - val_loss: 0.5102 - val_accuracy: 0.8056\n","Epoch 399/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4713 - accuracy: 0.8889\n","Epoch 00399: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 35ms/step - loss: 0.4713 - accuracy: 0.8889 - val_loss: 0.5098 - val_accuracy: 0.8056\n","Epoch 400/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4858 - accuracy: 0.8642\n","Epoch 00400: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4858 - accuracy: 0.8642 - val_loss: 0.5093 - val_accuracy: 0.8056\n","Epoch 401/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4690 - accuracy: 0.8642\n","Epoch 00401: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4690 - accuracy: 0.8642 - val_loss: 0.5089 - val_accuracy: 0.8056\n","Epoch 402/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4733 - accuracy: 0.8765\n","Epoch 00402: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4733 - accuracy: 0.8765 - val_loss: 0.5084 - val_accuracy: 0.8056\n","Epoch 403/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5014 - accuracy: 0.8642\n","Epoch 00403: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.5014 - accuracy: 0.8642 - val_loss: 0.5079 - val_accuracy: 0.8056\n","Epoch 404/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4760 - accuracy: 0.8519\n","Epoch 00404: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4760 - accuracy: 0.8519 - val_loss: 0.5075 - val_accuracy: 0.8056\n","Epoch 405/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4968 - accuracy: 0.8272\n","Epoch 00405: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4968 - accuracy: 0.8272 - val_loss: 0.5070 - val_accuracy: 0.8056\n","Epoch 406/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4453 - accuracy: 0.9012\n","Epoch 00406: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 34ms/step - loss: 0.4453 - accuracy: 0.9012 - val_loss: 0.5065 - val_accuracy: 0.8056\n","Epoch 407/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4918 - accuracy: 0.8519\n","Epoch 00407: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4918 - accuracy: 0.8519 - val_loss: 0.5060 - val_accuracy: 0.8056\n","Epoch 408/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4848 - accuracy: 0.8148\n","Epoch 00408: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 35ms/step - loss: 0.4848 - accuracy: 0.8148 - val_loss: 0.5055 - val_accuracy: 0.8056\n","Epoch 409/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4569 - accuracy: 0.8765\n","Epoch 00409: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4569 - accuracy: 0.8765 - val_loss: 0.5051 - val_accuracy: 0.8056\n","Epoch 410/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4502 - accuracy: 0.8519\n","Epoch 00410: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4502 - accuracy: 0.8519 - val_loss: 0.5046 - val_accuracy: 0.8056\n","Epoch 411/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4883 - accuracy: 0.8519\n","Epoch 00411: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4883 - accuracy: 0.8519 - val_loss: 0.5041 - val_accuracy: 0.8056\n","Epoch 412/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4483 - accuracy: 0.8889\n","Epoch 00412: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 40ms/step - loss: 0.4483 - accuracy: 0.8889 - val_loss: 0.5036 - val_accuracy: 0.8056\n","Epoch 413/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4820 - accuracy: 0.8395\n","Epoch 00413: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4820 - accuracy: 0.8395 - val_loss: 0.5032 - val_accuracy: 0.8056\n","Epoch 414/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4708 - accuracy: 0.8642\n","Epoch 00414: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4708 - accuracy: 0.8642 - val_loss: 0.5027 - val_accuracy: 0.8056\n","Epoch 415/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4341 - accuracy: 0.8889\n","Epoch 00415: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4341 - accuracy: 0.8889 - val_loss: 0.5023 - val_accuracy: 0.8056\n","Epoch 416/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4764 - accuracy: 0.8889\n","Epoch 00416: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4764 - accuracy: 0.8889 - val_loss: 0.5018 - val_accuracy: 0.8056\n","Epoch 417/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.5124 - accuracy: 0.8395\n","Epoch 00417: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 35ms/step - loss: 0.5124 - accuracy: 0.8395 - val_loss: 0.5014 - val_accuracy: 0.8056\n","Epoch 418/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4534 - accuracy: 0.8765\n","Epoch 00418: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 36ms/step - loss: 0.4534 - accuracy: 0.8765 - val_loss: 0.5009 - val_accuracy: 0.8056\n","Epoch 419/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4575 - accuracy: 0.8642\n","Epoch 00419: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4575 - accuracy: 0.8642 - val_loss: 0.5005 - val_accuracy: 0.8056\n","Epoch 420/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4616 - accuracy: 0.8642\n","Epoch 00420: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4616 - accuracy: 0.8642 - val_loss: 0.5001 - val_accuracy: 0.8056\n","Epoch 421/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4678 - accuracy: 0.8642\n","Epoch 00421: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4678 - accuracy: 0.8642 - val_loss: 0.4997 - val_accuracy: 0.8056\n","Epoch 422/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4667 - accuracy: 0.8765\n","Epoch 00422: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4667 - accuracy: 0.8765 - val_loss: 0.4993 - val_accuracy: 0.8056\n","Epoch 423/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4585 - accuracy: 0.8889\n","Epoch 00423: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4585 - accuracy: 0.8889 - val_loss: 0.4989 - val_accuracy: 0.8056\n","Epoch 424/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4620 - accuracy: 0.8765\n","Epoch 00424: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4620 - accuracy: 0.8765 - val_loss: 0.4985 - val_accuracy: 0.8056\n","Epoch 425/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4540 - accuracy: 0.8642\n","Epoch 00425: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 34ms/step - loss: 0.4540 - accuracy: 0.8642 - val_loss: 0.4982 - val_accuracy: 0.8056\n","Epoch 426/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4468 - accuracy: 0.8642\n","Epoch 00426: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 37ms/step - loss: 0.4468 - accuracy: 0.8642 - val_loss: 0.4978 - val_accuracy: 0.8056\n","Epoch 427/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4869 - accuracy: 0.8272\n","Epoch 00427: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4869 - accuracy: 0.8272 - val_loss: 0.4974 - val_accuracy: 0.8056\n","Epoch 428/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4757 - accuracy: 0.8272\n","Epoch 00428: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 43ms/step - loss: 0.4757 - accuracy: 0.8272 - val_loss: 0.4970 - val_accuracy: 0.8056\n","Epoch 429/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4424 - accuracy: 0.8765\n","Epoch 00429: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 34ms/step - loss: 0.4424 - accuracy: 0.8765 - val_loss: 0.4966 - val_accuracy: 0.8056\n","Epoch 430/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4617 - accuracy: 0.8519\n","Epoch 00430: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4617 - accuracy: 0.8519 - val_loss: 0.4962 - val_accuracy: 0.8056\n","Epoch 431/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4756 - accuracy: 0.8519\n","Epoch 00431: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4756 - accuracy: 0.8519 - val_loss: 0.4958 - val_accuracy: 0.8056\n","Epoch 432/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4892 - accuracy: 0.8519\n","Epoch 00432: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4892 - accuracy: 0.8519 - val_loss: 0.4955 - val_accuracy: 0.8056\n","Epoch 433/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4492 - accuracy: 0.8642\n","Epoch 00433: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4492 - accuracy: 0.8642 - val_loss: 0.4951 - val_accuracy: 0.8056\n","Epoch 434/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4706 - accuracy: 0.8642\n","Epoch 00434: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4706 - accuracy: 0.8642 - val_loss: 0.4947 - val_accuracy: 0.8056\n","Epoch 435/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4544 - accuracy: 0.8519\n","Epoch 00435: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4544 - accuracy: 0.8519 - val_loss: 0.4943 - val_accuracy: 0.8056\n","Epoch 436/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4480 - accuracy: 0.8642\n","Epoch 00436: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4480 - accuracy: 0.8642 - val_loss: 0.4939 - val_accuracy: 0.8056\n","Epoch 437/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4706 - accuracy: 0.8519\n","Epoch 00437: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4706 - accuracy: 0.8519 - val_loss: 0.4935 - val_accuracy: 0.8056\n","Epoch 438/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4416 - accuracy: 0.8765\n","Epoch 00438: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4416 - accuracy: 0.8765 - val_loss: 0.4932 - val_accuracy: 0.8056\n","Epoch 439/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4649 - accuracy: 0.8519\n","Epoch 00439: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4649 - accuracy: 0.8519 - val_loss: 0.4928 - val_accuracy: 0.8056\n","Epoch 440/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4407 - accuracy: 0.8889\n","Epoch 00440: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4407 - accuracy: 0.8889 - val_loss: 0.4924 - val_accuracy: 0.8056\n","Epoch 441/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4463 - accuracy: 0.8765\n","Epoch 00441: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4463 - accuracy: 0.8765 - val_loss: 0.4920 - val_accuracy: 0.8056\n","Epoch 442/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4476 - accuracy: 0.8642\n","Epoch 00442: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4476 - accuracy: 0.8642 - val_loss: 0.4916 - val_accuracy: 0.8056\n","Epoch 443/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4315 - accuracy: 0.8765\n","Epoch 00443: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4315 - accuracy: 0.8765 - val_loss: 0.4912 - val_accuracy: 0.8056\n","Epoch 444/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4282 - accuracy: 0.8642\n","Epoch 00444: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4282 - accuracy: 0.8642 - val_loss: 0.4908 - val_accuracy: 0.8056\n","Epoch 445/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4428 - accuracy: 0.8642\n","Epoch 00445: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4428 - accuracy: 0.8642 - val_loss: 0.4904 - val_accuracy: 0.8056\n","Epoch 446/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4523 - accuracy: 0.8519\n","Epoch 00446: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 38ms/step - loss: 0.4523 - accuracy: 0.8519 - val_loss: 0.4900 - val_accuracy: 0.8056\n","Epoch 447/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4636 - accuracy: 0.8272\n","Epoch 00447: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 35ms/step - loss: 0.4636 - accuracy: 0.8272 - val_loss: 0.4896 - val_accuracy: 0.8056\n","Epoch 448/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4482 - accuracy: 0.9012\n","Epoch 00448: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4482 - accuracy: 0.9012 - val_loss: 0.4892 - val_accuracy: 0.8056\n","Epoch 449/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4562 - accuracy: 0.8765\n","Epoch 00449: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4562 - accuracy: 0.8765 - val_loss: 0.4888 - val_accuracy: 0.8056\n","Epoch 450/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4582 - accuracy: 0.8642\n","Epoch 00450: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4582 - accuracy: 0.8642 - val_loss: 0.4884 - val_accuracy: 0.8056\n","Epoch 451/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4826 - accuracy: 0.8272\n","Epoch 00451: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4826 - accuracy: 0.8272 - val_loss: 0.4880 - val_accuracy: 0.8056\n","Epoch 452/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4575 - accuracy: 0.8395\n","Epoch 00452: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 34ms/step - loss: 0.4575 - accuracy: 0.8395 - val_loss: 0.4877 - val_accuracy: 0.8056\n","Epoch 453/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4400 - accuracy: 0.8889\n","Epoch 00453: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4400 - accuracy: 0.8889 - val_loss: 0.4873 - val_accuracy: 0.8056\n","Epoch 454/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4505 - accuracy: 0.8765\n","Epoch 00454: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4505 - accuracy: 0.8765 - val_loss: 0.4869 - val_accuracy: 0.8056\n","Epoch 455/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4436 - accuracy: 0.8642\n","Epoch 00455: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4436 - accuracy: 0.8642 - val_loss: 0.4866 - val_accuracy: 0.8056\n","Epoch 456/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4380 - accuracy: 0.8519\n","Epoch 00456: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 34ms/step - loss: 0.4380 - accuracy: 0.8519 - val_loss: 0.4862 - val_accuracy: 0.8056\n","Epoch 457/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4467 - accuracy: 0.8642\n","Epoch 00457: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4467 - accuracy: 0.8642 - val_loss: 0.4858 - val_accuracy: 0.8056\n","Epoch 458/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4368 - accuracy: 0.8642\n","Epoch 00458: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4368 - accuracy: 0.8642 - val_loss: 0.4854 - val_accuracy: 0.8056\n","Epoch 459/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4416 - accuracy: 0.8765\n","Epoch 00459: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4416 - accuracy: 0.8765 - val_loss: 0.4851 - val_accuracy: 0.8056\n","Epoch 460/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4450 - accuracy: 0.9012\n","Epoch 00460: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4450 - accuracy: 0.9012 - val_loss: 0.4847 - val_accuracy: 0.8056\n","Epoch 461/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4263 - accuracy: 0.8765\n","Epoch 00461: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 36ms/step - loss: 0.4263 - accuracy: 0.8765 - val_loss: 0.4844 - val_accuracy: 0.8056\n","Epoch 462/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4753 - accuracy: 0.8642\n","Epoch 00462: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4753 - accuracy: 0.8642 - val_loss: 0.4840 - val_accuracy: 0.8056\n","Epoch 463/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4546 - accuracy: 0.8642\n","Epoch 00463: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 35ms/step - loss: 0.4546 - accuracy: 0.8642 - val_loss: 0.4837 - val_accuracy: 0.8056\n","Epoch 464/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4517 - accuracy: 0.8519\n","Epoch 00464: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4517 - accuracy: 0.8519 - val_loss: 0.4833 - val_accuracy: 0.8056\n","Epoch 465/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4738 - accuracy: 0.8395\n","Epoch 00465: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4738 - accuracy: 0.8395 - val_loss: 0.4830 - val_accuracy: 0.8056\n","Epoch 466/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4265 - accuracy: 0.8889\n","Epoch 00466: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 36ms/step - loss: 0.4265 - accuracy: 0.8889 - val_loss: 0.4827 - val_accuracy: 0.8056\n","Epoch 467/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4232 - accuracy: 0.8889\n","Epoch 00467: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4232 - accuracy: 0.8889 - val_loss: 0.4824 - val_accuracy: 0.8056\n","Epoch 468/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4417 - accuracy: 0.8642\n","Epoch 00468: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4417 - accuracy: 0.8642 - val_loss: 0.4821 - val_accuracy: 0.8056\n","Epoch 469/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4597 - accuracy: 0.8642\n","Epoch 00469: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4597 - accuracy: 0.8642 - val_loss: 0.4818 - val_accuracy: 0.8056\n","Epoch 470/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4453 - accuracy: 0.8889\n","Epoch 00470: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4453 - accuracy: 0.8889 - val_loss: 0.4816 - val_accuracy: 0.8056\n","Epoch 471/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4371 - accuracy: 0.8765\n","Epoch 00471: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4371 - accuracy: 0.8765 - val_loss: 0.4813 - val_accuracy: 0.8056\n","Epoch 472/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4231 - accuracy: 0.8765\n","Epoch 00472: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4231 - accuracy: 0.8765 - val_loss: 0.4810 - val_accuracy: 0.8056\n","Epoch 473/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4451 - accuracy: 0.8765\n","Epoch 00473: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 39ms/step - loss: 0.4451 - accuracy: 0.8765 - val_loss: 0.4807 - val_accuracy: 0.8056\n","Epoch 474/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4319 - accuracy: 0.8642\n","Epoch 00474: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4319 - accuracy: 0.8642 - val_loss: 0.4804 - val_accuracy: 0.8056\n","Epoch 475/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4221 - accuracy: 0.8519\n","Epoch 00475: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4221 - accuracy: 0.8519 - val_loss: 0.4800 - val_accuracy: 0.8056\n","Epoch 476/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4551 - accuracy: 0.8395\n","Epoch 00476: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4551 - accuracy: 0.8395 - val_loss: 0.4797 - val_accuracy: 0.8056\n","Epoch 477/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4332 - accuracy: 0.8765\n","Epoch 00477: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4332 - accuracy: 0.8765 - val_loss: 0.4794 - val_accuracy: 0.8056\n","Epoch 478/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4350 - accuracy: 0.8765\n","Epoch 00478: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4350 - accuracy: 0.8765 - val_loss: 0.4791 - val_accuracy: 0.8056\n","Epoch 479/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4055 - accuracy: 0.8765\n","Epoch 00479: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4055 - accuracy: 0.8765 - val_loss: 0.4787 - val_accuracy: 0.8056\n","Epoch 480/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4556 - accuracy: 0.8642\n","Epoch 00480: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4556 - accuracy: 0.8642 - val_loss: 0.4784 - val_accuracy: 0.8056\n","Epoch 481/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4204 - accuracy: 0.9012\n","Epoch 00481: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4204 - accuracy: 0.9012 - val_loss: 0.4781 - val_accuracy: 0.8056\n","Epoch 482/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4515 - accuracy: 0.8642\n","Epoch 00482: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4515 - accuracy: 0.8642 - val_loss: 0.4777 - val_accuracy: 0.8056\n","Epoch 483/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4386 - accuracy: 0.8765\n","Epoch 00483: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4386 - accuracy: 0.8765 - val_loss: 0.4774 - val_accuracy: 0.8056\n","Epoch 484/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4033 - accuracy: 0.9136\n","Epoch 00484: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4033 - accuracy: 0.9136 - val_loss: 0.4771 - val_accuracy: 0.8056\n","Epoch 485/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4398 - accuracy: 0.8519\n","Epoch 00485: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4398 - accuracy: 0.8519 - val_loss: 0.4768 - val_accuracy: 0.8056\n","Epoch 486/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4478 - accuracy: 0.8642\n","Epoch 00486: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4478 - accuracy: 0.8642 - val_loss: 0.4765 - val_accuracy: 0.8056\n","Epoch 487/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4108 - accuracy: 0.8889\n","Epoch 00487: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4108 - accuracy: 0.8889 - val_loss: 0.4762 - val_accuracy: 0.8056\n","Epoch 488/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4505 - accuracy: 0.8519\n","Epoch 00488: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4505 - accuracy: 0.8519 - val_loss: 0.4759 - val_accuracy: 0.8056\n","Epoch 489/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4331 - accuracy: 0.8395\n","Epoch 00489: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4331 - accuracy: 0.8395 - val_loss: 0.4755 - val_accuracy: 0.8056\n","Epoch 490/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4169 - accuracy: 0.8765\n","Epoch 00490: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4169 - accuracy: 0.8765 - val_loss: 0.4752 - val_accuracy: 0.8056\n","Epoch 491/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4629 - accuracy: 0.8395\n","Epoch 00491: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4629 - accuracy: 0.8395 - val_loss: 0.4749 - val_accuracy: 0.8056\n","Epoch 492/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4319 - accuracy: 0.8765\n","Epoch 00492: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4319 - accuracy: 0.8765 - val_loss: 0.4746 - val_accuracy: 0.8056\n","Epoch 493/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4622 - accuracy: 0.8272\n","Epoch 00493: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4622 - accuracy: 0.8272 - val_loss: 0.4743 - val_accuracy: 0.8056\n","Epoch 494/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4620 - accuracy: 0.8272\n","Epoch 00494: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4620 - accuracy: 0.8272 - val_loss: 0.4740 - val_accuracy: 0.8056\n","Epoch 495/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4468 - accuracy: 0.8519\n","Epoch 00495: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 35ms/step - loss: 0.4468 - accuracy: 0.8519 - val_loss: 0.4737 - val_accuracy: 0.8056\n","Epoch 496/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4345 - accuracy: 0.8889\n","Epoch 00496: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4345 - accuracy: 0.8889 - val_loss: 0.4734 - val_accuracy: 0.8056\n","Epoch 497/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4269 - accuracy: 0.8642\n","Epoch 00497: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4269 - accuracy: 0.8642 - val_loss: 0.4731 - val_accuracy: 0.8056\n","Epoch 498/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4301 - accuracy: 0.8642\n","Epoch 00498: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4301 - accuracy: 0.8642 - val_loss: 0.4728 - val_accuracy: 0.8056\n","Epoch 499/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4437 - accuracy: 0.8765\n","Epoch 00499: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4437 - accuracy: 0.8765 - val_loss: 0.4725 - val_accuracy: 0.8056\n","Epoch 500/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4527 - accuracy: 0.8272\n","Epoch 00500: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4527 - accuracy: 0.8272 - val_loss: 0.4721 - val_accuracy: 0.8056\n","Epoch 501/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4202 - accuracy: 0.8889\n","Epoch 00501: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4202 - accuracy: 0.8889 - val_loss: 0.4718 - val_accuracy: 0.8056\n","Epoch 502/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4197 - accuracy: 0.8642\n","Epoch 00502: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4197 - accuracy: 0.8642 - val_loss: 0.4714 - val_accuracy: 0.8056\n","Epoch 503/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4398 - accuracy: 0.8765\n","Epoch 00503: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4398 - accuracy: 0.8765 - val_loss: 0.4711 - val_accuracy: 0.8056\n","Epoch 504/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4272 - accuracy: 0.8395\n","Epoch 00504: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4272 - accuracy: 0.8395 - val_loss: 0.4707 - val_accuracy: 0.8056\n","Epoch 505/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4489 - accuracy: 0.8889\n","Epoch 00505: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4489 - accuracy: 0.8889 - val_loss: 0.4704 - val_accuracy: 0.8056\n","Epoch 506/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4163 - accuracy: 0.8765\n","Epoch 00506: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4163 - accuracy: 0.8765 - val_loss: 0.4701 - val_accuracy: 0.8056\n","Epoch 507/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4326 - accuracy: 0.8765\n","Epoch 00507: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4326 - accuracy: 0.8765 - val_loss: 0.4698 - val_accuracy: 0.8056\n","Epoch 508/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4237 - accuracy: 0.8642\n","Epoch 00508: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4237 - accuracy: 0.8642 - val_loss: 0.4695 - val_accuracy: 0.8056\n","Epoch 509/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4181 - accuracy: 0.9012\n","Epoch 00509: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4181 - accuracy: 0.9012 - val_loss: 0.4692 - val_accuracy: 0.8056\n","Epoch 510/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4342 - accuracy: 0.8395\n","Epoch 00510: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4342 - accuracy: 0.8395 - val_loss: 0.4689 - val_accuracy: 0.8056\n","Epoch 511/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4629 - accuracy: 0.8395\n","Epoch 00511: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4629 - accuracy: 0.8395 - val_loss: 0.4686 - val_accuracy: 0.8056\n","Epoch 512/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4284 - accuracy: 0.8642\n","Epoch 00512: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4284 - accuracy: 0.8642 - val_loss: 0.4682 - val_accuracy: 0.8056\n","Epoch 513/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4304 - accuracy: 0.8395\n","Epoch 00513: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4304 - accuracy: 0.8395 - val_loss: 0.4679 - val_accuracy: 0.8056\n","Epoch 514/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4446 - accuracy: 0.8765\n","Epoch 00514: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 34ms/step - loss: 0.4446 - accuracy: 0.8765 - val_loss: 0.4676 - val_accuracy: 0.8056\n","Epoch 515/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4471 - accuracy: 0.8272\n","Epoch 00515: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4471 - accuracy: 0.8272 - val_loss: 0.4673 - val_accuracy: 0.8056\n","Epoch 516/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4148 - accuracy: 0.8765\n","Epoch 00516: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4148 - accuracy: 0.8765 - val_loss: 0.4670 - val_accuracy: 0.8056\n","Epoch 517/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4335 - accuracy: 0.8642\n","Epoch 00517: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4335 - accuracy: 0.8642 - val_loss: 0.4667 - val_accuracy: 0.8056\n","Epoch 518/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4348 - accuracy: 0.8642\n","Epoch 00518: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4348 - accuracy: 0.8642 - val_loss: 0.4664 - val_accuracy: 0.8056\n","Epoch 519/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4427 - accuracy: 0.8642\n","Epoch 00519: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4427 - accuracy: 0.8642 - val_loss: 0.4660 - val_accuracy: 0.8056\n","Epoch 520/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4084 - accuracy: 0.8642\n","Epoch 00520: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4084 - accuracy: 0.8642 - val_loss: 0.4657 - val_accuracy: 0.8056\n","Epoch 521/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4355 - accuracy: 0.8642\n","Epoch 00521: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4355 - accuracy: 0.8642 - val_loss: 0.4654 - val_accuracy: 0.8056\n","Epoch 522/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4200 - accuracy: 0.8765\n","Epoch 00522: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4200 - accuracy: 0.8765 - val_loss: 0.4651 - val_accuracy: 0.8056\n","Epoch 523/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4283 - accuracy: 0.8765\n","Epoch 00523: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4283 - accuracy: 0.8765 - val_loss: 0.4648 - val_accuracy: 0.8056\n","Epoch 524/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4330 - accuracy: 0.8519\n","Epoch 00524: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 38ms/step - loss: 0.4330 - accuracy: 0.8519 - val_loss: 0.4645 - val_accuracy: 0.8056\n","Epoch 525/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4419 - accuracy: 0.8642\n","Epoch 00525: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4419 - accuracy: 0.8642 - val_loss: 0.4642 - val_accuracy: 0.8056\n","Epoch 526/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4119 - accuracy: 0.8765\n","Epoch 00526: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4119 - accuracy: 0.8765 - val_loss: 0.4639 - val_accuracy: 0.8056\n","Epoch 527/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4279 - accuracy: 0.8642\n","Epoch 00527: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4279 - accuracy: 0.8642 - val_loss: 0.4637 - val_accuracy: 0.8056\n","Epoch 528/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3975 - accuracy: 0.8642\n","Epoch 00528: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 38ms/step - loss: 0.3975 - accuracy: 0.8642 - val_loss: 0.4634 - val_accuracy: 0.8056\n","Epoch 529/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4281 - accuracy: 0.8519\n","Epoch 00529: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4281 - accuracy: 0.8519 - val_loss: 0.4631 - val_accuracy: 0.8056\n","Epoch 530/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4398 - accuracy: 0.8519\n","Epoch 00530: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4398 - accuracy: 0.8519 - val_loss: 0.4629 - val_accuracy: 0.8056\n","Epoch 531/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4094 - accuracy: 0.8765\n","Epoch 00531: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4094 - accuracy: 0.8765 - val_loss: 0.4626 - val_accuracy: 0.8056\n","Epoch 532/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4415 - accuracy: 0.8395\n","Epoch 00532: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4415 - accuracy: 0.8395 - val_loss: 0.4623 - val_accuracy: 0.8056\n","Epoch 533/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4170 - accuracy: 0.8642\n","Epoch 00533: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 37ms/step - loss: 0.4170 - accuracy: 0.8642 - val_loss: 0.4621 - val_accuracy: 0.8056\n","Epoch 534/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4146 - accuracy: 0.8519\n","Epoch 00534: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4146 - accuracy: 0.8519 - val_loss: 0.4618 - val_accuracy: 0.8056\n","Epoch 535/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4012 - accuracy: 0.8765\n","Epoch 00535: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4012 - accuracy: 0.8765 - val_loss: 0.4616 - val_accuracy: 0.8056\n","Epoch 536/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3995 - accuracy: 0.8765\n","Epoch 00536: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3995 - accuracy: 0.8765 - val_loss: 0.4613 - val_accuracy: 0.8056\n","Epoch 537/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4558 - accuracy: 0.8519\n","Epoch 00537: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4558 - accuracy: 0.8519 - val_loss: 0.4610 - val_accuracy: 0.8056\n","Epoch 538/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4459 - accuracy: 0.8395\n","Epoch 00538: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4459 - accuracy: 0.8395 - val_loss: 0.4607 - val_accuracy: 0.8056\n","Epoch 539/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4211 - accuracy: 0.8519\n","Epoch 00539: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4211 - accuracy: 0.8519 - val_loss: 0.4604 - val_accuracy: 0.8056\n","Epoch 540/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4276 - accuracy: 0.8642\n","Epoch 00540: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4276 - accuracy: 0.8642 - val_loss: 0.4601 - val_accuracy: 0.8056\n","Epoch 541/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3909 - accuracy: 0.8765\n","Epoch 00541: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3909 - accuracy: 0.8765 - val_loss: 0.4598 - val_accuracy: 0.8056\n","Epoch 542/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4356 - accuracy: 0.8395\n","Epoch 00542: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4356 - accuracy: 0.8395 - val_loss: 0.4595 - val_accuracy: 0.8056\n","Epoch 543/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4088 - accuracy: 0.8519\n","Epoch 00543: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 35ms/step - loss: 0.4088 - accuracy: 0.8519 - val_loss: 0.4592 - val_accuracy: 0.8056\n","Epoch 544/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4221 - accuracy: 0.8889\n","Epoch 00544: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4221 - accuracy: 0.8889 - val_loss: 0.4589 - val_accuracy: 0.8056\n","Epoch 545/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4166 - accuracy: 0.8519\n","Epoch 00545: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4166 - accuracy: 0.8519 - val_loss: 0.4586 - val_accuracy: 0.8056\n","Epoch 546/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4613 - accuracy: 0.8519\n","Epoch 00546: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 35ms/step - loss: 0.4613 - accuracy: 0.8519 - val_loss: 0.4583 - val_accuracy: 0.8056\n","Epoch 547/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4170 - accuracy: 0.8519\n","Epoch 00547: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4170 - accuracy: 0.8519 - val_loss: 0.4580 - val_accuracy: 0.8056\n","Epoch 548/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4072 - accuracy: 0.8519\n","Epoch 00548: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4072 - accuracy: 0.8519 - val_loss: 0.4578 - val_accuracy: 0.8056\n","Epoch 549/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4560 - accuracy: 0.8272\n","Epoch 00549: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4560 - accuracy: 0.8272 - val_loss: 0.4575 - val_accuracy: 0.8056\n","Epoch 550/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4115 - accuracy: 0.8642\n","Epoch 00550: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4115 - accuracy: 0.8642 - val_loss: 0.4572 - val_accuracy: 0.8056\n","Epoch 551/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4206 - accuracy: 0.8519\n","Epoch 00551: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 26ms/step - loss: 0.4206 - accuracy: 0.8519 - val_loss: 0.4570 - val_accuracy: 0.8056\n","Epoch 552/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4169 - accuracy: 0.8519\n","Epoch 00552: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4169 - accuracy: 0.8519 - val_loss: 0.4567 - val_accuracy: 0.8056\n","Epoch 553/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4402 - accuracy: 0.8765\n","Epoch 00553: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4402 - accuracy: 0.8765 - val_loss: 0.4564 - val_accuracy: 0.8056\n","Epoch 554/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4190 - accuracy: 0.8395\n","Epoch 00554: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 26ms/step - loss: 0.4190 - accuracy: 0.8395 - val_loss: 0.4561 - val_accuracy: 0.8056\n","Epoch 555/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4016 - accuracy: 0.8765\n","Epoch 00555: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 34ms/step - loss: 0.4016 - accuracy: 0.8765 - val_loss: 0.4558 - val_accuracy: 0.8056\n","Epoch 556/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4367 - accuracy: 0.8519\n","Epoch 00556: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4367 - accuracy: 0.8519 - val_loss: 0.4556 - val_accuracy: 0.8056\n","Epoch 557/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3982 - accuracy: 0.8765\n","Epoch 00557: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3982 - accuracy: 0.8765 - val_loss: 0.4553 - val_accuracy: 0.8056\n","Epoch 558/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4452 - accuracy: 0.8395\n","Epoch 00558: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4452 - accuracy: 0.8395 - val_loss: 0.4550 - val_accuracy: 0.8056\n","Epoch 559/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4009 - accuracy: 0.8765\n","Epoch 00559: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4009 - accuracy: 0.8765 - val_loss: 0.4547 - val_accuracy: 0.8056\n","Epoch 560/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4131 - accuracy: 0.8519\n","Epoch 00560: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 34ms/step - loss: 0.4131 - accuracy: 0.8519 - val_loss: 0.4544 - val_accuracy: 0.8056\n","Epoch 561/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4047 - accuracy: 0.8642\n","Epoch 00561: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4047 - accuracy: 0.8642 - val_loss: 0.4542 - val_accuracy: 0.8056\n","Epoch 562/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3875 - accuracy: 0.8889\n","Epoch 00562: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3875 - accuracy: 0.8889 - val_loss: 0.4539 - val_accuracy: 0.8056\n","Epoch 563/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4293 - accuracy: 0.8395\n","Epoch 00563: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4293 - accuracy: 0.8395 - val_loss: 0.4536 - val_accuracy: 0.8056\n","Epoch 564/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4164 - accuracy: 0.8642\n","Epoch 00564: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4164 - accuracy: 0.8642 - val_loss: 0.4533 - val_accuracy: 0.8056\n","Epoch 565/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3841 - accuracy: 0.9012\n","Epoch 00565: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3841 - accuracy: 0.9012 - val_loss: 0.4530 - val_accuracy: 0.8056\n","Epoch 566/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4122 - accuracy: 0.8765\n","Epoch 00566: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4122 - accuracy: 0.8765 - val_loss: 0.4527 - val_accuracy: 0.8056\n","Epoch 567/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4002 - accuracy: 0.8765\n","Epoch 00567: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4002 - accuracy: 0.8765 - val_loss: 0.4525 - val_accuracy: 0.8056\n","Epoch 568/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4756 - accuracy: 0.8148\n","Epoch 00568: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4756 - accuracy: 0.8148 - val_loss: 0.4522 - val_accuracy: 0.8056\n","Epoch 569/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4147 - accuracy: 0.8889\n","Epoch 00569: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4147 - accuracy: 0.8889 - val_loss: 0.4519 - val_accuracy: 0.8056\n","Epoch 570/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4339 - accuracy: 0.8765\n","Epoch 00570: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4339 - accuracy: 0.8765 - val_loss: 0.4517 - val_accuracy: 0.8056\n","Epoch 571/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3926 - accuracy: 0.8889\n","Epoch 00571: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3926 - accuracy: 0.8889 - val_loss: 0.4515 - val_accuracy: 0.8056\n","Epoch 572/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4471 - accuracy: 0.8395\n","Epoch 00572: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 39ms/step - loss: 0.4471 - accuracy: 0.8395 - val_loss: 0.4512 - val_accuracy: 0.8056\n","Epoch 573/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3918 - accuracy: 0.8889\n","Epoch 00573: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3918 - accuracy: 0.8889 - val_loss: 0.4510 - val_accuracy: 0.8056\n","Epoch 574/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4212 - accuracy: 0.8395\n","Epoch 00574: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4212 - accuracy: 0.8395 - val_loss: 0.4507 - val_accuracy: 0.8056\n","Epoch 575/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4131 - accuracy: 0.8889\n","Epoch 00575: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4131 - accuracy: 0.8889 - val_loss: 0.4504 - val_accuracy: 0.8056\n","Epoch 576/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3947 - accuracy: 0.9012\n","Epoch 00576: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3947 - accuracy: 0.9012 - val_loss: 0.4502 - val_accuracy: 0.8056\n","Epoch 577/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3706 - accuracy: 0.8889\n","Epoch 00577: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3706 - accuracy: 0.8889 - val_loss: 0.4499 - val_accuracy: 0.8056\n","Epoch 578/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4244 - accuracy: 0.8519\n","Epoch 00578: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4244 - accuracy: 0.8519 - val_loss: 0.4497 - val_accuracy: 0.8056\n","Epoch 579/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4002 - accuracy: 0.8642\n","Epoch 00579: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4002 - accuracy: 0.8642 - val_loss: 0.4494 - val_accuracy: 0.8056\n","Epoch 580/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3660 - accuracy: 0.9012\n","Epoch 00580: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3660 - accuracy: 0.9012 - val_loss: 0.4491 - val_accuracy: 0.8056\n","Epoch 581/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.8642\n","Epoch 00581: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3863 - accuracy: 0.8642 - val_loss: 0.4488 - val_accuracy: 0.8056\n","Epoch 582/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.8519\n","Epoch 00582: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3863 - accuracy: 0.8519 - val_loss: 0.4486 - val_accuracy: 0.8056\n","Epoch 583/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4216 - accuracy: 0.8519\n","Epoch 00583: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 204ms/step - loss: 0.4216 - accuracy: 0.8519 - val_loss: 0.4483 - val_accuracy: 0.8056\n","Epoch 584/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4043 - accuracy: 0.8642\n","Epoch 00584: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4043 - accuracy: 0.8642 - val_loss: 0.4480 - val_accuracy: 0.8056\n","Epoch 585/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4208 - accuracy: 0.8519\n","Epoch 00585: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4208 - accuracy: 0.8519 - val_loss: 0.4477 - val_accuracy: 0.8056\n","Epoch 586/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4275 - accuracy: 0.8395\n","Epoch 00586: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4275 - accuracy: 0.8395 - val_loss: 0.4474 - val_accuracy: 0.8056\n","Epoch 587/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4176 - accuracy: 0.8765\n","Epoch 00587: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4176 - accuracy: 0.8765 - val_loss: 0.4471 - val_accuracy: 0.8056\n","Epoch 588/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4096 - accuracy: 0.8765\n","Epoch 00588: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4096 - accuracy: 0.8765 - val_loss: 0.4468 - val_accuracy: 0.8056\n","Epoch 589/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3799 - accuracy: 0.8765\n","Epoch 00589: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3799 - accuracy: 0.8765 - val_loss: 0.4465 - val_accuracy: 0.8056\n","Epoch 590/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4271 - accuracy: 0.8272\n","Epoch 00590: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 26ms/step - loss: 0.4271 - accuracy: 0.8272 - val_loss: 0.4462 - val_accuracy: 0.8056\n","Epoch 591/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4050 - accuracy: 0.8889\n","Epoch 00591: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 26ms/step - loss: 0.4050 - accuracy: 0.8889 - val_loss: 0.4459 - val_accuracy: 0.8056\n","Epoch 592/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4265 - accuracy: 0.8395\n","Epoch 00592: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 34ms/step - loss: 0.4265 - accuracy: 0.8395 - val_loss: 0.4457 - val_accuracy: 0.8056\n","Epoch 593/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4148 - accuracy: 0.8642\n","Epoch 00593: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 35ms/step - loss: 0.4148 - accuracy: 0.8642 - val_loss: 0.4454 - val_accuracy: 0.8056\n","Epoch 594/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3972 - accuracy: 0.8765\n","Epoch 00594: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3972 - accuracy: 0.8765 - val_loss: 0.4451 - val_accuracy: 0.8056\n","Epoch 595/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3895 - accuracy: 0.8889\n","Epoch 00595: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3895 - accuracy: 0.8889 - val_loss: 0.4449 - val_accuracy: 0.8056\n","Epoch 596/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4050 - accuracy: 0.8395\n","Epoch 00596: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4050 - accuracy: 0.8395 - val_loss: 0.4446 - val_accuracy: 0.8056\n","Epoch 597/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4126 - accuracy: 0.8642\n","Epoch 00597: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4126 - accuracy: 0.8642 - val_loss: 0.4443 - val_accuracy: 0.8056\n","Epoch 598/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4109 - accuracy: 0.8889\n","Epoch 00598: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4109 - accuracy: 0.8889 - val_loss: 0.4441 - val_accuracy: 0.8056\n","Epoch 599/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4140 - accuracy: 0.8395\n","Epoch 00599: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 26ms/step - loss: 0.4140 - accuracy: 0.8395 - val_loss: 0.4438 - val_accuracy: 0.8056\n","Epoch 600/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4145 - accuracy: 0.8642\n","Epoch 00600: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4145 - accuracy: 0.8642 - val_loss: 0.4435 - val_accuracy: 0.8056\n","Epoch 601/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4134 - accuracy: 0.8519\n","Epoch 00601: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4134 - accuracy: 0.8519 - val_loss: 0.4433 - val_accuracy: 0.8056\n","Epoch 602/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4214 - accuracy: 0.8395\n","Epoch 00602: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 26ms/step - loss: 0.4214 - accuracy: 0.8395 - val_loss: 0.4430 - val_accuracy: 0.8056\n","Epoch 603/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3766 - accuracy: 0.8642\n","Epoch 00603: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 26ms/step - loss: 0.3766 - accuracy: 0.8642 - val_loss: 0.4428 - val_accuracy: 0.8056\n","Epoch 604/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3995 - accuracy: 0.8642\n","Epoch 00604: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.3995 - accuracy: 0.8642 - val_loss: 0.4425 - val_accuracy: 0.8056\n","Epoch 605/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4049 - accuracy: 0.8765\n","Epoch 00605: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4049 - accuracy: 0.8765 - val_loss: 0.4423 - val_accuracy: 0.8056\n","Epoch 606/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4021 - accuracy: 0.8519\n","Epoch 00606: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4021 - accuracy: 0.8519 - val_loss: 0.4420 - val_accuracy: 0.8056\n","Epoch 607/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4504 - accuracy: 0.8025\n","Epoch 00607: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4504 - accuracy: 0.8025 - val_loss: 0.4418 - val_accuracy: 0.8056\n","Epoch 608/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4023 - accuracy: 0.8642\n","Epoch 00608: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4023 - accuracy: 0.8642 - val_loss: 0.4415 - val_accuracy: 0.8056\n","Epoch 609/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3901 - accuracy: 0.8765\n","Epoch 00609: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3901 - accuracy: 0.8765 - val_loss: 0.4413 - val_accuracy: 0.8056\n","Epoch 610/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3923 - accuracy: 0.8519\n","Epoch 00610: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.3923 - accuracy: 0.8519 - val_loss: 0.4411 - val_accuracy: 0.8056\n","Epoch 611/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3815 - accuracy: 0.9012\n","Epoch 00611: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 36ms/step - loss: 0.3815 - accuracy: 0.9012 - val_loss: 0.4408 - val_accuracy: 0.8056\n","Epoch 612/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4044 - accuracy: 0.8765\n","Epoch 00612: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4044 - accuracy: 0.8765 - val_loss: 0.4406 - val_accuracy: 0.8056\n","Epoch 613/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3912 - accuracy: 0.8889\n","Epoch 00613: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.3912 - accuracy: 0.8889 - val_loss: 0.4404 - val_accuracy: 0.8056\n","Epoch 614/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4212 - accuracy: 0.8272\n","Epoch 00614: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4212 - accuracy: 0.8272 - val_loss: 0.4402 - val_accuracy: 0.8056\n","Epoch 615/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3963 - accuracy: 0.8889\n","Epoch 00615: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3963 - accuracy: 0.8889 - val_loss: 0.4400 - val_accuracy: 0.8056\n","Epoch 616/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4188 - accuracy: 0.8642\n","Epoch 00616: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4188 - accuracy: 0.8642 - val_loss: 0.4398 - val_accuracy: 0.8056\n","Epoch 617/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3928 - accuracy: 0.8642\n","Epoch 00617: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3928 - accuracy: 0.8642 - val_loss: 0.4396 - val_accuracy: 0.8056\n","Epoch 618/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4044 - accuracy: 0.8765\n","Epoch 00618: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4044 - accuracy: 0.8765 - val_loss: 0.4395 - val_accuracy: 0.8056\n","Epoch 619/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3614 - accuracy: 0.8765\n","Epoch 00619: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3614 - accuracy: 0.8765 - val_loss: 0.4393 - val_accuracy: 0.8056\n","Epoch 620/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4237 - accuracy: 0.8889\n","Epoch 00620: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4237 - accuracy: 0.8889 - val_loss: 0.4391 - val_accuracy: 0.8056\n","Epoch 621/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4256 - accuracy: 0.8395\n","Epoch 00621: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4256 - accuracy: 0.8395 - val_loss: 0.4389 - val_accuracy: 0.8056\n","Epoch 622/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4338 - accuracy: 0.8395\n","Epoch 00622: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4338 - accuracy: 0.8395 - val_loss: 0.4387 - val_accuracy: 0.8056\n","Epoch 623/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4162 - accuracy: 0.8642\n","Epoch 00623: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4162 - accuracy: 0.8642 - val_loss: 0.4386 - val_accuracy: 0.8056\n","Epoch 624/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3908 - accuracy: 0.8889\n","Epoch 00624: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.3908 - accuracy: 0.8889 - val_loss: 0.4384 - val_accuracy: 0.8056\n","Epoch 625/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3965 - accuracy: 0.8519\n","Epoch 00625: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3965 - accuracy: 0.8519 - val_loss: 0.4382 - val_accuracy: 0.8056\n","Epoch 626/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4121 - accuracy: 0.8765\n","Epoch 00626: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4121 - accuracy: 0.8765 - val_loss: 0.4380 - val_accuracy: 0.8056\n","Epoch 627/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4030 - accuracy: 0.8765\n","Epoch 00627: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4030 - accuracy: 0.8765 - val_loss: 0.4378 - val_accuracy: 0.8056\n","Epoch 628/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3824 - accuracy: 0.9012\n","Epoch 00628: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 26ms/step - loss: 0.3824 - accuracy: 0.9012 - val_loss: 0.4376 - val_accuracy: 0.8056\n","Epoch 629/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4153 - accuracy: 0.8395\n","Epoch 00629: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4153 - accuracy: 0.8395 - val_loss: 0.4374 - val_accuracy: 0.8056\n","Epoch 630/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3884 - accuracy: 0.8765\n","Epoch 00630: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 34ms/step - loss: 0.3884 - accuracy: 0.8765 - val_loss: 0.4372 - val_accuracy: 0.8056\n","Epoch 631/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4191 - accuracy: 0.8519\n","Epoch 00631: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4191 - accuracy: 0.8519 - val_loss: 0.4370 - val_accuracy: 0.8056\n","Epoch 632/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3641 - accuracy: 0.8889\n","Epoch 00632: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 34ms/step - loss: 0.3641 - accuracy: 0.8889 - val_loss: 0.4368 - val_accuracy: 0.8056\n","Epoch 633/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4044 - accuracy: 0.8765\n","Epoch 00633: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4044 - accuracy: 0.8765 - val_loss: 0.4366 - val_accuracy: 0.8056\n","Epoch 634/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4296 - accuracy: 0.8272\n","Epoch 00634: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4296 - accuracy: 0.8272 - val_loss: 0.4364 - val_accuracy: 0.8056\n","Epoch 635/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4112 - accuracy: 0.8519\n","Epoch 00635: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4112 - accuracy: 0.8519 - val_loss: 0.4362 - val_accuracy: 0.8056\n","Epoch 636/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3873 - accuracy: 0.8519\n","Epoch 00636: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3873 - accuracy: 0.8519 - val_loss: 0.4359 - val_accuracy: 0.8056\n","Epoch 637/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3739 - accuracy: 0.9012\n","Epoch 00637: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3739 - accuracy: 0.9012 - val_loss: 0.4357 - val_accuracy: 0.8056\n","Epoch 638/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4030 - accuracy: 0.8272\n","Epoch 00638: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4030 - accuracy: 0.8272 - val_loss: 0.4355 - val_accuracy: 0.8056\n","Epoch 639/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4040 - accuracy: 0.8395\n","Epoch 00639: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4040 - accuracy: 0.8395 - val_loss: 0.4352 - val_accuracy: 0.8056\n","Epoch 640/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3793 - accuracy: 0.8765\n","Epoch 00640: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 34ms/step - loss: 0.3793 - accuracy: 0.8765 - val_loss: 0.4350 - val_accuracy: 0.8056\n","Epoch 641/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4081 - accuracy: 0.8642\n","Epoch 00641: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4081 - accuracy: 0.8642 - val_loss: 0.4348 - val_accuracy: 0.8056\n","Epoch 642/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3655 - accuracy: 0.8765\n","Epoch 00642: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3655 - accuracy: 0.8765 - val_loss: 0.4346 - val_accuracy: 0.8056\n","Epoch 643/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3751 - accuracy: 0.8765\n","Epoch 00643: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3751 - accuracy: 0.8765 - val_loss: 0.4344 - val_accuracy: 0.8056\n","Epoch 644/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4131 - accuracy: 0.8519\n","Epoch 00644: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4131 - accuracy: 0.8519 - val_loss: 0.4342 - val_accuracy: 0.8056\n","Epoch 645/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3851 - accuracy: 0.8889\n","Epoch 00645: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3851 - accuracy: 0.8889 - val_loss: 0.4339 - val_accuracy: 0.8056\n","Epoch 646/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4060 - accuracy: 0.8642\n","Epoch 00646: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4060 - accuracy: 0.8642 - val_loss: 0.4337 - val_accuracy: 0.8056\n","Epoch 647/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3659 - accuracy: 0.8765\n","Epoch 00647: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3659 - accuracy: 0.8765 - val_loss: 0.4335 - val_accuracy: 0.8056\n","Epoch 648/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4194 - accuracy: 0.8519\n","Epoch 00648: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4194 - accuracy: 0.8519 - val_loss: 0.4332 - val_accuracy: 0.8056\n","Epoch 649/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3643 - accuracy: 0.8889\n","Epoch 00649: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3643 - accuracy: 0.8889 - val_loss: 0.4330 - val_accuracy: 0.8056\n","Epoch 650/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3643 - accuracy: 0.9012\n","Epoch 00650: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3643 - accuracy: 0.9012 - val_loss: 0.4328 - val_accuracy: 0.8056\n","Epoch 651/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3944 - accuracy: 0.8765\n","Epoch 00651: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 26ms/step - loss: 0.3944 - accuracy: 0.8765 - val_loss: 0.4326 - val_accuracy: 0.8056\n","Epoch 652/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3967 - accuracy: 0.8765\n","Epoch 00652: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3967 - accuracy: 0.8765 - val_loss: 0.4324 - val_accuracy: 0.8056\n","Epoch 653/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3749 - accuracy: 0.8765\n","Epoch 00653: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3749 - accuracy: 0.8765 - val_loss: 0.4322 - val_accuracy: 0.8056\n","Epoch 654/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4116 - accuracy: 0.8765\n","Epoch 00654: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4116 - accuracy: 0.8765 - val_loss: 0.4320 - val_accuracy: 0.8056\n","Epoch 655/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.8519\n","Epoch 00655: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3816 - accuracy: 0.8519 - val_loss: 0.4318 - val_accuracy: 0.8056\n","Epoch 656/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3710 - accuracy: 0.8765\n","Epoch 00656: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3710 - accuracy: 0.8765 - val_loss: 0.4316 - val_accuracy: 0.8056\n","Epoch 657/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3884 - accuracy: 0.8642\n","Epoch 00657: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3884 - accuracy: 0.8642 - val_loss: 0.4314 - val_accuracy: 0.8056\n","Epoch 658/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4267 - accuracy: 0.8519\n","Epoch 00658: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.4267 - accuracy: 0.8519 - val_loss: 0.4312 - val_accuracy: 0.8056\n","Epoch 659/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3834 - accuracy: 0.9136\n","Epoch 00659: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3834 - accuracy: 0.9136 - val_loss: 0.4310 - val_accuracy: 0.8056\n","Epoch 660/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3756 - accuracy: 0.8642\n","Epoch 00660: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3756 - accuracy: 0.8642 - val_loss: 0.4308 - val_accuracy: 0.8056\n","Epoch 661/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3885 - accuracy: 0.8765\n","Epoch 00661: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 34ms/step - loss: 0.3885 - accuracy: 0.8765 - val_loss: 0.4305 - val_accuracy: 0.8056\n","Epoch 662/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4151 - accuracy: 0.8395\n","Epoch 00662: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4151 - accuracy: 0.8395 - val_loss: 0.4304 - val_accuracy: 0.8056\n","Epoch 663/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3939 - accuracy: 0.8765\n","Epoch 00663: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3939 - accuracy: 0.8765 - val_loss: 0.4302 - val_accuracy: 0.8056\n","Epoch 664/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4170 - accuracy: 0.8642\n","Epoch 00664: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4170 - accuracy: 0.8642 - val_loss: 0.4300 - val_accuracy: 0.8056\n","Epoch 665/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3965 - accuracy: 0.8519\n","Epoch 00665: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3965 - accuracy: 0.8519 - val_loss: 0.4297 - val_accuracy: 0.8056\n","Epoch 666/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3938 - accuracy: 0.8519\n","Epoch 00666: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 34ms/step - loss: 0.3938 - accuracy: 0.8519 - val_loss: 0.4295 - val_accuracy: 0.8056\n","Epoch 667/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3789 - accuracy: 0.8765\n","Epoch 00667: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3789 - accuracy: 0.8765 - val_loss: 0.4293 - val_accuracy: 0.8056\n","Epoch 668/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3906 - accuracy: 0.8642\n","Epoch 00668: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3906 - accuracy: 0.8642 - val_loss: 0.4291 - val_accuracy: 0.8056\n","Epoch 669/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3773 - accuracy: 0.8642\n","Epoch 00669: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 34ms/step - loss: 0.3773 - accuracy: 0.8642 - val_loss: 0.4288 - val_accuracy: 0.8056\n","Epoch 670/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4140 - accuracy: 0.8519\n","Epoch 00670: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4140 - accuracy: 0.8519 - val_loss: 0.4286 - val_accuracy: 0.8056\n","Epoch 671/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3914 - accuracy: 0.8765\n","Epoch 00671: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3914 - accuracy: 0.8765 - val_loss: 0.4284 - val_accuracy: 0.8056\n","Epoch 672/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3992 - accuracy: 0.8765\n","Epoch 00672: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3992 - accuracy: 0.8765 - val_loss: 0.4282 - val_accuracy: 0.8056\n","Epoch 673/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3982 - accuracy: 0.8519\n","Epoch 00673: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3982 - accuracy: 0.8519 - val_loss: 0.4280 - val_accuracy: 0.8056\n","Epoch 674/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3782 - accuracy: 0.8765\n","Epoch 00674: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.3782 - accuracy: 0.8765 - val_loss: 0.4278 - val_accuracy: 0.8056\n","Epoch 675/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4179 - accuracy: 0.8395\n","Epoch 00675: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4179 - accuracy: 0.8395 - val_loss: 0.4276 - val_accuracy: 0.8056\n","Epoch 676/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4018 - accuracy: 0.8765\n","Epoch 00676: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4018 - accuracy: 0.8765 - val_loss: 0.4274 - val_accuracy: 0.8056\n","Epoch 677/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3942 - accuracy: 0.8395\n","Epoch 00677: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3942 - accuracy: 0.8395 - val_loss: 0.4272 - val_accuracy: 0.8056\n","Epoch 678/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3912 - accuracy: 0.8765\n","Epoch 00678: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 35ms/step - loss: 0.3912 - accuracy: 0.8765 - val_loss: 0.4270 - val_accuracy: 0.8056\n","Epoch 679/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3812 - accuracy: 0.8642\n","Epoch 00679: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3812 - accuracy: 0.8642 - val_loss: 0.4268 - val_accuracy: 0.8056\n","Epoch 680/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4022 - accuracy: 0.8642\n","Epoch 00680: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4022 - accuracy: 0.8642 - val_loss: 0.4266 - val_accuracy: 0.8056\n","Epoch 681/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3808 - accuracy: 0.8889\n","Epoch 00681: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3808 - accuracy: 0.8889 - val_loss: 0.4264 - val_accuracy: 0.8056\n","Epoch 682/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3890 - accuracy: 0.8765\n","Epoch 00682: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3890 - accuracy: 0.8765 - val_loss: 0.4262 - val_accuracy: 0.8056\n","Epoch 683/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3780 - accuracy: 0.8765\n","Epoch 00683: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3780 - accuracy: 0.8765 - val_loss: 0.4260 - val_accuracy: 0.8056\n","Epoch 684/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4429 - accuracy: 0.8148\n","Epoch 00684: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4429 - accuracy: 0.8148 - val_loss: 0.4258 - val_accuracy: 0.8056\n","Epoch 685/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4085 - accuracy: 0.8395\n","Epoch 00685: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.4085 - accuracy: 0.8395 - val_loss: 0.4256 - val_accuracy: 0.8056\n","Epoch 686/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3812 - accuracy: 0.8765\n","Epoch 00686: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3812 - accuracy: 0.8765 - val_loss: 0.4253 - val_accuracy: 0.8056\n","Epoch 687/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3964 - accuracy: 0.8642\n","Epoch 00687: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3964 - accuracy: 0.8642 - val_loss: 0.4251 - val_accuracy: 0.8056\n","Epoch 688/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4041 - accuracy: 0.8395\n","Epoch 00688: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4041 - accuracy: 0.8395 - val_loss: 0.4249 - val_accuracy: 0.8056\n","Epoch 689/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3463 - accuracy: 0.8765\n","Epoch 00689: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3463 - accuracy: 0.8765 - val_loss: 0.4247 - val_accuracy: 0.8056\n","Epoch 690/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3848 - accuracy: 0.9012\n","Epoch 00690: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3848 - accuracy: 0.9012 - val_loss: 0.4244 - val_accuracy: 0.8056\n","Epoch 691/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3787 - accuracy: 0.9012\n","Epoch 00691: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3787 - accuracy: 0.9012 - val_loss: 0.4243 - val_accuracy: 0.8056\n","Epoch 692/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3946 - accuracy: 0.8765\n","Epoch 00692: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3946 - accuracy: 0.8765 - val_loss: 0.4241 - val_accuracy: 0.8056\n","Epoch 693/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3989 - accuracy: 0.8519\n","Epoch 00693: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 34ms/step - loss: 0.3989 - accuracy: 0.8519 - val_loss: 0.4239 - val_accuracy: 0.8056\n","Epoch 694/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3476 - accuracy: 0.8889\n","Epoch 00694: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3476 - accuracy: 0.8889 - val_loss: 0.4237 - val_accuracy: 0.8056\n","Epoch 695/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3776 - accuracy: 0.8519\n","Epoch 00695: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.3776 - accuracy: 0.8519 - val_loss: 0.4235 - val_accuracy: 0.8056\n","Epoch 696/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3721 - accuracy: 0.8642\n","Epoch 00696: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.3721 - accuracy: 0.8642 - val_loss: 0.4233 - val_accuracy: 0.8056\n","Epoch 697/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3804 - accuracy: 0.8519\n","Epoch 00697: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.3804 - accuracy: 0.8519 - val_loss: 0.4232 - val_accuracy: 0.8056\n","Epoch 698/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3888 - accuracy: 0.8642\n","Epoch 00698: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3888 - accuracy: 0.8642 - val_loss: 0.4230 - val_accuracy: 0.8056\n","Epoch 699/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.8765\n","Epoch 00699: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.3816 - accuracy: 0.8765 - val_loss: 0.4228 - val_accuracy: 0.8056\n","Epoch 700/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3958 - accuracy: 0.8642\n","Epoch 00700: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3958 - accuracy: 0.8642 - val_loss: 0.4226 - val_accuracy: 0.8056\n","Epoch 701/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3457 - accuracy: 0.8889\n","Epoch 00701: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3457 - accuracy: 0.8889 - val_loss: 0.4224 - val_accuracy: 0.8056\n","Epoch 702/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4187 - accuracy: 0.8642\n","Epoch 00702: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.4187 - accuracy: 0.8642 - val_loss: 0.4223 - val_accuracy: 0.8056\n","Epoch 703/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3742 - accuracy: 0.8889\n","Epoch 00703: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3742 - accuracy: 0.8889 - val_loss: 0.4221 - val_accuracy: 0.8056\n","Epoch 704/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3766 - accuracy: 0.8765\n","Epoch 00704: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3766 - accuracy: 0.8765 - val_loss: 0.4220 - val_accuracy: 0.8056\n","Epoch 705/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3795 - accuracy: 0.8519\n","Epoch 00705: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3795 - accuracy: 0.8519 - val_loss: 0.4219 - val_accuracy: 0.8056\n","Epoch 706/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3907 - accuracy: 0.8765\n","Epoch 00706: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3907 - accuracy: 0.8765 - val_loss: 0.4217 - val_accuracy: 0.8056\n","Epoch 707/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3801 - accuracy: 0.8765\n","Epoch 00707: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3801 - accuracy: 0.8765 - val_loss: 0.4216 - val_accuracy: 0.8056\n","Epoch 708/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3824 - accuracy: 0.8519\n","Epoch 00708: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3824 - accuracy: 0.8519 - val_loss: 0.4215 - val_accuracy: 0.8056\n","Epoch 709/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.8642\n","Epoch 00709: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3837 - accuracy: 0.8642 - val_loss: 0.4214 - val_accuracy: 0.8056\n","Epoch 710/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4159 - accuracy: 0.8395\n","Epoch 00710: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4159 - accuracy: 0.8395 - val_loss: 0.4212 - val_accuracy: 0.8056\n","Epoch 711/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3734 - accuracy: 0.8889\n","Epoch 00711: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3734 - accuracy: 0.8889 - val_loss: 0.4211 - val_accuracy: 0.8056\n","Epoch 712/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3821 - accuracy: 0.8642\n","Epoch 00712: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3821 - accuracy: 0.8642 - val_loss: 0.4210 - val_accuracy: 0.8056\n","Epoch 713/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3777 - accuracy: 0.8272\n","Epoch 00713: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3777 - accuracy: 0.8272 - val_loss: 0.4209 - val_accuracy: 0.8056\n","Epoch 714/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3866 - accuracy: 0.8765\n","Epoch 00714: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3866 - accuracy: 0.8765 - val_loss: 0.4208 - val_accuracy: 0.8056\n","Epoch 715/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3731 - accuracy: 0.8889\n","Epoch 00715: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3731 - accuracy: 0.8889 - val_loss: 0.4206 - val_accuracy: 0.8056\n","Epoch 716/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3723 - accuracy: 0.8765\n","Epoch 00716: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3723 - accuracy: 0.8765 - val_loss: 0.4205 - val_accuracy: 0.8056\n","Epoch 717/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3563 - accuracy: 0.8765\n","Epoch 00717: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 36ms/step - loss: 0.3563 - accuracy: 0.8765 - val_loss: 0.4204 - val_accuracy: 0.8056\n","Epoch 718/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3603 - accuracy: 0.8642\n","Epoch 00718: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.3603 - accuracy: 0.8642 - val_loss: 0.4202 - val_accuracy: 0.8056\n","Epoch 719/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3593 - accuracy: 0.8765\n","Epoch 00719: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3593 - accuracy: 0.8765 - val_loss: 0.4201 - val_accuracy: 0.8056\n","Epoch 720/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3781 - accuracy: 0.8765\n","Epoch 00720: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3781 - accuracy: 0.8765 - val_loss: 0.4199 - val_accuracy: 0.8056\n","Epoch 721/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3565 - accuracy: 0.8889\n","Epoch 00721: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3565 - accuracy: 0.8889 - val_loss: 0.4198 - val_accuracy: 0.8056\n","Epoch 722/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3611 - accuracy: 0.8642\n","Epoch 00722: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3611 - accuracy: 0.8642 - val_loss: 0.4196 - val_accuracy: 0.8056\n","Epoch 723/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4037 - accuracy: 0.8642\n","Epoch 00723: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4037 - accuracy: 0.8642 - val_loss: 0.4195 - val_accuracy: 0.8056\n","Epoch 724/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3956 - accuracy: 0.8642\n","Epoch 00724: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3956 - accuracy: 0.8642 - val_loss: 0.4193 - val_accuracy: 0.8056\n","Epoch 725/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3563 - accuracy: 0.8889\n","Epoch 00725: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3563 - accuracy: 0.8889 - val_loss: 0.4192 - val_accuracy: 0.8056\n","Epoch 726/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3942 - accuracy: 0.8642\n","Epoch 00726: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 35ms/step - loss: 0.3942 - accuracy: 0.8642 - val_loss: 0.4190 - val_accuracy: 0.8056\n","Epoch 727/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3842 - accuracy: 0.8642\n","Epoch 00727: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3842 - accuracy: 0.8642 - val_loss: 0.4188 - val_accuracy: 0.8056\n","Epoch 728/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3801 - accuracy: 0.8889\n","Epoch 00728: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3801 - accuracy: 0.8889 - val_loss: 0.4187 - val_accuracy: 0.8056\n","Epoch 729/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3906 - accuracy: 0.8395\n","Epoch 00729: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3906 - accuracy: 0.8395 - val_loss: 0.4185 - val_accuracy: 0.8056\n","Epoch 730/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3550 - accuracy: 0.8765\n","Epoch 00730: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3550 - accuracy: 0.8765 - val_loss: 0.4183 - val_accuracy: 0.8056\n","Epoch 731/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3481 - accuracy: 0.8765\n","Epoch 00731: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3481 - accuracy: 0.8765 - val_loss: 0.4181 - val_accuracy: 0.8056\n","Epoch 732/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3813 - accuracy: 0.8642\n","Epoch 00732: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3813 - accuracy: 0.8642 - val_loss: 0.4180 - val_accuracy: 0.8056\n","Epoch 733/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3679 - accuracy: 0.8642\n","Epoch 00733: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3679 - accuracy: 0.8642 - val_loss: 0.4178 - val_accuracy: 0.8056\n","Epoch 734/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3821 - accuracy: 0.8519\n","Epoch 00734: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3821 - accuracy: 0.8519 - val_loss: 0.4177 - val_accuracy: 0.8056\n","Epoch 735/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3760 - accuracy: 0.9012\n","Epoch 00735: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 26ms/step - loss: 0.3760 - accuracy: 0.9012 - val_loss: 0.4175 - val_accuracy: 0.8056\n","Epoch 736/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3595 - accuracy: 0.8642\n","Epoch 00736: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 38ms/step - loss: 0.3595 - accuracy: 0.8642 - val_loss: 0.4174 - val_accuracy: 0.8056\n","Epoch 737/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3661 - accuracy: 0.8889\n","Epoch 00737: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3661 - accuracy: 0.8889 - val_loss: 0.4172 - val_accuracy: 0.8056\n","Epoch 738/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3541 - accuracy: 0.8765\n","Epoch 00738: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3541 - accuracy: 0.8765 - val_loss: 0.4171 - val_accuracy: 0.8056\n","Epoch 739/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3825 - accuracy: 0.8765\n","Epoch 00739: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3825 - accuracy: 0.8765 - val_loss: 0.4169 - val_accuracy: 0.8056\n","Epoch 740/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4155 - accuracy: 0.8395\n","Epoch 00740: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.4155 - accuracy: 0.8395 - val_loss: 0.4167 - val_accuracy: 0.8056\n","Epoch 741/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3224 - accuracy: 0.9012\n","Epoch 00741: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3224 - accuracy: 0.9012 - val_loss: 0.4165 - val_accuracy: 0.8056\n","Epoch 742/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3731 - accuracy: 0.8642\n","Epoch 00742: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3731 - accuracy: 0.8642 - val_loss: 0.4163 - val_accuracy: 0.8056\n","Epoch 743/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3437 - accuracy: 0.9136\n","Epoch 00743: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3437 - accuracy: 0.9136 - val_loss: 0.4161 - val_accuracy: 0.8056\n","Epoch 744/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3559 - accuracy: 0.8889\n","Epoch 00744: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3559 - accuracy: 0.8889 - val_loss: 0.4160 - val_accuracy: 0.8056\n","Epoch 745/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4278 - accuracy: 0.8148\n","Epoch 00745: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4278 - accuracy: 0.8148 - val_loss: 0.4158 - val_accuracy: 0.8056\n","Epoch 746/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3646 - accuracy: 0.8889\n","Epoch 00746: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 37ms/step - loss: 0.3646 - accuracy: 0.8889 - val_loss: 0.4157 - val_accuracy: 0.8056\n","Epoch 747/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.8642\n","Epoch 00747: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3853 - accuracy: 0.8642 - val_loss: 0.4155 - val_accuracy: 0.8056\n","Epoch 748/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3783 - accuracy: 0.8642\n","Epoch 00748: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3783 - accuracy: 0.8642 - val_loss: 0.4153 - val_accuracy: 0.8056\n","Epoch 749/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3894 - accuracy: 0.8765\n","Epoch 00749: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3894 - accuracy: 0.8765 - val_loss: 0.4152 - val_accuracy: 0.8056\n","Epoch 750/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3633 - accuracy: 0.8642\n","Epoch 00750: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3633 - accuracy: 0.8642 - val_loss: 0.4150 - val_accuracy: 0.8056\n","Epoch 751/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3620 - accuracy: 0.8519\n","Epoch 00751: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3620 - accuracy: 0.8519 - val_loss: 0.4149 - val_accuracy: 0.8056\n","Epoch 752/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4183 - accuracy: 0.8272\n","Epoch 00752: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4183 - accuracy: 0.8272 - val_loss: 0.4147 - val_accuracy: 0.8056\n","Epoch 753/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3663 - accuracy: 0.8765\n","Epoch 00753: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3663 - accuracy: 0.8765 - val_loss: 0.4146 - val_accuracy: 0.8056\n","Epoch 754/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3672 - accuracy: 0.8642\n","Epoch 00754: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3672 - accuracy: 0.8642 - val_loss: 0.4145 - val_accuracy: 0.8056\n","Epoch 755/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3940 - accuracy: 0.8765\n","Epoch 00755: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3940 - accuracy: 0.8765 - val_loss: 0.4143 - val_accuracy: 0.8056\n","Epoch 756/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3481 - accuracy: 0.8642\n","Epoch 00756: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.3481 - accuracy: 0.8642 - val_loss: 0.4142 - val_accuracy: 0.8056\n","Epoch 757/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3699 - accuracy: 0.8395\n","Epoch 00757: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3699 - accuracy: 0.8395 - val_loss: 0.4140 - val_accuracy: 0.8056\n","Epoch 758/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3934 - accuracy: 0.8519\n","Epoch 00758: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3934 - accuracy: 0.8519 - val_loss: 0.4137 - val_accuracy: 0.8056\n","Epoch 759/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3808 - accuracy: 0.8642\n","Epoch 00759: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3808 - accuracy: 0.8642 - val_loss: 0.4135 - val_accuracy: 0.8056\n","Epoch 760/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3761 - accuracy: 0.8519\n","Epoch 00760: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3761 - accuracy: 0.8519 - val_loss: 0.4133 - val_accuracy: 0.8056\n","Epoch 761/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3759 - accuracy: 0.8765\n","Epoch 00761: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3759 - accuracy: 0.8765 - val_loss: 0.4131 - val_accuracy: 0.8056\n","Epoch 762/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3732 - accuracy: 0.8765\n","Epoch 00762: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3732 - accuracy: 0.8765 - val_loss: 0.4130 - val_accuracy: 0.8056\n","Epoch 763/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3829 - accuracy: 0.8642\n","Epoch 00763: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3829 - accuracy: 0.8642 - val_loss: 0.4128 - val_accuracy: 0.8056\n","Epoch 764/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3406 - accuracy: 0.9012\n","Epoch 00764: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3406 - accuracy: 0.9012 - val_loss: 0.4126 - val_accuracy: 0.8056\n","Epoch 765/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3966 - accuracy: 0.8519\n","Epoch 00765: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.3966 - accuracy: 0.8519 - val_loss: 0.4125 - val_accuracy: 0.8056\n","Epoch 766/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3621 - accuracy: 0.9012\n","Epoch 00766: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3621 - accuracy: 0.9012 - val_loss: 0.4123 - val_accuracy: 0.8056\n","Epoch 767/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3755 - accuracy: 0.8519\n","Epoch 00767: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3755 - accuracy: 0.8519 - val_loss: 0.4121 - val_accuracy: 0.8056\n","Epoch 768/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3787 - accuracy: 0.8519\n","Epoch 00768: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 26ms/step - loss: 0.3787 - accuracy: 0.8519 - val_loss: 0.4119 - val_accuracy: 0.8056\n","Epoch 769/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3851 - accuracy: 0.8395\n","Epoch 00769: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3851 - accuracy: 0.8395 - val_loss: 0.4118 - val_accuracy: 0.8056\n","Epoch 770/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3335 - accuracy: 0.8642\n","Epoch 00770: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3335 - accuracy: 0.8642 - val_loss: 0.4116 - val_accuracy: 0.8056\n","Epoch 771/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3762 - accuracy: 0.8395\n","Epoch 00771: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 26ms/step - loss: 0.3762 - accuracy: 0.8395 - val_loss: 0.4114 - val_accuracy: 0.8056\n","Epoch 772/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3425 - accuracy: 0.8889\n","Epoch 00772: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3425 - accuracy: 0.8889 - val_loss: 0.4113 - val_accuracy: 0.8056\n","Epoch 773/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3698 - accuracy: 0.8642\n","Epoch 00773: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3698 - accuracy: 0.8642 - val_loss: 0.4111 - val_accuracy: 0.8056\n","Epoch 774/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3611 - accuracy: 0.8765\n","Epoch 00774: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 36ms/step - loss: 0.3611 - accuracy: 0.8765 - val_loss: 0.4109 - val_accuracy: 0.8056\n","Epoch 775/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3942 - accuracy: 0.8642\n","Epoch 00775: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.3942 - accuracy: 0.8642 - val_loss: 0.4107 - val_accuracy: 0.8056\n","Epoch 776/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3886 - accuracy: 0.8519\n","Epoch 00776: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3886 - accuracy: 0.8519 - val_loss: 0.4106 - val_accuracy: 0.8056\n","Epoch 777/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3645 - accuracy: 0.8765\n","Epoch 00777: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3645 - accuracy: 0.8765 - val_loss: 0.4104 - val_accuracy: 0.8056\n","Epoch 778/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3512 - accuracy: 0.8765\n","Epoch 00778: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3512 - accuracy: 0.8765 - val_loss: 0.4101 - val_accuracy: 0.8056\n","Epoch 779/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3744 - accuracy: 0.8395\n","Epoch 00779: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3744 - accuracy: 0.8395 - val_loss: 0.4099 - val_accuracy: 0.8056\n","Epoch 780/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3897 - accuracy: 0.8519\n","Epoch 00780: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3897 - accuracy: 0.8519 - val_loss: 0.4097 - val_accuracy: 0.8056\n","Epoch 781/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3502 - accuracy: 0.8889\n","Epoch 00781: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3502 - accuracy: 0.8889 - val_loss: 0.4095 - val_accuracy: 0.8056\n","Epoch 782/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3663 - accuracy: 0.8889\n","Epoch 00782: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3663 - accuracy: 0.8889 - val_loss: 0.4093 - val_accuracy: 0.8056\n","Epoch 783/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3934 - accuracy: 0.8395\n","Epoch 00783: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3934 - accuracy: 0.8395 - val_loss: 0.4090 - val_accuracy: 0.8056\n","Epoch 784/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3717 - accuracy: 0.8395\n","Epoch 00784: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 38ms/step - loss: 0.3717 - accuracy: 0.8395 - val_loss: 0.4088 - val_accuracy: 0.8056\n","Epoch 785/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3480 - accuracy: 0.8889\n","Epoch 00785: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3480 - accuracy: 0.8889 - val_loss: 0.4085 - val_accuracy: 0.8056\n","Epoch 786/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3434 - accuracy: 0.8889\n","Epoch 00786: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3434 - accuracy: 0.8889 - val_loss: 0.4083 - val_accuracy: 0.8056\n","Epoch 787/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3737 - accuracy: 0.8889\n","Epoch 00787: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.3737 - accuracy: 0.8889 - val_loss: 0.4081 - val_accuracy: 0.8056\n","Epoch 788/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3859 - accuracy: 0.8519\n","Epoch 00788: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3859 - accuracy: 0.8519 - val_loss: 0.4079 - val_accuracy: 0.8056\n","Epoch 789/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3534 - accuracy: 0.8889\n","Epoch 00789: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3534 - accuracy: 0.8889 - val_loss: 0.4076 - val_accuracy: 0.8056\n","Epoch 790/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3965 - accuracy: 0.8519\n","Epoch 00790: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3965 - accuracy: 0.8519 - val_loss: 0.4074 - val_accuracy: 0.8056\n","Epoch 791/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3474 - accuracy: 0.8889\n","Epoch 00791: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3474 - accuracy: 0.8889 - val_loss: 0.4072 - val_accuracy: 0.8056\n","Epoch 792/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4125 - accuracy: 0.8519\n","Epoch 00792: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.4125 - accuracy: 0.8519 - val_loss: 0.4071 - val_accuracy: 0.8056\n","Epoch 793/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3322 - accuracy: 0.8889\n","Epoch 00793: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 26ms/step - loss: 0.3322 - accuracy: 0.8889 - val_loss: 0.4069 - val_accuracy: 0.8056\n","Epoch 794/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3854 - accuracy: 0.8519\n","Epoch 00794: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 34ms/step - loss: 0.3854 - accuracy: 0.8519 - val_loss: 0.4067 - val_accuracy: 0.8056\n","Epoch 795/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3632 - accuracy: 0.8642\n","Epoch 00795: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3632 - accuracy: 0.8642 - val_loss: 0.4065 - val_accuracy: 0.8056\n","Epoch 796/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3787 - accuracy: 0.8889\n","Epoch 00796: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3787 - accuracy: 0.8889 - val_loss: 0.4064 - val_accuracy: 0.8056\n","Epoch 797/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3645 - accuracy: 0.8642\n","Epoch 00797: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3645 - accuracy: 0.8642 - val_loss: 0.4062 - val_accuracy: 0.8056\n","Epoch 798/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3451 - accuracy: 0.8889\n","Epoch 00798: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3451 - accuracy: 0.8889 - val_loss: 0.4061 - val_accuracy: 0.8056\n","Epoch 799/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3268 - accuracy: 0.9012\n","Epoch 00799: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.3268 - accuracy: 0.9012 - val_loss: 0.4060 - val_accuracy: 0.8056\n","Epoch 800/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3994 - accuracy: 0.8519\n","Epoch 00800: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3994 - accuracy: 0.8519 - val_loss: 0.4058 - val_accuracy: 0.8056\n","Epoch 801/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3458 - accuracy: 0.8765\n","Epoch 00801: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3458 - accuracy: 0.8765 - val_loss: 0.4057 - val_accuracy: 0.8056\n","Epoch 802/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3860 - accuracy: 0.8765\n","Epoch 00802: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3860 - accuracy: 0.8765 - val_loss: 0.4056 - val_accuracy: 0.8056\n","Epoch 803/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3417 - accuracy: 0.8765\n","Epoch 00803: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 39ms/step - loss: 0.3417 - accuracy: 0.8765 - val_loss: 0.4055 - val_accuracy: 0.8056\n","Epoch 804/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3682 - accuracy: 0.8642\n","Epoch 00804: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3682 - accuracy: 0.8642 - val_loss: 0.4054 - val_accuracy: 0.8056\n","Epoch 805/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3605 - accuracy: 0.8642\n","Epoch 00805: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3605 - accuracy: 0.8642 - val_loss: 0.4052 - val_accuracy: 0.8056\n","Epoch 806/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3527 - accuracy: 0.8765\n","Epoch 00806: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3527 - accuracy: 0.8765 - val_loss: 0.4051 - val_accuracy: 0.8056\n","Epoch 807/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3590 - accuracy: 0.8889\n","Epoch 00807: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3590 - accuracy: 0.8889 - val_loss: 0.4050 - val_accuracy: 0.8056\n","Epoch 808/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3723 - accuracy: 0.8519\n","Epoch 00808: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3723 - accuracy: 0.8519 - val_loss: 0.4048 - val_accuracy: 0.8056\n","Epoch 809/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3879 - accuracy: 0.8272\n","Epoch 00809: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 35ms/step - loss: 0.3879 - accuracy: 0.8272 - val_loss: 0.4047 - val_accuracy: 0.8056\n","Epoch 810/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3651 - accuracy: 0.8519\n","Epoch 00810: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3651 - accuracy: 0.8519 - val_loss: 0.4046 - val_accuracy: 0.8056\n","Epoch 811/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3481 - accuracy: 0.8765\n","Epoch 00811: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3481 - accuracy: 0.8765 - val_loss: 0.4044 - val_accuracy: 0.8056\n","Epoch 812/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3528 - accuracy: 0.8889\n","Epoch 00812: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3528 - accuracy: 0.8889 - val_loss: 0.4043 - val_accuracy: 0.8056\n","Epoch 813/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3729 - accuracy: 0.8519\n","Epoch 00813: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 34ms/step - loss: 0.3729 - accuracy: 0.8519 - val_loss: 0.4042 - val_accuracy: 0.8056\n","Epoch 814/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3528 - accuracy: 0.8889\n","Epoch 00814: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3528 - accuracy: 0.8889 - val_loss: 0.4040 - val_accuracy: 0.8056\n","Epoch 815/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3965 - accuracy: 0.8395\n","Epoch 00815: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 26ms/step - loss: 0.3965 - accuracy: 0.8395 - val_loss: 0.4039 - val_accuracy: 0.8056\n","Epoch 816/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3537 - accuracy: 0.8765\n","Epoch 00816: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3537 - accuracy: 0.8765 - val_loss: 0.4038 - val_accuracy: 0.8056\n","Epoch 817/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3369 - accuracy: 0.9012\n","Epoch 00817: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3369 - accuracy: 0.9012 - val_loss: 0.4036 - val_accuracy: 0.8056\n","Epoch 818/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3691 - accuracy: 0.8765\n","Epoch 00818: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3691 - accuracy: 0.8765 - val_loss: 0.4035 - val_accuracy: 0.8056\n","Epoch 819/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3739 - accuracy: 0.8765\n","Epoch 00819: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 26ms/step - loss: 0.3739 - accuracy: 0.8765 - val_loss: 0.4034 - val_accuracy: 0.8056\n","Epoch 820/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3613 - accuracy: 0.9012\n","Epoch 00820: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 26ms/step - loss: 0.3613 - accuracy: 0.9012 - val_loss: 0.4034 - val_accuracy: 0.8056\n","Epoch 821/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3255 - accuracy: 0.8889\n","Epoch 00821: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 26ms/step - loss: 0.3255 - accuracy: 0.8889 - val_loss: 0.4033 - val_accuracy: 0.8056\n","Epoch 822/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3933 - accuracy: 0.8395\n","Epoch 00822: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 26ms/step - loss: 0.3933 - accuracy: 0.8395 - val_loss: 0.4032 - val_accuracy: 0.8056\n","Epoch 823/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3911 - accuracy: 0.8642\n","Epoch 00823: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.3911 - accuracy: 0.8642 - val_loss: 0.4030 - val_accuracy: 0.8056\n","Epoch 824/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3532 - accuracy: 0.8642\n","Epoch 00824: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3532 - accuracy: 0.8642 - val_loss: 0.4029 - val_accuracy: 0.8056\n","Epoch 825/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3587 - accuracy: 0.8642\n","Epoch 00825: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3587 - accuracy: 0.8642 - val_loss: 0.4028 - val_accuracy: 0.8056\n","Epoch 826/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3563 - accuracy: 0.8642\n","Epoch 00826: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 34ms/step - loss: 0.3563 - accuracy: 0.8642 - val_loss: 0.4026 - val_accuracy: 0.8056\n","Epoch 827/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3894 - accuracy: 0.8519\n","Epoch 00827: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.3894 - accuracy: 0.8519 - val_loss: 0.4025 - val_accuracy: 0.8056\n","Epoch 828/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3942 - accuracy: 0.8642\n","Epoch 00828: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3942 - accuracy: 0.8642 - val_loss: 0.4024 - val_accuracy: 0.8056\n","Epoch 829/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3575 - accuracy: 0.8765\n","Epoch 00829: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.3575 - accuracy: 0.8765 - val_loss: 0.4022 - val_accuracy: 0.8056\n","Epoch 830/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3873 - accuracy: 0.8395\n","Epoch 00830: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.3873 - accuracy: 0.8395 - val_loss: 0.4020 - val_accuracy: 0.8056\n","Epoch 831/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3552 - accuracy: 0.8889\n","Epoch 00831: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3552 - accuracy: 0.8889 - val_loss: 0.4019 - val_accuracy: 0.8056\n","Epoch 832/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.4447 - accuracy: 0.8272\n","Epoch 00832: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 45ms/step - loss: 0.4447 - accuracy: 0.8272 - val_loss: 0.4018 - val_accuracy: 0.8056\n","Epoch 833/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3343 - accuracy: 0.9012\n","Epoch 00833: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3343 - accuracy: 0.9012 - val_loss: 0.4017 - val_accuracy: 0.8056\n","Epoch 834/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3335 - accuracy: 0.8642\n","Epoch 00834: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3335 - accuracy: 0.8642 - val_loss: 0.4015 - val_accuracy: 0.8056\n","Epoch 835/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3460 - accuracy: 0.8889\n","Epoch 00835: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3460 - accuracy: 0.8889 - val_loss: 0.4014 - val_accuracy: 0.8056\n","Epoch 836/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3714 - accuracy: 0.8519\n","Epoch 00836: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3714 - accuracy: 0.8519 - val_loss: 0.4013 - val_accuracy: 0.8056\n","Epoch 837/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3477 - accuracy: 0.8889\n","Epoch 00837: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.3477 - accuracy: 0.8889 - val_loss: 0.4012 - val_accuracy: 0.8056\n","Epoch 838/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3386 - accuracy: 0.8642\n","Epoch 00838: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.3386 - accuracy: 0.8642 - val_loss: 0.4011 - val_accuracy: 0.8056\n","Epoch 839/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3638 - accuracy: 0.8642\n","Epoch 00839: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3638 - accuracy: 0.8642 - val_loss: 0.4009 - val_accuracy: 0.8056\n","Epoch 840/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.8642\n","Epoch 00840: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3805 - accuracy: 0.8642 - val_loss: 0.4008 - val_accuracy: 0.8056\n","Epoch 841/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3459 - accuracy: 0.8765\n","Epoch 00841: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3459 - accuracy: 0.8765 - val_loss: 0.4006 - val_accuracy: 0.8056\n","Epoch 842/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3345 - accuracy: 0.8889\n","Epoch 00842: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 36ms/step - loss: 0.3345 - accuracy: 0.8889 - val_loss: 0.4005 - val_accuracy: 0.8056\n","Epoch 843/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3809 - accuracy: 0.8642\n","Epoch 00843: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3809 - accuracy: 0.8642 - val_loss: 0.4003 - val_accuracy: 0.8056\n","Epoch 844/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3745 - accuracy: 0.8519\n","Epoch 00844: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3745 - accuracy: 0.8519 - val_loss: 0.4002 - val_accuracy: 0.8056\n","Epoch 845/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3506 - accuracy: 0.8642\n","Epoch 00845: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 31ms/step - loss: 0.3506 - accuracy: 0.8642 - val_loss: 0.4000 - val_accuracy: 0.8056\n","Epoch 846/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.8519\n","Epoch 00846: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3816 - accuracy: 0.8519 - val_loss: 0.3998 - val_accuracy: 0.8056\n","Epoch 847/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3501 - accuracy: 0.8642\n","Epoch 00847: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3501 - accuracy: 0.8642 - val_loss: 0.3997 - val_accuracy: 0.8056\n","Epoch 848/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3883 - accuracy: 0.8765\n","Epoch 00848: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3883 - accuracy: 0.8765 - val_loss: 0.3995 - val_accuracy: 0.8056\n","Epoch 849/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3312 - accuracy: 0.8889\n","Epoch 00849: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3312 - accuracy: 0.8889 - val_loss: 0.3994 - val_accuracy: 0.8056\n","Epoch 850/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3569 - accuracy: 0.8765\n","Epoch 00850: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3569 - accuracy: 0.8765 - val_loss: 0.3992 - val_accuracy: 0.8056\n","Epoch 851/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3543 - accuracy: 0.8519\n","Epoch 00851: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 34ms/step - loss: 0.3543 - accuracy: 0.8519 - val_loss: 0.3991 - val_accuracy: 0.8056\n","Epoch 852/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3922 - accuracy: 0.8395\n","Epoch 00852: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3922 - accuracy: 0.8395 - val_loss: 0.3989 - val_accuracy: 0.8056\n","Epoch 853/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3533 - accuracy: 0.8642\n","Epoch 00853: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3533 - accuracy: 0.8642 - val_loss: 0.3987 - val_accuracy: 0.8056\n","Epoch 854/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3685 - accuracy: 0.8765\n","Epoch 00854: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3685 - accuracy: 0.8765 - val_loss: 0.3986 - val_accuracy: 0.8056\n","Epoch 855/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3615 - accuracy: 0.8519\n","Epoch 00855: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 26ms/step - loss: 0.3615 - accuracy: 0.8519 - val_loss: 0.3984 - val_accuracy: 0.8056\n","Epoch 856/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3794 - accuracy: 0.8519\n","Epoch 00856: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3794 - accuracy: 0.8519 - val_loss: 0.3983 - val_accuracy: 0.8056\n","Epoch 857/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3525 - accuracy: 0.8765\n","Epoch 00857: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3525 - accuracy: 0.8765 - val_loss: 0.3981 - val_accuracy: 0.8056\n","Epoch 858/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3400 - accuracy: 0.9012\n","Epoch 00858: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3400 - accuracy: 0.9012 - val_loss: 0.3979 - val_accuracy: 0.8056\n","Epoch 859/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3418 - accuracy: 0.8889\n","Epoch 00859: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3418 - accuracy: 0.8889 - val_loss: 0.3978 - val_accuracy: 0.8056\n","Epoch 860/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3479 - accuracy: 0.8889\n","Epoch 00860: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3479 - accuracy: 0.8889 - val_loss: 0.3976 - val_accuracy: 0.8056\n","Epoch 861/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3394 - accuracy: 0.9012\n","Epoch 00861: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.3394 - accuracy: 0.9012 - val_loss: 0.3975 - val_accuracy: 0.8056\n","Epoch 862/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3721 - accuracy: 0.8395\n","Epoch 00862: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3721 - accuracy: 0.8395 - val_loss: 0.3974 - val_accuracy: 0.8056\n","Epoch 863/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3741 - accuracy: 0.8889\n","Epoch 00863: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 26ms/step - loss: 0.3741 - accuracy: 0.8889 - val_loss: 0.3972 - val_accuracy: 0.8056\n","Epoch 864/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3762 - accuracy: 0.8642\n","Epoch 00864: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3762 - accuracy: 0.8642 - val_loss: 0.3971 - val_accuracy: 0.8056\n","Epoch 865/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3397 - accuracy: 0.9012\n","Epoch 00865: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3397 - accuracy: 0.9012 - val_loss: 0.3970 - val_accuracy: 0.8056\n","Epoch 866/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3730 - accuracy: 0.8519\n","Epoch 00866: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 34ms/step - loss: 0.3730 - accuracy: 0.8519 - val_loss: 0.3968 - val_accuracy: 0.8056\n","Epoch 867/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3372 - accuracy: 0.8889\n","Epoch 00867: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3372 - accuracy: 0.8889 - val_loss: 0.3967 - val_accuracy: 0.8056\n","Epoch 868/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3712 - accuracy: 0.8889\n","Epoch 00868: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3712 - accuracy: 0.8889 - val_loss: 0.3965 - val_accuracy: 0.8056\n","Epoch 869/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3310 - accuracy: 0.8765\n","Epoch 00869: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3310 - accuracy: 0.8765 - val_loss: 0.3964 - val_accuracy: 0.8056\n","Epoch 870/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3562 - accuracy: 0.8642\n","Epoch 00870: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3562 - accuracy: 0.8642 - val_loss: 0.3962 - val_accuracy: 0.8056\n","Epoch 871/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3624 - accuracy: 0.8765\n","Epoch 00871: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 36ms/step - loss: 0.3624 - accuracy: 0.8765 - val_loss: 0.3960 - val_accuracy: 0.8056\n","Epoch 872/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3429 - accuracy: 0.8642\n","Epoch 00872: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3429 - accuracy: 0.8642 - val_loss: 0.3958 - val_accuracy: 0.8056\n","Epoch 873/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3481 - accuracy: 0.8765\n","Epoch 00873: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3481 - accuracy: 0.8765 - val_loss: 0.3956 - val_accuracy: 0.8056\n","Epoch 874/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3472 - accuracy: 0.8889\n","Epoch 00874: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3472 - accuracy: 0.8889 - val_loss: 0.3954 - val_accuracy: 0.8056\n","Epoch 875/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3300 - accuracy: 0.8889\n","Epoch 00875: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3300 - accuracy: 0.8889 - val_loss: 0.3952 - val_accuracy: 0.8056\n","Epoch 876/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.8642\n","Epoch 00876: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3863 - accuracy: 0.8642 - val_loss: 0.3950 - val_accuracy: 0.8056\n","Epoch 877/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3625 - accuracy: 0.8642\n","Epoch 00877: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3625 - accuracy: 0.8642 - val_loss: 0.3948 - val_accuracy: 0.8056\n","Epoch 878/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3431 - accuracy: 0.8889\n","Epoch 00878: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 35ms/step - loss: 0.3431 - accuracy: 0.8889 - val_loss: 0.3946 - val_accuracy: 0.8056\n","Epoch 879/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3994 - accuracy: 0.8395\n","Epoch 00879: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 32ms/step - loss: 0.3994 - accuracy: 0.8395 - val_loss: 0.3944 - val_accuracy: 0.8056\n","Epoch 880/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3961 - accuracy: 0.8519\n","Epoch 00880: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 35ms/step - loss: 0.3961 - accuracy: 0.8519 - val_loss: 0.3943 - val_accuracy: 0.8056\n","Epoch 881/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3641 - accuracy: 0.8765\n","Epoch 00881: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3641 - accuracy: 0.8765 - val_loss: 0.3941 - val_accuracy: 0.8056\n","Epoch 882/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3565 - accuracy: 0.8642\n","Epoch 00882: val_accuracy did not improve from 0.80556\n","1/1 [==============================] - 0s 26ms/step - loss: 0.3565 - accuracy: 0.8642 - val_loss: 0.3940 - val_accuracy: 0.8056\n","Epoch 883/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3628 - accuracy: 0.8642\n","Epoch 00883: val_accuracy improved from 0.80556 to 0.83333, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/Demographic_ANN_Binary_883.h5\n","1/1 [==============================] - 0s 47ms/step - loss: 0.3628 - accuracy: 0.8642 - val_loss: 0.3938 - val_accuracy: 0.8333\n","Epoch 884/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3617 - accuracy: 0.8519\n","Epoch 00884: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3617 - accuracy: 0.8519 - val_loss: 0.3936 - val_accuracy: 0.8333\n","Epoch 885/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3510 - accuracy: 0.8765\n","Epoch 00885: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3510 - accuracy: 0.8765 - val_loss: 0.3934 - val_accuracy: 0.8333\n","Epoch 886/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3865 - accuracy: 0.8395\n","Epoch 00886: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3865 - accuracy: 0.8395 - val_loss: 0.3932 - val_accuracy: 0.8333\n","Epoch 887/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3639 - accuracy: 0.8642\n","Epoch 00887: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 35ms/step - loss: 0.3639 - accuracy: 0.8642 - val_loss: 0.3931 - val_accuracy: 0.8333\n","Epoch 888/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3482 - accuracy: 0.8642\n","Epoch 00888: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3482 - accuracy: 0.8642 - val_loss: 0.3929 - val_accuracy: 0.8333\n","Epoch 889/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3941 - accuracy: 0.8519\n","Epoch 00889: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3941 - accuracy: 0.8519 - val_loss: 0.3927 - val_accuracy: 0.8333\n","Epoch 890/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3437 - accuracy: 0.8765\n","Epoch 00890: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 32ms/step - loss: 0.3437 - accuracy: 0.8765 - val_loss: 0.3925 - val_accuracy: 0.8333\n","Epoch 891/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3490 - accuracy: 0.8519\n","Epoch 00891: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3490 - accuracy: 0.8519 - val_loss: 0.3924 - val_accuracy: 0.8333\n","Epoch 892/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3353 - accuracy: 0.8765\n","Epoch 00892: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3353 - accuracy: 0.8765 - val_loss: 0.3922 - val_accuracy: 0.8333\n","Epoch 893/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3579 - accuracy: 0.8765\n","Epoch 00893: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 31ms/step - loss: 0.3579 - accuracy: 0.8765 - val_loss: 0.3920 - val_accuracy: 0.8333\n","Epoch 894/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3373 - accuracy: 0.9012\n","Epoch 00894: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 35ms/step - loss: 0.3373 - accuracy: 0.9012 - val_loss: 0.3919 - val_accuracy: 0.8333\n","Epoch 895/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3420 - accuracy: 0.8765\n","Epoch 00895: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3420 - accuracy: 0.8765 - val_loss: 0.3918 - val_accuracy: 0.8333\n","Epoch 896/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3651 - accuracy: 0.8642\n","Epoch 00896: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3651 - accuracy: 0.8642 - val_loss: 0.3916 - val_accuracy: 0.8333\n","Epoch 897/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3878 - accuracy: 0.8519\n","Epoch 00897: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3878 - accuracy: 0.8519 - val_loss: 0.3915 - val_accuracy: 0.8333\n","Epoch 898/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3902 - accuracy: 0.8272\n","Epoch 00898: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3902 - accuracy: 0.8272 - val_loss: 0.3913 - val_accuracy: 0.8333\n","Epoch 899/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3163 - accuracy: 0.9136\n","Epoch 00899: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3163 - accuracy: 0.9136 - val_loss: 0.3912 - val_accuracy: 0.8333\n","Epoch 900/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3684 - accuracy: 0.8642\n","Epoch 00900: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3684 - accuracy: 0.8642 - val_loss: 0.3910 - val_accuracy: 0.8333\n","Epoch 901/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.8519\n","Epoch 00901: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3853 - accuracy: 0.8519 - val_loss: 0.3909 - val_accuracy: 0.8333\n","Epoch 902/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3537 - accuracy: 0.8889\n","Epoch 00902: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3537 - accuracy: 0.8889 - val_loss: 0.3908 - val_accuracy: 0.8333\n","Epoch 903/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3777 - accuracy: 0.8642\n","Epoch 00903: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3777 - accuracy: 0.8642 - val_loss: 0.3906 - val_accuracy: 0.8333\n","Epoch 904/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3328 - accuracy: 0.9012\n","Epoch 00904: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3328 - accuracy: 0.9012 - val_loss: 0.3905 - val_accuracy: 0.8333\n","Epoch 905/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3073 - accuracy: 0.9136\n","Epoch 00905: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3073 - accuracy: 0.9136 - val_loss: 0.3903 - val_accuracy: 0.8333\n","Epoch 906/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3378 - accuracy: 0.8889\n","Epoch 00906: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3378 - accuracy: 0.8889 - val_loss: 0.3902 - val_accuracy: 0.8333\n","Epoch 907/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3358 - accuracy: 0.9012\n","Epoch 00907: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3358 - accuracy: 0.9012 - val_loss: 0.3901 - val_accuracy: 0.8333\n","Epoch 908/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3761 - accuracy: 0.8519\n","Epoch 00908: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3761 - accuracy: 0.8519 - val_loss: 0.3899 - val_accuracy: 0.8333\n","Epoch 909/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3608 - accuracy: 0.8642\n","Epoch 00909: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 32ms/step - loss: 0.3608 - accuracy: 0.8642 - val_loss: 0.3898 - val_accuracy: 0.8333\n","Epoch 910/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.8519\n","Epoch 00910: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3853 - accuracy: 0.8519 - val_loss: 0.3897 - val_accuracy: 0.8333\n","Epoch 911/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3184 - accuracy: 0.9136\n","Epoch 00911: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3184 - accuracy: 0.9136 - val_loss: 0.3896 - val_accuracy: 0.8333\n","Epoch 912/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3578 - accuracy: 0.8519\n","Epoch 00912: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3578 - accuracy: 0.8519 - val_loss: 0.3895 - val_accuracy: 0.8333\n","Epoch 913/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3673 - accuracy: 0.8765\n","Epoch 00913: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3673 - accuracy: 0.8765 - val_loss: 0.3894 - val_accuracy: 0.8333\n","Epoch 914/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3363 - accuracy: 0.8765\n","Epoch 00914: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3363 - accuracy: 0.8765 - val_loss: 0.3893 - val_accuracy: 0.8333\n","Epoch 915/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3520 - accuracy: 0.8519\n","Epoch 00915: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3520 - accuracy: 0.8519 - val_loss: 0.3891 - val_accuracy: 0.8333\n","Epoch 916/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3358 - accuracy: 0.8765\n","Epoch 00916: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 34ms/step - loss: 0.3358 - accuracy: 0.8765 - val_loss: 0.3890 - val_accuracy: 0.8333\n","Epoch 917/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3433 - accuracy: 0.8765\n","Epoch 00917: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3433 - accuracy: 0.8765 - val_loss: 0.3889 - val_accuracy: 0.8333\n","Epoch 918/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3781 - accuracy: 0.8642\n","Epoch 00918: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3781 - accuracy: 0.8642 - val_loss: 0.3887 - val_accuracy: 0.8333\n","Epoch 919/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3607 - accuracy: 0.8642\n","Epoch 00919: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 36ms/step - loss: 0.3607 - accuracy: 0.8642 - val_loss: 0.3886 - val_accuracy: 0.8333\n","Epoch 920/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3496 - accuracy: 0.8642\n","Epoch 00920: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 31ms/step - loss: 0.3496 - accuracy: 0.8642 - val_loss: 0.3885 - val_accuracy: 0.8333\n","Epoch 921/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3644 - accuracy: 0.8642\n","Epoch 00921: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3644 - accuracy: 0.8642 - val_loss: 0.3883 - val_accuracy: 0.8333\n","Epoch 922/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3653 - accuracy: 0.8765\n","Epoch 00922: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3653 - accuracy: 0.8765 - val_loss: 0.3882 - val_accuracy: 0.8333\n","Epoch 923/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3366 - accuracy: 0.9012\n","Epoch 00923: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3366 - accuracy: 0.9012 - val_loss: 0.3881 - val_accuracy: 0.8333\n","Epoch 924/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3610 - accuracy: 0.8642\n","Epoch 00924: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3610 - accuracy: 0.8642 - val_loss: 0.3880 - val_accuracy: 0.8333\n","Epoch 925/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3273 - accuracy: 0.9136\n","Epoch 00925: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3273 - accuracy: 0.9136 - val_loss: 0.3879 - val_accuracy: 0.8333\n","Epoch 926/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3329 - accuracy: 0.8889\n","Epoch 00926: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3329 - accuracy: 0.8889 - val_loss: 0.3878 - val_accuracy: 0.8333\n","Epoch 927/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3317 - accuracy: 0.8765\n","Epoch 00927: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3317 - accuracy: 0.8765 - val_loss: 0.3877 - val_accuracy: 0.8333\n","Epoch 928/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3265 - accuracy: 0.8889\n","Epoch 00928: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3265 - accuracy: 0.8889 - val_loss: 0.3876 - val_accuracy: 0.8333\n","Epoch 929/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3576 - accuracy: 0.8765\n","Epoch 00929: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3576 - accuracy: 0.8765 - val_loss: 0.3874 - val_accuracy: 0.8333\n","Epoch 930/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3484 - accuracy: 0.8765\n","Epoch 00930: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3484 - accuracy: 0.8765 - val_loss: 0.3873 - val_accuracy: 0.8333\n","Epoch 931/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3408 - accuracy: 0.8889\n","Epoch 00931: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3408 - accuracy: 0.8889 - val_loss: 0.3873 - val_accuracy: 0.8333\n","Epoch 932/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3572 - accuracy: 0.8765\n","Epoch 00932: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3572 - accuracy: 0.8765 - val_loss: 0.3872 - val_accuracy: 0.8333\n","Epoch 933/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3234 - accuracy: 0.8889\n","Epoch 00933: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 36ms/step - loss: 0.3234 - accuracy: 0.8889 - val_loss: 0.3871 - val_accuracy: 0.8333\n","Epoch 934/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3586 - accuracy: 0.8889\n","Epoch 00934: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3586 - accuracy: 0.8889 - val_loss: 0.3871 - val_accuracy: 0.8333\n","Epoch 935/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3329 - accuracy: 0.8889\n","Epoch 00935: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3329 - accuracy: 0.8889 - val_loss: 0.3870 - val_accuracy: 0.8333\n","Epoch 936/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3299 - accuracy: 0.8765\n","Epoch 00936: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3299 - accuracy: 0.8765 - val_loss: 0.3870 - val_accuracy: 0.8333\n","Epoch 937/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3324 - accuracy: 0.8642\n","Epoch 00937: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3324 - accuracy: 0.8642 - val_loss: 0.3869 - val_accuracy: 0.8333\n","Epoch 938/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3736 - accuracy: 0.8519\n","Epoch 00938: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 36ms/step - loss: 0.3736 - accuracy: 0.8519 - val_loss: 0.3868 - val_accuracy: 0.8333\n","Epoch 939/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3688 - accuracy: 0.8519\n","Epoch 00939: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 35ms/step - loss: 0.3688 - accuracy: 0.8519 - val_loss: 0.3867 - val_accuracy: 0.8333\n","Epoch 940/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3369 - accuracy: 0.8642\n","Epoch 00940: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3369 - accuracy: 0.8642 - val_loss: 0.3866 - val_accuracy: 0.8333\n","Epoch 941/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3279 - accuracy: 0.8765\n","Epoch 00941: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3279 - accuracy: 0.8765 - val_loss: 0.3865 - val_accuracy: 0.8333\n","Epoch 942/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3771 - accuracy: 0.8765\n","Epoch 00942: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3771 - accuracy: 0.8765 - val_loss: 0.3864 - val_accuracy: 0.8333\n","Epoch 943/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3554 - accuracy: 0.8765\n","Epoch 00943: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3554 - accuracy: 0.8765 - val_loss: 0.3863 - val_accuracy: 0.8333\n","Epoch 944/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3466 - accuracy: 0.8889\n","Epoch 00944: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 32ms/step - loss: 0.3466 - accuracy: 0.8889 - val_loss: 0.3863 - val_accuracy: 0.8333\n","Epoch 945/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3760 - accuracy: 0.8519\n","Epoch 00945: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3760 - accuracy: 0.8519 - val_loss: 0.3862 - val_accuracy: 0.8333\n","Epoch 946/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3637 - accuracy: 0.8765\n","Epoch 00946: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3637 - accuracy: 0.8765 - val_loss: 0.3861 - val_accuracy: 0.8333\n","Epoch 947/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3711 - accuracy: 0.8395\n","Epoch 00947: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3711 - accuracy: 0.8395 - val_loss: 0.3859 - val_accuracy: 0.8333\n","Epoch 948/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3224 - accuracy: 0.9012\n","Epoch 00948: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 35ms/step - loss: 0.3224 - accuracy: 0.9012 - val_loss: 0.3858 - val_accuracy: 0.8333\n","Epoch 949/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3643 - accuracy: 0.8519\n","Epoch 00949: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3643 - accuracy: 0.8519 - val_loss: 0.3857 - val_accuracy: 0.8333\n","Epoch 950/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3341 - accuracy: 0.8642\n","Epoch 00950: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3341 - accuracy: 0.8642 - val_loss: 0.3855 - val_accuracy: 0.8333\n","Epoch 951/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3746 - accuracy: 0.8519\n","Epoch 00951: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3746 - accuracy: 0.8519 - val_loss: 0.3854 - val_accuracy: 0.8333\n","Epoch 952/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3760 - accuracy: 0.8272\n","Epoch 00952: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3760 - accuracy: 0.8272 - val_loss: 0.3853 - val_accuracy: 0.8333\n","Epoch 953/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3365 - accuracy: 0.8765\n","Epoch 00953: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3365 - accuracy: 0.8765 - val_loss: 0.3852 - val_accuracy: 0.8333\n","Epoch 954/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3544 - accuracy: 0.8765\n","Epoch 00954: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3544 - accuracy: 0.8765 - val_loss: 0.3851 - val_accuracy: 0.8333\n","Epoch 955/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3489 - accuracy: 0.8642\n","Epoch 00955: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3489 - accuracy: 0.8642 - val_loss: 0.3850 - val_accuracy: 0.8333\n","Epoch 956/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3505 - accuracy: 0.8889\n","Epoch 00956: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3505 - accuracy: 0.8889 - val_loss: 0.3850 - val_accuracy: 0.8333\n","Epoch 957/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3439 - accuracy: 0.8889\n","Epoch 00957: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 35ms/step - loss: 0.3439 - accuracy: 0.8889 - val_loss: 0.3849 - val_accuracy: 0.8333\n","Epoch 958/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3624 - accuracy: 0.8395\n","Epoch 00958: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3624 - accuracy: 0.8395 - val_loss: 0.3848 - val_accuracy: 0.8333\n","Epoch 959/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3705 - accuracy: 0.8395\n","Epoch 00959: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3705 - accuracy: 0.8395 - val_loss: 0.3847 - val_accuracy: 0.8333\n","Epoch 960/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3768 - accuracy: 0.8519\n","Epoch 00960: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 32ms/step - loss: 0.3768 - accuracy: 0.8519 - val_loss: 0.3846 - val_accuracy: 0.8333\n","Epoch 961/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3441 - accuracy: 0.8765\n","Epoch 00961: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3441 - accuracy: 0.8765 - val_loss: 0.3845 - val_accuracy: 0.8333\n","Epoch 962/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3204 - accuracy: 0.8889\n","Epoch 00962: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3204 - accuracy: 0.8889 - val_loss: 0.3844 - val_accuracy: 0.8333\n","Epoch 963/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3550 - accuracy: 0.8519\n","Epoch 00963: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3550 - accuracy: 0.8519 - val_loss: 0.3843 - val_accuracy: 0.8333\n","Epoch 964/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3581 - accuracy: 0.8642\n","Epoch 00964: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3581 - accuracy: 0.8642 - val_loss: 0.3842 - val_accuracy: 0.8333\n","Epoch 965/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3438 - accuracy: 0.8765\n","Epoch 00965: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3438 - accuracy: 0.8765 - val_loss: 0.3840 - val_accuracy: 0.8333\n","Epoch 966/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3474 - accuracy: 0.8889\n","Epoch 00966: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3474 - accuracy: 0.8889 - val_loss: 0.3839 - val_accuracy: 0.8333\n","Epoch 967/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3437 - accuracy: 0.8889\n","Epoch 00967: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3437 - accuracy: 0.8889 - val_loss: 0.3838 - val_accuracy: 0.8333\n","Epoch 968/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3380 - accuracy: 0.8519\n","Epoch 00968: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3380 - accuracy: 0.8519 - val_loss: 0.3838 - val_accuracy: 0.8333\n","Epoch 969/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3498 - accuracy: 0.8642\n","Epoch 00969: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3498 - accuracy: 0.8642 - val_loss: 0.3837 - val_accuracy: 0.8333\n","Epoch 970/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3616 - accuracy: 0.8519\n","Epoch 00970: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3616 - accuracy: 0.8519 - val_loss: 0.3836 - val_accuracy: 0.8333\n","Epoch 971/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3434 - accuracy: 0.8642\n","Epoch 00971: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 32ms/step - loss: 0.3434 - accuracy: 0.8642 - val_loss: 0.3836 - val_accuracy: 0.8333\n","Epoch 972/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3689 - accuracy: 0.8642\n","Epoch 00972: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3689 - accuracy: 0.8642 - val_loss: 0.3835 - val_accuracy: 0.8333\n","Epoch 973/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3594 - accuracy: 0.8765\n","Epoch 00973: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 31ms/step - loss: 0.3594 - accuracy: 0.8765 - val_loss: 0.3834 - val_accuracy: 0.8333\n","Epoch 974/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3089 - accuracy: 0.9136\n","Epoch 00974: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3089 - accuracy: 0.9136 - val_loss: 0.3834 - val_accuracy: 0.8333\n","Epoch 975/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3537 - accuracy: 0.8642\n","Epoch 00975: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3537 - accuracy: 0.8642 - val_loss: 0.3833 - val_accuracy: 0.8333\n","Epoch 976/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3254 - accuracy: 0.8889\n","Epoch 00976: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3254 - accuracy: 0.8889 - val_loss: 0.3832 - val_accuracy: 0.8333\n","Epoch 977/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3510 - accuracy: 0.8765\n","Epoch 00977: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 31ms/step - loss: 0.3510 - accuracy: 0.8765 - val_loss: 0.3832 - val_accuracy: 0.8333\n","Epoch 978/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3381 - accuracy: 0.8642\n","Epoch 00978: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3381 - accuracy: 0.8642 - val_loss: 0.3831 - val_accuracy: 0.8333\n","Epoch 979/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3392 - accuracy: 0.8889\n","Epoch 00979: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3392 - accuracy: 0.8889 - val_loss: 0.3830 - val_accuracy: 0.8333\n","Epoch 980/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3115 - accuracy: 0.8889\n","Epoch 00980: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 37ms/step - loss: 0.3115 - accuracy: 0.8889 - val_loss: 0.3830 - val_accuracy: 0.8333\n","Epoch 981/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3369 - accuracy: 0.8765\n","Epoch 00981: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 31ms/step - loss: 0.3369 - accuracy: 0.8765 - val_loss: 0.3829 - val_accuracy: 0.8333\n","Epoch 982/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3524 - accuracy: 0.8765\n","Epoch 00982: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3524 - accuracy: 0.8765 - val_loss: 0.3828 - val_accuracy: 0.8333\n","Epoch 983/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3530 - accuracy: 0.8765\n","Epoch 00983: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3530 - accuracy: 0.8765 - val_loss: 0.3828 - val_accuracy: 0.8333\n","Epoch 984/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3519 - accuracy: 0.8889\n","Epoch 00984: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3519 - accuracy: 0.8889 - val_loss: 0.3827 - val_accuracy: 0.8333\n","Epoch 985/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3064 - accuracy: 0.9012\n","Epoch 00985: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3064 - accuracy: 0.9012 - val_loss: 0.3827 - val_accuracy: 0.8333\n","Epoch 986/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3086 - accuracy: 0.9136\n","Epoch 00986: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 35ms/step - loss: 0.3086 - accuracy: 0.9136 - val_loss: 0.3826 - val_accuracy: 0.8333\n","Epoch 987/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3669 - accuracy: 0.8642\n","Epoch 00987: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3669 - accuracy: 0.8642 - val_loss: 0.3826 - val_accuracy: 0.8333\n","Epoch 988/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3699 - accuracy: 0.8642\n","Epoch 00988: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3699 - accuracy: 0.8642 - val_loss: 0.3825 - val_accuracy: 0.8333\n","Epoch 989/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3282 - accuracy: 0.8642\n","Epoch 00989: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3282 - accuracy: 0.8642 - val_loss: 0.3825 - val_accuracy: 0.8333\n","Epoch 990/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3184 - accuracy: 0.8889\n","Epoch 00990: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3184 - accuracy: 0.8889 - val_loss: 0.3824 - val_accuracy: 0.8333\n","Epoch 991/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3039 - accuracy: 0.9012\n","Epoch 00991: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 30ms/step - loss: 0.3039 - accuracy: 0.9012 - val_loss: 0.3823 - val_accuracy: 0.8333\n","Epoch 992/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3439 - accuracy: 0.8889\n","Epoch 00992: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3439 - accuracy: 0.8889 - val_loss: 0.3822 - val_accuracy: 0.8333\n","Epoch 993/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3923 - accuracy: 0.8395\n","Epoch 00993: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3923 - accuracy: 0.8395 - val_loss: 0.3821 - val_accuracy: 0.8333\n","Epoch 994/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3671 - accuracy: 0.8642\n","Epoch 00994: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 26ms/step - loss: 0.3671 - accuracy: 0.8642 - val_loss: 0.3820 - val_accuracy: 0.8333\n","Epoch 995/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3211 - accuracy: 0.8889\n","Epoch 00995: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3211 - accuracy: 0.8889 - val_loss: 0.3819 - val_accuracy: 0.8333\n","Epoch 996/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3340 - accuracy: 0.8889\n","Epoch 00996: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 32ms/step - loss: 0.3340 - accuracy: 0.8889 - val_loss: 0.3818 - val_accuracy: 0.8333\n","Epoch 997/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3156 - accuracy: 0.8889\n","Epoch 00997: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3156 - accuracy: 0.8889 - val_loss: 0.3818 - val_accuracy: 0.8333\n","Epoch 998/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3711 - accuracy: 0.8642\n","Epoch 00998: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 27ms/step - loss: 0.3711 - accuracy: 0.8642 - val_loss: 0.3817 - val_accuracy: 0.8333\n","Epoch 999/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3501 - accuracy: 0.8519\n","Epoch 00999: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 29ms/step - loss: 0.3501 - accuracy: 0.8519 - val_loss: 0.3817 - val_accuracy: 0.8333\n","Epoch 1000/1000\n","1/1 [==============================] - ETA: 0s - loss: 0.3265 - accuracy: 0.8889\n","Epoch 01000: val_accuracy did not improve from 0.83333\n","1/1 [==============================] - 0s 28ms/step - loss: 0.3265 - accuracy: 0.8889 - val_loss: 0.3816 - val_accuracy: 0.8333\n","Training completed in time:  0:00:39.474996\n","2/2 [==============================] - 0s 3ms/step - loss: 0.3800 - accuracy: 0.8333\n","Pre-training accuracy: 83.3333%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Hl83I_QNNzq9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":205},"outputId":"77d2183b-ae6d-40c9-99af-7472b08c82cf","executionInfo":{"status":"ok","timestamp":1588537768448,"user_tz":300,"elapsed":510,"user":{"displayName":"Shu-Hao Yeh","photoUrl":"","userId":"02698211427086926082"}}},"source":["model_predictions = model.predict(x_test) \n","model_labels = model_predictions\n","#print(model_predictions[5])\n","for i in range(model_predictions.shape[0]):\n","  if model_predictions[i][0] > 0.5:\n","    model_labels[i][0] = 1\n","    model_labels[i][1] = 0\n","  else:\n","    model_labels[i][0] = 0\n","    model_labels[i][1] = 1\n","\n","#print(model_labels[5])\n","# print classification report \n","print(classification_report(y_test, model_predictions))\n","print(accuracy_score(y_test,model_predictions))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.87      0.76      0.81        17\n","           1       0.81      0.89      0.85        19\n","\n","   micro avg       0.83      0.83      0.83        36\n","   macro avg       0.84      0.83      0.83        36\n","weighted avg       0.84      0.83      0.83        36\n"," samples avg       0.83      0.83      0.83        36\n","\n","0.8333333333333334\n"],"name":"stdout"}]}]}