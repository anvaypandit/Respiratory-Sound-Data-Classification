{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MFCC_CNN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPpDmAGgPEejj5waKwQ6uNx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"QxOzi4t0DLMQ","colab_type":"code","outputId":"ab453e0e-a85a-4dff-8f5a-3bca94df08e9","executionInfo":{"status":"ok","timestamp":1588535353122,"user_tz":300,"elapsed":3195,"user":{"displayName":"Shu-Hao Yeh","photoUrl":"","userId":"02698211427086926082"}},"colab":{"base_uri":"https://localhost:8080/","height":222}},"source":["# Set up the mount of the google drive.\n","!pip install librosa"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.12.0)\n","Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.14.1)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.22.2.post1)\n","Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.48.0)\n","Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.2)\n","Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.18.3)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.4.1)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.8)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (46.1.3)\n","Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.31.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h8NuNHszVVgu","colab_type":"code","outputId":"0bc8324b-f162-4117-8ffb-501c7f7562c0","executionInfo":{"status":"ok","timestamp":1588535374775,"user_tz":300,"elapsed":19453,"user":{"displayName":"Shu-Hao Yeh","photoUrl":"","userId":"02698211427086926082"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uQkJLutcM9vF","colab_type":"code","outputId":"4de60d9f-20f2-4b11-b1fa-64a4f6b99c6d","executionInfo":{"status":"ok","timestamp":1588535379860,"user_tz":300,"elapsed":2836,"user":{"displayName":"Shu-Hao Yeh","photoUrl":"","userId":"02698211427086926082"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import sklearn\n","import pandas as pd\n","import wave\n","import sys\n","import os\n","import librosa\n","import librosa.display\n","import xgboost as xgb\n","from  sklearn.preprocessing import StandardScaler,MinMaxScaler\n","from sklearn.cluster import KMeans\n","from sklearn.model_selection import GridSearchCV \n","from sklearn.metrics import accuracy_score, f1_score, classification_report\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","import sklearn.naive_bayes as nb\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import BaggingClassifier,GradientBoostingClassifier\n","from sklearn.neighbors import kd_tree\n","import seaborn as sn\n","from sklearn.metrics import confusion_matrix\n","from collections import Counter\n","from sklearn.datasets import make_classification\n","from imblearn.over_sampling import SMOTE\n","from sklearn.model_selection import train_test_split"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n","/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.kd_tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n","  warnings.warn(message, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n","  \"(https://pypi.org/project/six/).\", FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n","  warnings.warn(message, FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Vz7zWPByNAdQ","colab_type":"code","outputId":"9b37f57f-7927-4bc1-da8e-bfc5a961b955","executionInfo":{"status":"ok","timestamp":1588535383114,"user_tz":300,"elapsed":1609,"user":{"displayName":"Shu-Hao Yeh","photoUrl":"","userId":"02698211427086926082"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n","from keras.utils import to_categorical\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","\n","from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, accuracy_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from datetime import datetime"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"bZhNMoIB_amB","colab_type":"code","colab":{}},"source":["# Load wav data.\n","import pickle\n","filename = '/content/drive/My Drive/CSCE 666/Project/Feature/w_c_dataset.pickle'\n","infile = open(filename,'rb')\n","[sound, sr, lengths, times, wc_label] = pickle.load(infile)\n","infile.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mLBIQ07-WDQM","colab_type":"code","colab":{}},"source":["# Obtain wav file ID.\n","import glob\n","wav_list = [f.split('.wav')[0] for f in glob.glob(\"/content/drive/My Drive/CSCE 666/Project/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/*.wav\")]\n","wav_list.sort()\n","\n","wav_ids = []\n","wav_names = []\n","for wav_path in wav_list:\n","  ind = wav_path.rfind(\"/\")\n","  wav_name = wav_path[ind+1:]\n","  Id = int(wav_name[:wav_name.find(\"_\")])\n","  wav_ids.append(Id)\n","  wav_names.append(wav_name)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qpGtrPMofBRW","colab_type":"code","colab":{}},"source":["import pandas as pd\n","demographic = pd.read_csv('/content/drive/My Drive/CSCE 666/Project/Feature/wav_info_COPD_missdata_samplemean.csv', header=None)\n","demographic_data = demographic.values\n","wav_disease_labels = demographic_data[:, -1]\n","demographic_data = demographic_data[0:, 1:-1] # Remove the id column (the first column)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OXuIVovpBFFi","colab_type":"code","colab":{}},"source":["\"\"\"\n","# 8 disease classification\n","def updatelabel(labels): \n","    l=[]\n","    for label in labels:\n","      if label == 0:\n","        a = np.array([1, 0, 0, 0, 0, 0, 0, 0])\n","      elif label == 1:\n","        a = np.array([0, 1, 0, 0, 0, 0, 0, 0])\n","      elif label == 2:\n","        a = np.array([0, 0, 1, 0, 0, 0, 0, 0])\n","      elif label == 3:\n","        a = np.array([0, 0, 0, 1, 0, 0, 0, 0])  \n","      elif label == 4:\n","        a = np.array([0, 0, 0, 0, 1, 0, 0, 0])  \n","      elif label == 5:\n","        a = np.array([0, 0, 0, 0, 0, 1, 0, 0])\n","      elif label == 6:\n","        a = np.array([0, 0, 0, 0, 0, 0, 1, 0])\n","      else:\n","        a = np.array([0, 0, 0, 0, 0, 0, 0, 1])\n","      l.append(a)\n","    return l\n","  \"\"\"\n","# COPD vs. non-COPD\n","def updatelabel(labels):\n","    l=[]\n","    for label in labels:\n","      if label == 0:\n","        a = np.array([1, 0])\n","      if label == 1:\n","        a = np.array([0, 1]) \n","      l.append(a)\n","    return l"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-rwK3VcmBvoN","colab_type":"code","outputId":"29250443-bea8-4fca-fcdd-fde374a930b9","executionInfo":{"status":"ok","timestamp":1588535447560,"user_tz":300,"elapsed":279,"user":{"displayName":"Shu-Hao Yeh","photoUrl":"","userId":"02698211427086926082"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["new_wav_disease_labels = updatelabel(wav_disease_labels)\n","print(len(new_wav_disease_labels))\n","print(new_wav_disease_labels)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["920\n","[array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0])]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7XedYNI6u9zM","colab_type":"code","colab":{}},"source":["print(type(demographic_data))\n","print(demographic_data.shape)\n","print(demographic_data[0])\n","print(demographic_data[1])\n","print(demographic_data[2])\n","print(demographic_data[3])\n","print(demographic_data[4])\n","print(demographic_data[0].shape)\n","#print(demographic_data[0:, 1:])\n","print(len(sound))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FwwY8AEs1XLI","colab_type":"code","colab":{}},"source":["import librosa\n","def find_mfcc_max_length(sound, sr):\n","  num_sound = len(sound)\n","  max_length = 0\n","  for i in range(num_sound):\n","    mfccs = librosa.feature.mfcc(y=sound[i], sr=sr[i], n_mfcc=40)\n","    mfcc_length = mfccs.shape[1]\n","    if mfcc_length > max_length:\n","      max_length = mfcc_length\n","\n","  return max_length"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"voO0qWaj2mzl","colab_type":"code","outputId":"f67af89f-704b-45a0-9faf-00c0a320f04e","executionInfo":{"status":"ok","timestamp":1588045019081,"user_tz":300,"elapsed":82398,"user":{"displayName":"Shu-Hao Yeh","photoUrl":"","userId":"02698211427086926082"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["max_len = find_mfcc_max_length(sound, sr)\n","print(max_len)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["3704\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NcTyLkb8NG5V","colab_type":"code","colab":{}},"source":["# Define feature extraction function: MFCC + demographic info\n","import librosa\n","max_len = 3704\n","def extract_feature(X, sample_rate):\n","    mfccs = librosa.feature.mfcc(y=X, sr=sample_rate,n_mfcc=40)\n","    \n","    # Pad  mfcc till the end\n","    pad_width_mfcc = max_len - mfccs.shape[1]\n","    \n","    mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width_mfcc)), mode='constant')\n","    \n","    return mfccs\n","    # Make mfccs as a vector\n","    #feat = mfccs[0, :]\n","    #for i in range(39):\n","    #  feat = np.hstack((feat, mfccs[i+1, :]))\n","    #print(feat.shape)\n","    #return feat\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b6b872UAN5-V","colab_type":"code","colab":{}},"source":["# Extract features\n","featset = []\n","for i in range(len(sound)):\n","    a = extract_feature(sound[i], sr[i])\n","    featset.append(a)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3KmKjvkUgDKA","colab_type":"code","outputId":"25d20f1e-9096-406c-e69b-11a269c70ac6","executionInfo":{"status":"ok","timestamp":1588535534519,"user_tz":300,"elapsed":1610,"user":{"displayName":"Shu-Hao Yeh","photoUrl":"","userId":"02698211427086926082"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["featset = np.array(featset)\n","featset.shape"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(920, 40, 3704)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"i8XrvapECASo","colab_type":"code","colab":{}},"source":["# add channel dimension for CNN\n","featset = np.reshape(featset, (*featset.shape,1))\n","\n","new_wav_disease_labels=np.asarray(new_wav_disease_labels)\n","a=np.zeros(new_wav_disease_labels.shape[0])\n","for i in range(new_wav_disease_labels.shape[0]):\n","    for j in range(new_wav_disease_labels.shape[1]):\n","        if new_wav_disease_labels[i][j]==1:\n","            a[i]=j\n","\n","# One-hot encode labels\n","le = LabelEncoder()\n","i_labels = le.fit_transform(a)\n","oh_labels = to_categorical(i_labels) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jt8i5DocuYz3","colab_type":"code","outputId":"6c5e38f6-46cf-49fe-a2e4-7128b3437bb7","executionInfo":{"status":"ok","timestamp":1588535539991,"user_tz":300,"elapsed":252,"user":{"displayName":"Shu-Hao Yeh","photoUrl":"","userId":"02698211427086926082"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["featset.shape"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(920, 40, 3704, 1)"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"ryHHOyt3CZAA","colab_type":"code","colab":{}},"source":["# train test split\n","x_train, x_test, y_train, y_test = train_test_split(featset, oh_labels, stratify=new_wav_disease_labels, \n","                                                    test_size=0.2, random_state = 42)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T4wdw5lcCi-m","colab_type":"code","colab":{}},"source":["num_rows = 40\n","num_columns = 3704\n","num_channels = 1\n","\n","num_labels = 2 # COPD vs. non-COPD\n","filter_size = 2\n","\n","# Construct model \n","model = Sequential()\n","model.add(Conv2D(filters=16, kernel_size=filter_size,\n","                 input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n","model.add(MaxPooling2D(pool_size=2))\n","model.add(Dropout(0.2))\n","\n","model.add(Conv2D(filters=32, kernel_size=filter_size, activation='relu'))\n","model.add(MaxPooling2D(pool_size=2))\n","model.add(Dropout(0.2))\n","\n","model.add(Conv2D(filters=64, kernel_size=filter_size, activation='relu'))\n","model.add(MaxPooling2D(pool_size=2))\n","model.add(Dropout(0.2))\n","\n","model.add(Conv2D(filters=128, kernel_size=filter_size, activation='relu'))\n","model.add(MaxPooling2D(pool_size=2))\n","model.add(Dropout(0.2))\n","\n","model.add(GlobalAveragePooling2D())\n","\n","model.add(Dense(32, activation='relu')) \n","\n","model.add(Dense(num_labels, activation='softmax')) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4-nIYIiaCr8s","colab_type":"code","colab":{}},"source":["# Compile the model\n","model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s6G1XtuHCyUF","colab_type":"code","outputId":"b72c32af-29b4-4cda-cc0b-2790f76aad15","executionInfo":{"status":"ok","timestamp":1588535850355,"user_tz":300,"elapsed":289514,"user":{"displayName":"Shu-Hao Yeh","photoUrl":"","userId":"02698211427086926082"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Display model architecture summary \n","model.summary()\n","\n","# train model\n","num_epochs = 250\n","num_batch_size = 128\n","\n","\n","\n","callbacks = [\n","    ModelCheckpoint(\n","        filepath='/content/drive/My Drive/CSCE 666/Project/Eric\\'s Notebooks/saved_models/MFCC_CNN_Binary_{epoch:02d}.h5', \n","        # Path where to save the model\n","        # The two parameters below mean that we will overwrite\n","        # the current checkpoint if and only if\n","        # the `val_accuracy` score has improved.\n","        save_best_only=True,\n","        monitor='val_accuracy',\n","        verbose=1)\n","]\n","start = datetime.now()\n","\n","model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, verbose=1,\n","          validation_data=(x_test, y_test), callbacks=callbacks)\n","\n","\n","duration = datetime.now() - start\n","print(\"Training completed in time: \", duration)\n","\n","#model.fit(x_train, y_train,\n","#          batch_size=batch_size,\n","#          epochs=epochs,\n","#          verbose=1,\n","#          validation_data=(x_test, y_test),\n","#          callbacks=[history])\n","\n","# Calculate pre-training accuracy \n","score = model.evaluate(x_test, y_test, verbose=1)\n","accuracy = 100*score[1]\n","\n","print(\"Pre-training accuracy: %.4f%%\" % accuracy)\n"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 39, 3703, 16)      80        \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 19, 1851, 16)      0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 19, 1851, 16)      0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 18, 1850, 32)      2080      \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 9, 925, 32)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 9, 925, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 8, 924, 64)        8256      \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 4, 462, 64)        0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 4, 462, 64)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 3, 461, 128)       32896     \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 1, 230, 128)       0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 1, 230, 128)       0         \n","_________________________________________________________________\n","global_average_pooling2d (Gl (None, 128)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 32)                4128      \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 2)                 66        \n","=================================================================\n","Total params: 47,506\n","Trainable params: 47,506\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/250\n","6/6 [==============================] - ETA: 0s - loss: 0.6913 - accuracy: 0.7446\n","Epoch 00001: val_accuracy improved from -inf to 0.86413, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/MFCC_CNN_Binary_01.h5\n","6/6 [==============================] - 2s 323ms/step - loss: 0.6913 - accuracy: 0.7446 - val_loss: 0.4919 - val_accuracy: 0.8641\n","Epoch 2/250\n","6/6 [==============================] - ETA: 0s - loss: 0.4765 - accuracy: 0.8601\n","Epoch 00002: val_accuracy did not improve from 0.86413\n","6/6 [==============================] - 1s 167ms/step - loss: 0.4765 - accuracy: 0.8601 - val_loss: 0.5379 - val_accuracy: 0.8641\n","Epoch 3/250\n","6/6 [==============================] - ETA: 0s - loss: 0.4247 - accuracy: 0.8614\n","Epoch 00003: val_accuracy did not improve from 0.86413\n","6/6 [==============================] - 1s 161ms/step - loss: 0.4247 - accuracy: 0.8614 - val_loss: 0.4662 - val_accuracy: 0.8641\n","Epoch 4/250\n","6/6 [==============================] - ETA: 0s - loss: 0.4115 - accuracy: 0.8614\n","Epoch 00004: val_accuracy did not improve from 0.86413\n","6/6 [==============================] - 1s 161ms/step - loss: 0.4115 - accuracy: 0.8614 - val_loss: 0.4768 - val_accuracy: 0.8641\n","Epoch 5/250\n","6/6 [==============================] - ETA: 0s - loss: 0.3915 - accuracy: 0.8614\n","Epoch 00005: val_accuracy did not improve from 0.86413\n","6/6 [==============================] - 1s 160ms/step - loss: 0.3915 - accuracy: 0.8614 - val_loss: 0.4865 - val_accuracy: 0.8641\n","Epoch 6/250\n","6/6 [==============================] - ETA: 0s - loss: 0.3734 - accuracy: 0.8614\n","Epoch 00006: val_accuracy did not improve from 0.86413\n","6/6 [==============================] - 1s 160ms/step - loss: 0.3734 - accuracy: 0.8614 - val_loss: 0.4412 - val_accuracy: 0.8641\n","Epoch 7/250\n","6/6 [==============================] - ETA: 0s - loss: 0.3579 - accuracy: 0.8614\n","Epoch 00007: val_accuracy did not improve from 0.86413\n","6/6 [==============================] - 1s 165ms/step - loss: 0.3579 - accuracy: 0.8614 - val_loss: 0.4290 - val_accuracy: 0.8641\n","Epoch 8/250\n","6/6 [==============================] - ETA: 0s - loss: 0.3434 - accuracy: 0.8560\n","Epoch 00008: val_accuracy did not improve from 0.86413\n","6/6 [==============================] - 1s 167ms/step - loss: 0.3434 - accuracy: 0.8560 - val_loss: 0.3919 - val_accuracy: 0.8641\n","Epoch 9/250\n","6/6 [==============================] - ETA: 0s - loss: 0.3205 - accuracy: 0.8546\n","Epoch 00009: val_accuracy did not improve from 0.86413\n","6/6 [==============================] - 1s 164ms/step - loss: 0.3205 - accuracy: 0.8546 - val_loss: 0.3671 - val_accuracy: 0.8587\n","Epoch 10/250\n","6/6 [==============================] - ETA: 0s - loss: 0.3090 - accuracy: 0.8410\n","Epoch 00010: val_accuracy did not improve from 0.86413\n","6/6 [==============================] - 1s 163ms/step - loss: 0.3090 - accuracy: 0.8410 - val_loss: 0.3394 - val_accuracy: 0.8587\n","Epoch 11/250\n","6/6 [==============================] - ETA: 0s - loss: 0.2976 - accuracy: 0.8397\n","Epoch 00011: val_accuracy did not improve from 0.86413\n","6/6 [==============================] - 1s 168ms/step - loss: 0.2976 - accuracy: 0.8397 - val_loss: 0.3199 - val_accuracy: 0.8533\n","Epoch 12/250\n","6/6 [==============================] - ETA: 0s - loss: 0.2672 - accuracy: 0.8478\n","Epoch 00012: val_accuracy did not improve from 0.86413\n","6/6 [==============================] - 1s 162ms/step - loss: 0.2672 - accuracy: 0.8478 - val_loss: 0.3020 - val_accuracy: 0.8641\n","Epoch 13/250\n","6/6 [==============================] - ETA: 0s - loss: 0.2514 - accuracy: 0.8601\n","Epoch 00013: val_accuracy improved from 0.86413 to 0.88043, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/MFCC_CNN_Binary_13.h5\n","6/6 [==============================] - 1s 163ms/step - loss: 0.2514 - accuracy: 0.8601 - val_loss: 0.2780 - val_accuracy: 0.8804\n","Epoch 14/250\n","6/6 [==============================] - ETA: 0s - loss: 0.2281 - accuracy: 0.8832\n","Epoch 00014: val_accuracy did not improve from 0.88043\n","6/6 [==============================] - 1s 158ms/step - loss: 0.2281 - accuracy: 0.8832 - val_loss: 0.2683 - val_accuracy: 0.8696\n","Epoch 15/250\n","6/6 [==============================] - ETA: 0s - loss: 0.2235 - accuracy: 0.8764\n","Epoch 00015: val_accuracy did not improve from 0.88043\n","6/6 [==============================] - 1s 157ms/step - loss: 0.2235 - accuracy: 0.8764 - val_loss: 0.2691 - val_accuracy: 0.8750\n","Epoch 16/250\n","6/6 [==============================] - ETA: 0s - loss: 0.2121 - accuracy: 0.8832\n","Epoch 00016: val_accuracy did not improve from 0.88043\n","6/6 [==============================] - 1s 158ms/step - loss: 0.2121 - accuracy: 0.8832 - val_loss: 0.2630 - val_accuracy: 0.8750\n","Epoch 17/250\n","6/6 [==============================] - ETA: 0s - loss: 0.2072 - accuracy: 0.8832\n","Epoch 00017: val_accuracy did not improve from 0.88043\n","6/6 [==============================] - 1s 154ms/step - loss: 0.2072 - accuracy: 0.8832 - val_loss: 0.2468 - val_accuracy: 0.8750\n","Epoch 18/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1913 - accuracy: 0.8899\n","Epoch 00018: val_accuracy did not improve from 0.88043\n","6/6 [==============================] - 1s 155ms/step - loss: 0.1913 - accuracy: 0.8899 - val_loss: 0.2391 - val_accuracy: 0.8750\n","Epoch 19/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1989 - accuracy: 0.8995\n","Epoch 00019: val_accuracy did not improve from 0.88043\n","6/6 [==============================] - 1s 157ms/step - loss: 0.1989 - accuracy: 0.8995 - val_loss: 0.2394 - val_accuracy: 0.8696\n","Epoch 20/250\n","6/6 [==============================] - ETA: 0s - loss: 0.2134 - accuracy: 0.8940\n","Epoch 00020: val_accuracy improved from 0.88043 to 0.90217, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/MFCC_CNN_Binary_20.h5\n","6/6 [==============================] - 1s 169ms/step - loss: 0.2134 - accuracy: 0.8940 - val_loss: 0.2210 - val_accuracy: 0.9022\n","Epoch 21/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1979 - accuracy: 0.8832\n","Epoch 00021: val_accuracy did not improve from 0.90217\n","6/6 [==============================] - 1s 160ms/step - loss: 0.1979 - accuracy: 0.8832 - val_loss: 0.2268 - val_accuracy: 0.8750\n","Epoch 22/250\n","6/6 [==============================] - ETA: 0s - loss: 0.2043 - accuracy: 0.9062\n","Epoch 00022: val_accuracy did not improve from 0.90217\n","6/6 [==============================] - 1s 164ms/step - loss: 0.2043 - accuracy: 0.9062 - val_loss: 0.2321 - val_accuracy: 0.8859\n","Epoch 23/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1860 - accuracy: 0.9008\n","Epoch 00023: val_accuracy did not improve from 0.90217\n","6/6 [==============================] - 1s 159ms/step - loss: 0.1860 - accuracy: 0.9008 - val_loss: 0.2672 - val_accuracy: 0.8696\n","Epoch 24/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1940 - accuracy: 0.9130\n","Epoch 00024: val_accuracy did not improve from 0.90217\n","6/6 [==============================] - 1s 158ms/step - loss: 0.1940 - accuracy: 0.9130 - val_loss: 0.2217 - val_accuracy: 0.8859\n","Epoch 25/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1844 - accuracy: 0.9049\n","Epoch 00025: val_accuracy did not improve from 0.90217\n","6/6 [==============================] - 1s 160ms/step - loss: 0.1844 - accuracy: 0.9049 - val_loss: 0.2315 - val_accuracy: 0.8859\n","Epoch 26/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1842 - accuracy: 0.9144\n","Epoch 00026: val_accuracy did not improve from 0.90217\n","6/6 [==============================] - 1s 153ms/step - loss: 0.1842 - accuracy: 0.9144 - val_loss: 0.2481 - val_accuracy: 0.8750\n","Epoch 27/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1750 - accuracy: 0.9117\n","Epoch 00027: val_accuracy did not improve from 0.90217\n","6/6 [==============================] - 1s 159ms/step - loss: 0.1750 - accuracy: 0.9117 - val_loss: 0.2285 - val_accuracy: 0.8913\n","Epoch 28/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1662 - accuracy: 0.9253\n","Epoch 00028: val_accuracy did not improve from 0.90217\n","6/6 [==============================] - 1s 157ms/step - loss: 0.1662 - accuracy: 0.9253 - val_loss: 0.2140 - val_accuracy: 0.8913\n","Epoch 29/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1659 - accuracy: 0.9212\n","Epoch 00029: val_accuracy did not improve from 0.90217\n","6/6 [==============================] - 1s 155ms/step - loss: 0.1659 - accuracy: 0.9212 - val_loss: 0.2452 - val_accuracy: 0.8804\n","Epoch 30/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1718 - accuracy: 0.9185\n","Epoch 00030: val_accuracy did not improve from 0.90217\n","6/6 [==============================] - 1s 153ms/step - loss: 0.1718 - accuracy: 0.9185 - val_loss: 0.2455 - val_accuracy: 0.8913\n","Epoch 31/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1617 - accuracy: 0.9171\n","Epoch 00031: val_accuracy did not improve from 0.90217\n","6/6 [==============================] - 1s 156ms/step - loss: 0.1617 - accuracy: 0.9171 - val_loss: 0.2166 - val_accuracy: 0.8967\n","Epoch 32/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1527 - accuracy: 0.9307\n","Epoch 00032: val_accuracy did not improve from 0.90217\n","6/6 [==============================] - 1s 159ms/step - loss: 0.1527 - accuracy: 0.9307 - val_loss: 0.2213 - val_accuracy: 0.8967\n","Epoch 33/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1479 - accuracy: 0.9239\n","Epoch 00033: val_accuracy did not improve from 0.90217\n","6/6 [==============================] - 1s 161ms/step - loss: 0.1479 - accuracy: 0.9239 - val_loss: 0.2133 - val_accuracy: 0.9022\n","Epoch 34/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1446 - accuracy: 0.9348\n","Epoch 00034: val_accuracy did not improve from 0.90217\n","6/6 [==============================] - 1s 161ms/step - loss: 0.1446 - accuracy: 0.9348 - val_loss: 0.2295 - val_accuracy: 0.8913\n","Epoch 35/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1465 - accuracy: 0.9307\n","Epoch 00035: val_accuracy did not improve from 0.90217\n","6/6 [==============================] - 1s 156ms/step - loss: 0.1465 - accuracy: 0.9307 - val_loss: 0.2169 - val_accuracy: 0.9022\n","Epoch 36/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.9416\n","Epoch 00036: val_accuracy did not improve from 0.90217\n","6/6 [==============================] - 1s 155ms/step - loss: 0.1423 - accuracy: 0.9416 - val_loss: 0.2375 - val_accuracy: 0.8967\n","Epoch 37/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1484 - accuracy: 0.9348\n","Epoch 00037: val_accuracy improved from 0.90217 to 0.90761, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/MFCC_CNN_Binary_37.h5\n","6/6 [==============================] - 1s 168ms/step - loss: 0.1484 - accuracy: 0.9348 - val_loss: 0.2102 - val_accuracy: 0.9076\n","Epoch 38/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1424 - accuracy: 0.9307\n","Epoch 00038: val_accuracy improved from 0.90761 to 0.91304, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/MFCC_CNN_Binary_38.h5\n","6/6 [==============================] - 1s 164ms/step - loss: 0.1424 - accuracy: 0.9307 - val_loss: 0.1890 - val_accuracy: 0.9130\n","Epoch 39/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1500 - accuracy: 0.9416\n","Epoch 00039: val_accuracy did not improve from 0.91304\n","6/6 [==============================] - 1s 151ms/step - loss: 0.1500 - accuracy: 0.9416 - val_loss: 0.1887 - val_accuracy: 0.9022\n","Epoch 40/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1548 - accuracy: 0.9280\n","Epoch 00040: val_accuracy did not improve from 0.91304\n","6/6 [==============================] - 1s 156ms/step - loss: 0.1548 - accuracy: 0.9280 - val_loss: 0.2047 - val_accuracy: 0.9022\n","Epoch 41/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1296 - accuracy: 0.9389\n","Epoch 00041: val_accuracy did not improve from 0.91304\n","6/6 [==============================] - 1s 160ms/step - loss: 0.1296 - accuracy: 0.9389 - val_loss: 0.2081 - val_accuracy: 0.9130\n","Epoch 42/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1213 - accuracy: 0.9484\n","Epoch 00042: val_accuracy did not improve from 0.91304\n","6/6 [==============================] - 1s 159ms/step - loss: 0.1213 - accuracy: 0.9484 - val_loss: 0.2154 - val_accuracy: 0.9076\n","Epoch 43/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1282 - accuracy: 0.9361\n","Epoch 00043: val_accuracy did not improve from 0.91304\n","6/6 [==============================] - 1s 160ms/step - loss: 0.1282 - accuracy: 0.9361 - val_loss: 0.1986 - val_accuracy: 0.9076\n","Epoch 44/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1286 - accuracy: 0.9443\n","Epoch 00044: val_accuracy did not improve from 0.91304\n","6/6 [==============================] - 1s 158ms/step - loss: 0.1286 - accuracy: 0.9443 - val_loss: 0.2176 - val_accuracy: 0.9130\n","Epoch 45/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1214 - accuracy: 0.9429\n","Epoch 00045: val_accuracy did not improve from 0.91304\n","6/6 [==============================] - 1s 157ms/step - loss: 0.1214 - accuracy: 0.9429 - val_loss: 0.2317 - val_accuracy: 0.9022\n","Epoch 46/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 0.9470\n","Epoch 00046: val_accuracy did not improve from 0.91304\n","6/6 [==============================] - 1s 154ms/step - loss: 0.1181 - accuracy: 0.9470 - val_loss: 0.2157 - val_accuracy: 0.9130\n","Epoch 47/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1285 - accuracy: 0.9389\n","Epoch 00047: val_accuracy did not improve from 0.91304\n","6/6 [==============================] - 1s 156ms/step - loss: 0.1285 - accuracy: 0.9389 - val_loss: 0.2621 - val_accuracy: 0.8967\n","Epoch 48/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1217 - accuracy: 0.9524\n","Epoch 00048: val_accuracy did not improve from 0.91304\n","6/6 [==============================] - 1s 158ms/step - loss: 0.1217 - accuracy: 0.9524 - val_loss: 0.2526 - val_accuracy: 0.8967\n","Epoch 49/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1462 - accuracy: 0.9293\n","Epoch 00049: val_accuracy did not improve from 0.91304\n","6/6 [==============================] - 1s 165ms/step - loss: 0.1462 - accuracy: 0.9293 - val_loss: 0.2365 - val_accuracy: 0.9022\n","Epoch 50/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1209 - accuracy: 0.9375\n","Epoch 00050: val_accuracy improved from 0.91304 to 0.91848, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/MFCC_CNN_Binary_50.h5\n","6/6 [==============================] - 1s 177ms/step - loss: 0.1209 - accuracy: 0.9375 - val_loss: 0.2031 - val_accuracy: 0.9185\n","Epoch 51/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1074 - accuracy: 0.9579\n","Epoch 00051: val_accuracy did not improve from 0.91848\n","6/6 [==============================] - 1s 156ms/step - loss: 0.1074 - accuracy: 0.9579 - val_loss: 0.2539 - val_accuracy: 0.9022\n","Epoch 52/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1189 - accuracy: 0.9484\n","Epoch 00052: val_accuracy did not improve from 0.91848\n","6/6 [==============================] - 1s 157ms/step - loss: 0.1189 - accuracy: 0.9484 - val_loss: 0.2790 - val_accuracy: 0.9022\n","Epoch 53/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 0.9552\n","Epoch 00053: val_accuracy did not improve from 0.91848\n","6/6 [==============================] - 1s 154ms/step - loss: 0.1114 - accuracy: 0.9552 - val_loss: 0.2448 - val_accuracy: 0.9076\n","Epoch 54/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 0.9579\n","Epoch 00054: val_accuracy did not improve from 0.91848\n","6/6 [==============================] - 1s 160ms/step - loss: 0.0999 - accuracy: 0.9579 - val_loss: 0.2397 - val_accuracy: 0.9076\n","Epoch 55/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9484\n","Epoch 00055: val_accuracy did not improve from 0.91848\n","6/6 [==============================] - 1s 152ms/step - loss: 0.1060 - accuracy: 0.9484 - val_loss: 0.2331 - val_accuracy: 0.8967\n","Epoch 56/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1040 - accuracy: 0.9524\n","Epoch 00056: val_accuracy did not improve from 0.91848\n","6/6 [==============================] - 1s 160ms/step - loss: 0.1040 - accuracy: 0.9524 - val_loss: 0.2370 - val_accuracy: 0.9022\n","Epoch 57/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1044 - accuracy: 0.9524\n","Epoch 00057: val_accuracy did not improve from 0.91848\n","6/6 [==============================] - 1s 158ms/step - loss: 0.1044 - accuracy: 0.9524 - val_loss: 0.2485 - val_accuracy: 0.8967\n","Epoch 58/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.9565\n","Epoch 00058: val_accuracy did not improve from 0.91848\n","6/6 [==============================] - 1s 153ms/step - loss: 0.1003 - accuracy: 0.9565 - val_loss: 0.3283 - val_accuracy: 0.8967\n","Epoch 59/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1078 - accuracy: 0.9497\n","Epoch 00059: val_accuracy did not improve from 0.91848\n","6/6 [==============================] - 1s 158ms/step - loss: 0.1078 - accuracy: 0.9497 - val_loss: 0.2219 - val_accuracy: 0.9022\n","Epoch 60/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0988 - accuracy: 0.9524\n","Epoch 00060: val_accuracy did not improve from 0.91848\n","6/6 [==============================] - 1s 157ms/step - loss: 0.0988 - accuracy: 0.9524 - val_loss: 0.2684 - val_accuracy: 0.9022\n","Epoch 61/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1090 - accuracy: 0.9470\n","Epoch 00061: val_accuracy did not improve from 0.91848\n","6/6 [==============================] - 1s 155ms/step - loss: 0.1090 - accuracy: 0.9470 - val_loss: 0.2551 - val_accuracy: 0.8967\n","Epoch 62/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1103 - accuracy: 0.9416\n","Epoch 00062: val_accuracy did not improve from 0.91848\n","6/6 [==============================] - 1s 157ms/step - loss: 0.1103 - accuracy: 0.9416 - val_loss: 0.2464 - val_accuracy: 0.9022\n","Epoch 63/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0925 - accuracy: 0.9524\n","Epoch 00063: val_accuracy did not improve from 0.91848\n","6/6 [==============================] - 1s 155ms/step - loss: 0.0925 - accuracy: 0.9524 - val_loss: 0.2653 - val_accuracy: 0.8967\n","Epoch 64/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0957 - accuracy: 0.9552\n","Epoch 00064: val_accuracy did not improve from 0.91848\n","6/6 [==============================] - 1s 163ms/step - loss: 0.0957 - accuracy: 0.9552 - val_loss: 0.2645 - val_accuracy: 0.9022\n","Epoch 65/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0946 - accuracy: 0.9538\n","Epoch 00065: val_accuracy did not improve from 0.91848\n","6/6 [==============================] - 1s 157ms/step - loss: 0.0946 - accuracy: 0.9538 - val_loss: 0.2794 - val_accuracy: 0.8967\n","Epoch 66/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0981 - accuracy: 0.9579\n","Epoch 00066: val_accuracy did not improve from 0.91848\n","6/6 [==============================] - 1s 153ms/step - loss: 0.0981 - accuracy: 0.9579 - val_loss: 0.3003 - val_accuracy: 0.8967\n","Epoch 67/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0995 - accuracy: 0.9592\n","Epoch 00067: val_accuracy did not improve from 0.91848\n","6/6 [==============================] - 1s 161ms/step - loss: 0.0995 - accuracy: 0.9592 - val_loss: 0.3146 - val_accuracy: 0.8967\n","Epoch 68/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.9592\n","Epoch 00068: val_accuracy did not improve from 0.91848\n","6/6 [==============================] - 1s 162ms/step - loss: 0.0900 - accuracy: 0.9592 - val_loss: 0.2046 - val_accuracy: 0.9130\n","Epoch 69/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9592\n","Epoch 00069: val_accuracy did not improve from 0.91848\n","6/6 [==============================] - 1s 155ms/step - loss: 0.0919 - accuracy: 0.9592 - val_loss: 0.3015 - val_accuracy: 0.9022\n","Epoch 70/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1023 - accuracy: 0.9579\n","Epoch 00070: val_accuracy did not improve from 0.91848\n","6/6 [==============================] - 1s 161ms/step - loss: 0.1023 - accuracy: 0.9579 - val_loss: 0.3718 - val_accuracy: 0.8967\n","Epoch 71/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1130 - accuracy: 0.9565\n","Epoch 00071: val_accuracy did not improve from 0.91848\n","6/6 [==============================] - 1s 158ms/step - loss: 0.1130 - accuracy: 0.9565 - val_loss: 0.2873 - val_accuracy: 0.9022\n","Epoch 72/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1103 - accuracy: 0.9429\n","Epoch 00072: val_accuracy improved from 0.91848 to 0.92935, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/MFCC_CNN_Binary_72.h5\n","6/6 [==============================] - 1s 167ms/step - loss: 0.1103 - accuracy: 0.9429 - val_loss: 0.1978 - val_accuracy: 0.9293\n","Epoch 73/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1091 - accuracy: 0.9484\n","Epoch 00073: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 160ms/step - loss: 0.1091 - accuracy: 0.9484 - val_loss: 0.2771 - val_accuracy: 0.9022\n","Epoch 74/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9633\n","Epoch 00074: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 158ms/step - loss: 0.0836 - accuracy: 0.9633 - val_loss: 0.2732 - val_accuracy: 0.9022\n","Epoch 75/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 0.9660\n","Epoch 00075: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 154ms/step - loss: 0.0782 - accuracy: 0.9660 - val_loss: 0.2803 - val_accuracy: 0.8967\n","Epoch 76/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9660\n","Epoch 00076: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 155ms/step - loss: 0.0772 - accuracy: 0.9660 - val_loss: 0.2578 - val_accuracy: 0.8967\n","Epoch 77/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9647\n","Epoch 00077: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 165ms/step - loss: 0.0772 - accuracy: 0.9647 - val_loss: 0.2799 - val_accuracy: 0.8967\n","Epoch 78/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 0.9647\n","Epoch 00078: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 167ms/step - loss: 0.0756 - accuracy: 0.9647 - val_loss: 0.3098 - val_accuracy: 0.8967\n","Epoch 79/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9660\n","Epoch 00079: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 160ms/step - loss: 0.0769 - accuracy: 0.9660 - val_loss: 0.2625 - val_accuracy: 0.9022\n","Epoch 80/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0749 - accuracy: 0.9633\n","Epoch 00080: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 155ms/step - loss: 0.0749 - accuracy: 0.9633 - val_loss: 0.2916 - val_accuracy: 0.8967\n","Epoch 81/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0760 - accuracy: 0.9660\n","Epoch 00081: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 161ms/step - loss: 0.0760 - accuracy: 0.9660 - val_loss: 0.2889 - val_accuracy: 0.9022\n","Epoch 82/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9579\n","Epoch 00082: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 154ms/step - loss: 0.0780 - accuracy: 0.9579 - val_loss: 0.2647 - val_accuracy: 0.8967\n","Epoch 83/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0694 - accuracy: 0.9674\n","Epoch 00083: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 156ms/step - loss: 0.0694 - accuracy: 0.9674 - val_loss: 0.3545 - val_accuracy: 0.8967\n","Epoch 84/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.9660\n","Epoch 00084: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 161ms/step - loss: 0.0812 - accuracy: 0.9660 - val_loss: 0.3219 - val_accuracy: 0.8967\n","Epoch 85/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0710 - accuracy: 0.9647\n","Epoch 00085: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 157ms/step - loss: 0.0710 - accuracy: 0.9647 - val_loss: 0.2972 - val_accuracy: 0.8967\n","Epoch 86/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.9633\n","Epoch 00086: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 160ms/step - loss: 0.0812 - accuracy: 0.9633 - val_loss: 0.3886 - val_accuracy: 0.8967\n","Epoch 87/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.9633\n","Epoch 00087: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 158ms/step - loss: 0.0869 - accuracy: 0.9633 - val_loss: 0.3647 - val_accuracy: 0.8967\n","Epoch 88/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0852 - accuracy: 0.9606\n","Epoch 00088: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 158ms/step - loss: 0.0852 - accuracy: 0.9606 - val_loss: 0.2605 - val_accuracy: 0.9022\n","Epoch 89/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0800 - accuracy: 0.9565\n","Epoch 00089: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 159ms/step - loss: 0.0800 - accuracy: 0.9565 - val_loss: 0.2799 - val_accuracy: 0.9076\n","Epoch 90/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0829 - accuracy: 0.9565\n","Epoch 00090: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 157ms/step - loss: 0.0829 - accuracy: 0.9565 - val_loss: 0.2757 - val_accuracy: 0.9022\n","Epoch 91/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0762 - accuracy: 0.9633\n","Epoch 00091: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 156ms/step - loss: 0.0762 - accuracy: 0.9633 - val_loss: 0.3432 - val_accuracy: 0.8967\n","Epoch 92/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9633\n","Epoch 00092: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 160ms/step - loss: 0.0873 - accuracy: 0.9633 - val_loss: 0.2976 - val_accuracy: 0.8967\n","Epoch 93/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9579\n","Epoch 00093: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 159ms/step - loss: 0.0847 - accuracy: 0.9579 - val_loss: 0.2871 - val_accuracy: 0.9076\n","Epoch 94/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9674\n","Epoch 00094: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 155ms/step - loss: 0.0735 - accuracy: 0.9674 - val_loss: 0.2856 - val_accuracy: 0.8967\n","Epoch 95/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 0.9701\n","Epoch 00095: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 156ms/step - loss: 0.0654 - accuracy: 0.9701 - val_loss: 0.2980 - val_accuracy: 0.9022\n","Epoch 96/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.9688\n","Epoch 00096: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 176ms/step - loss: 0.0682 - accuracy: 0.9688 - val_loss: 0.3004 - val_accuracy: 0.9022\n","Epoch 97/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 0.9728\n","Epoch 00097: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 159ms/step - loss: 0.0647 - accuracy: 0.9728 - val_loss: 0.3080 - val_accuracy: 0.8967\n","Epoch 98/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9769\n","Epoch 00098: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 159ms/step - loss: 0.0568 - accuracy: 0.9769 - val_loss: 0.3221 - val_accuracy: 0.9022\n","Epoch 99/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.9742\n","Epoch 00099: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 158ms/step - loss: 0.0578 - accuracy: 0.9742 - val_loss: 0.3293 - val_accuracy: 0.8967\n","Epoch 100/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0685 - accuracy: 0.9715\n","Epoch 00100: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 156ms/step - loss: 0.0685 - accuracy: 0.9715 - val_loss: 0.3764 - val_accuracy: 0.8967\n","Epoch 101/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0736 - accuracy: 0.9647\n","Epoch 00101: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 157ms/step - loss: 0.0736 - accuracy: 0.9647 - val_loss: 0.4391 - val_accuracy: 0.9022\n","Epoch 102/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1096 - accuracy: 0.9470\n","Epoch 00102: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 162ms/step - loss: 0.1096 - accuracy: 0.9470 - val_loss: 0.4898 - val_accuracy: 0.8913\n","Epoch 103/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1085 - accuracy: 0.9552\n","Epoch 00103: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 157ms/step - loss: 0.1085 - accuracy: 0.9552 - val_loss: 0.2764 - val_accuracy: 0.8967\n","Epoch 104/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 0.9688\n","Epoch 00104: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 158ms/step - loss: 0.0708 - accuracy: 0.9688 - val_loss: 0.2693 - val_accuracy: 0.9076\n","Epoch 105/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0657 - accuracy: 0.9755\n","Epoch 00105: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 169ms/step - loss: 0.0657 - accuracy: 0.9755 - val_loss: 0.3362 - val_accuracy: 0.8967\n","Epoch 106/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 0.9701\n","Epoch 00106: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 176ms/step - loss: 0.0724 - accuracy: 0.9701 - val_loss: 0.2865 - val_accuracy: 0.8967\n","Epoch 107/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0697 - accuracy: 0.9647\n","Epoch 00107: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 159ms/step - loss: 0.0697 - accuracy: 0.9647 - val_loss: 0.2939 - val_accuracy: 0.8913\n","Epoch 108/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 0.9742\n","Epoch 00108: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 157ms/step - loss: 0.0585 - accuracy: 0.9742 - val_loss: 0.3480 - val_accuracy: 0.9022\n","Epoch 109/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 0.9715\n","Epoch 00109: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 155ms/step - loss: 0.0626 - accuracy: 0.9715 - val_loss: 0.3235 - val_accuracy: 0.8967\n","Epoch 110/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.9728\n","Epoch 00110: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 157ms/step - loss: 0.0546 - accuracy: 0.9728 - val_loss: 0.3592 - val_accuracy: 0.8967\n","Epoch 111/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0550 - accuracy: 0.9755\n","Epoch 00111: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 153ms/step - loss: 0.0550 - accuracy: 0.9755 - val_loss: 0.3749 - val_accuracy: 0.8967\n","Epoch 112/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0653 - accuracy: 0.9647\n","Epoch 00112: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 161ms/step - loss: 0.0653 - accuracy: 0.9647 - val_loss: 0.3080 - val_accuracy: 0.9022\n","Epoch 113/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0702 - accuracy: 0.9688\n","Epoch 00113: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 154ms/step - loss: 0.0702 - accuracy: 0.9688 - val_loss: 0.3294 - val_accuracy: 0.9130\n","Epoch 114/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.9660\n","Epoch 00114: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 155ms/step - loss: 0.0698 - accuracy: 0.9660 - val_loss: 0.3716 - val_accuracy: 0.8967\n","Epoch 115/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0681 - accuracy: 0.9674\n","Epoch 00115: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 154ms/step - loss: 0.0681 - accuracy: 0.9674 - val_loss: 0.3617 - val_accuracy: 0.8967\n","Epoch 116/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.9701\n","Epoch 00116: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 157ms/step - loss: 0.0687 - accuracy: 0.9701 - val_loss: 0.3224 - val_accuracy: 0.8967\n","Epoch 117/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.9769\n","Epoch 00117: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 159ms/step - loss: 0.0572 - accuracy: 0.9769 - val_loss: 0.3670 - val_accuracy: 0.8967\n","Epoch 118/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9755\n","Epoch 00118: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 155ms/step - loss: 0.0540 - accuracy: 0.9755 - val_loss: 0.3264 - val_accuracy: 0.8967\n","Epoch 119/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9742\n","Epoch 00119: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 153ms/step - loss: 0.0525 - accuracy: 0.9742 - val_loss: 0.3599 - val_accuracy: 0.9022\n","Epoch 120/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9755\n","Epoch 00120: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 157ms/step - loss: 0.0544 - accuracy: 0.9755 - val_loss: 0.3042 - val_accuracy: 0.9076\n","Epoch 121/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9715\n","Epoch 00121: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 155ms/step - loss: 0.0625 - accuracy: 0.9715 - val_loss: 0.3882 - val_accuracy: 0.8967\n","Epoch 122/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 0.9755\n","Epoch 00122: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 158ms/step - loss: 0.0541 - accuracy: 0.9755 - val_loss: 0.3675 - val_accuracy: 0.8967\n","Epoch 123/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9755\n","Epoch 00123: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 155ms/step - loss: 0.0554 - accuracy: 0.9755 - val_loss: 0.3976 - val_accuracy: 0.8967\n","Epoch 124/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.9755\n","Epoch 00124: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 167ms/step - loss: 0.0493 - accuracy: 0.9755 - val_loss: 0.3669 - val_accuracy: 0.9022\n","Epoch 125/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9742\n","Epoch 00125: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 172ms/step - loss: 0.0489 - accuracy: 0.9742 - val_loss: 0.4318 - val_accuracy: 0.8967\n","Epoch 126/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.9742\n","Epoch 00126: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 162ms/step - loss: 0.0538 - accuracy: 0.9742 - val_loss: 0.3512 - val_accuracy: 0.9022\n","Epoch 127/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 0.9823\n","Epoch 00127: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 156ms/step - loss: 0.0483 - accuracy: 0.9823 - val_loss: 0.3297 - val_accuracy: 0.8967\n","Epoch 128/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 0.9715\n","Epoch 00128: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 156ms/step - loss: 0.0521 - accuracy: 0.9715 - val_loss: 0.4318 - val_accuracy: 0.9022\n","Epoch 129/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 0.9742\n","Epoch 00129: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 154ms/step - loss: 0.0492 - accuracy: 0.9742 - val_loss: 0.3971 - val_accuracy: 0.9022\n","Epoch 130/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 0.9728\n","Epoch 00130: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 157ms/step - loss: 0.0527 - accuracy: 0.9728 - val_loss: 0.4144 - val_accuracy: 0.8967\n","Epoch 131/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9688\n","Epoch 00131: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 158ms/step - loss: 0.0658 - accuracy: 0.9688 - val_loss: 0.4442 - val_accuracy: 0.9022\n","Epoch 132/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0989 - accuracy: 0.9620\n","Epoch 00132: val_accuracy did not improve from 0.92935\n","6/6 [==============================] - 1s 154ms/step - loss: 0.0989 - accuracy: 0.9620 - val_loss: 0.3959 - val_accuracy: 0.8967\n","Epoch 133/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1167 - accuracy: 0.9402\n","Epoch 00133: val_accuracy improved from 0.92935 to 0.94565, saving model to /content/drive/My Drive/CSCE 666/Project/Eric's Notebooks/saved_models/MFCC_CNN_Binary_133.h5\n","6/6 [==============================] - 1s 165ms/step - loss: 0.1167 - accuracy: 0.9402 - val_loss: 0.2260 - val_accuracy: 0.9457\n","Epoch 134/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0943 - accuracy: 0.9524\n","Epoch 00134: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 158ms/step - loss: 0.0943 - accuracy: 0.9524 - val_loss: 0.3964 - val_accuracy: 0.9022\n","Epoch 135/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9647\n","Epoch 00135: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 155ms/step - loss: 0.0772 - accuracy: 0.9647 - val_loss: 0.4725 - val_accuracy: 0.8967\n","Epoch 136/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0717 - accuracy: 0.9633\n","Epoch 00136: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 159ms/step - loss: 0.0717 - accuracy: 0.9633 - val_loss: 0.2851 - val_accuracy: 0.9239\n","Epoch 137/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.9688\n","Epoch 00137: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 161ms/step - loss: 0.0605 - accuracy: 0.9688 - val_loss: 0.3799 - val_accuracy: 0.9130\n","Epoch 138/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.9755\n","Epoch 00138: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 157ms/step - loss: 0.0551 - accuracy: 0.9755 - val_loss: 0.3358 - val_accuracy: 0.9022\n","Epoch 139/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9823\n","Epoch 00139: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 157ms/step - loss: 0.0440 - accuracy: 0.9823 - val_loss: 0.3968 - val_accuracy: 0.9022\n","Epoch 140/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9837\n","Epoch 00140: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 160ms/step - loss: 0.0477 - accuracy: 0.9837 - val_loss: 0.3408 - val_accuracy: 0.9022\n","Epoch 141/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.9837\n","Epoch 00141: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 159ms/step - loss: 0.0422 - accuracy: 0.9837 - val_loss: 0.3882 - val_accuracy: 0.8859\n","Epoch 142/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.9769\n","Epoch 00142: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 161ms/step - loss: 0.0479 - accuracy: 0.9769 - val_loss: 0.3271 - val_accuracy: 0.9022\n","Epoch 143/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 0.9728\n","Epoch 00143: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 177ms/step - loss: 0.0521 - accuracy: 0.9728 - val_loss: 0.4032 - val_accuracy: 0.8967\n","Epoch 144/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0535 - accuracy: 0.9769\n","Epoch 00144: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 170ms/step - loss: 0.0535 - accuracy: 0.9769 - val_loss: 0.3520 - val_accuracy: 0.8967\n","Epoch 145/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.9755\n","Epoch 00145: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 156ms/step - loss: 0.0514 - accuracy: 0.9755 - val_loss: 0.3731 - val_accuracy: 0.9022\n","Epoch 146/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9728\n","Epoch 00146: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 161ms/step - loss: 0.0555 - accuracy: 0.9728 - val_loss: 0.3595 - val_accuracy: 0.8967\n","Epoch 147/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 0.9851\n","Epoch 00147: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 154ms/step - loss: 0.0492 - accuracy: 0.9851 - val_loss: 0.3398 - val_accuracy: 0.9022\n","Epoch 148/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9810\n","Epoch 00148: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 157ms/step - loss: 0.0421 - accuracy: 0.9810 - val_loss: 0.4229 - val_accuracy: 0.8967\n","Epoch 149/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9810\n","Epoch 00149: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 154ms/step - loss: 0.0451 - accuracy: 0.9810 - val_loss: 0.3705 - val_accuracy: 0.8967\n","Epoch 150/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.9769\n","Epoch 00150: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 160ms/step - loss: 0.0429 - accuracy: 0.9769 - val_loss: 0.3248 - val_accuracy: 0.9239\n","Epoch 151/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 0.9701\n","Epoch 00151: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 156ms/step - loss: 0.0647 - accuracy: 0.9701 - val_loss: 0.4229 - val_accuracy: 0.8967\n","Epoch 152/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9769\n","Epoch 00152: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 160ms/step - loss: 0.0511 - accuracy: 0.9769 - val_loss: 0.4227 - val_accuracy: 0.9022\n","Epoch 153/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.9796\n","Epoch 00153: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 157ms/step - loss: 0.0446 - accuracy: 0.9796 - val_loss: 0.3524 - val_accuracy: 0.9293\n","Epoch 154/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9823\n","Epoch 00154: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 159ms/step - loss: 0.0460 - accuracy: 0.9823 - val_loss: 0.4265 - val_accuracy: 0.9022\n","Epoch 155/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9851\n","Epoch 00155: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 161ms/step - loss: 0.0368 - accuracy: 0.9851 - val_loss: 0.3379 - val_accuracy: 0.9130\n","Epoch 156/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.9796\n","Epoch 00156: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 156ms/step - loss: 0.0429 - accuracy: 0.9796 - val_loss: 0.3752 - val_accuracy: 0.9022\n","Epoch 157/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9810\n","Epoch 00157: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 157ms/step - loss: 0.0401 - accuracy: 0.9810 - val_loss: 0.4179 - val_accuracy: 0.8967\n","Epoch 158/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.9864\n","Epoch 00158: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 159ms/step - loss: 0.0385 - accuracy: 0.9864 - val_loss: 0.4109 - val_accuracy: 0.8967\n","Epoch 159/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 0.9837\n","Epoch 00159: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 152ms/step - loss: 0.0390 - accuracy: 0.9837 - val_loss: 0.3719 - val_accuracy: 0.9022\n","Epoch 160/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9864\n","Epoch 00160: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 154ms/step - loss: 0.0350 - accuracy: 0.9864 - val_loss: 0.4404 - val_accuracy: 0.8967\n","Epoch 161/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9878\n","Epoch 00161: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 160ms/step - loss: 0.0346 - accuracy: 0.9878 - val_loss: 0.4363 - val_accuracy: 0.8967\n","Epoch 162/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9810\n","Epoch 00162: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 175ms/step - loss: 0.0349 - accuracy: 0.9810 - val_loss: 0.4749 - val_accuracy: 0.8967\n","Epoch 163/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.9851\n","Epoch 00163: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 159ms/step - loss: 0.0374 - accuracy: 0.9851 - val_loss: 0.4049 - val_accuracy: 0.9022\n","Epoch 164/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 0.9810\n","Epoch 00164: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 154ms/step - loss: 0.0393 - accuracy: 0.9810 - val_loss: 0.4064 - val_accuracy: 0.9022\n","Epoch 165/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9851\n","Epoch 00165: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 160ms/step - loss: 0.0365 - accuracy: 0.9851 - val_loss: 0.4626 - val_accuracy: 0.8967\n","Epoch 166/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9837\n","Epoch 00166: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 161ms/step - loss: 0.0380 - accuracy: 0.9837 - val_loss: 0.4471 - val_accuracy: 0.9022\n","Epoch 167/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.9769\n","Epoch 00167: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 156ms/step - loss: 0.0428 - accuracy: 0.9769 - val_loss: 0.4150 - val_accuracy: 0.9076\n","Epoch 168/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 0.9837\n","Epoch 00168: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 153ms/step - loss: 0.0395 - accuracy: 0.9837 - val_loss: 0.4689 - val_accuracy: 0.9022\n","Epoch 169/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9823\n","Epoch 00169: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 154ms/step - loss: 0.0421 - accuracy: 0.9823 - val_loss: 0.5654 - val_accuracy: 0.8967\n","Epoch 170/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 0.9823\n","Epoch 00170: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 159ms/step - loss: 0.0375 - accuracy: 0.9823 - val_loss: 0.5010 - val_accuracy: 0.8967\n","Epoch 171/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 0.9810\n","Epoch 00171: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 175ms/step - loss: 0.0402 - accuracy: 0.9810 - val_loss: 0.4522 - val_accuracy: 0.9076\n","Epoch 172/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0424 - accuracy: 0.9796\n","Epoch 00172: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 170ms/step - loss: 0.0424 - accuracy: 0.9796 - val_loss: 0.4341 - val_accuracy: 0.9022\n","Epoch 173/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.9796\n","Epoch 00173: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 156ms/step - loss: 0.0438 - accuracy: 0.9796 - val_loss: 0.5108 - val_accuracy: 0.8967\n","Epoch 174/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0441 - accuracy: 0.9796\n","Epoch 00174: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 156ms/step - loss: 0.0441 - accuracy: 0.9796 - val_loss: 0.4414 - val_accuracy: 0.9130\n","Epoch 175/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9823\n","Epoch 00175: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 156ms/step - loss: 0.0432 - accuracy: 0.9823 - val_loss: 0.5585 - val_accuracy: 0.9022\n","Epoch 176/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9823\n","Epoch 00176: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 153ms/step - loss: 0.0388 - accuracy: 0.9823 - val_loss: 0.4163 - val_accuracy: 0.9130\n","Epoch 177/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9837\n","Epoch 00177: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 160ms/step - loss: 0.0365 - accuracy: 0.9837 - val_loss: 0.4554 - val_accuracy: 0.8967\n","Epoch 178/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9823\n","Epoch 00178: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 158ms/step - loss: 0.0349 - accuracy: 0.9823 - val_loss: 0.4672 - val_accuracy: 0.8913\n","Epoch 179/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9932\n","Epoch 00179: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 153ms/step - loss: 0.0295 - accuracy: 0.9932 - val_loss: 0.4824 - val_accuracy: 0.9022\n","Epoch 180/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9837\n","Epoch 00180: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 158ms/step - loss: 0.0288 - accuracy: 0.9837 - val_loss: 0.5300 - val_accuracy: 0.9022\n","Epoch 181/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9796\n","Epoch 00181: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 158ms/step - loss: 0.0451 - accuracy: 0.9796 - val_loss: 0.4893 - val_accuracy: 0.9022\n","Epoch 182/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9878\n","Epoch 00182: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 153ms/step - loss: 0.0303 - accuracy: 0.9878 - val_loss: 0.4515 - val_accuracy: 0.9022\n","Epoch 183/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9823\n","Epoch 00183: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 158ms/step - loss: 0.0320 - accuracy: 0.9823 - val_loss: 0.5474 - val_accuracy: 0.8913\n","Epoch 184/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0384 - accuracy: 0.9755\n","Epoch 00184: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 155ms/step - loss: 0.0384 - accuracy: 0.9755 - val_loss: 0.4647 - val_accuracy: 0.8967\n","Epoch 185/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9810\n","Epoch 00185: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 159ms/step - loss: 0.0404 - accuracy: 0.9810 - val_loss: 0.5194 - val_accuracy: 0.9130\n","Epoch 186/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9796\n","Epoch 00186: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 153ms/step - loss: 0.0411 - accuracy: 0.9796 - val_loss: 0.4774 - val_accuracy: 0.9130\n","Epoch 187/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9878\n","Epoch 00187: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 154ms/step - loss: 0.0439 - accuracy: 0.9878 - val_loss: 0.5864 - val_accuracy: 0.9076\n","Epoch 188/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.9701\n","Epoch 00188: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 159ms/step - loss: 0.0609 - accuracy: 0.9701 - val_loss: 0.5697 - val_accuracy: 0.8913\n","Epoch 189/250\n","6/6 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.9565\n","Epoch 00189: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 159ms/step - loss: 0.1003 - accuracy: 0.9565 - val_loss: 0.4334 - val_accuracy: 0.8913\n","Epoch 190/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.9810\n","Epoch 00190: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 172ms/step - loss: 0.0453 - accuracy: 0.9810 - val_loss: 0.3087 - val_accuracy: 0.9239\n","Epoch 191/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0529 - accuracy: 0.9715\n","Epoch 00191: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 172ms/step - loss: 0.0529 - accuracy: 0.9715 - val_loss: 0.3925 - val_accuracy: 0.9076\n","Epoch 192/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0415 - accuracy: 0.9837\n","Epoch 00192: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 153ms/step - loss: 0.0415 - accuracy: 0.9837 - val_loss: 0.5055 - val_accuracy: 0.8967\n","Epoch 193/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9769\n","Epoch 00193: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 159ms/step - loss: 0.0471 - accuracy: 0.9769 - val_loss: 0.3948 - val_accuracy: 0.9239\n","Epoch 194/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.9837\n","Epoch 00194: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 160ms/step - loss: 0.0357 - accuracy: 0.9837 - val_loss: 0.4180 - val_accuracy: 0.9185\n","Epoch 195/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9810\n","Epoch 00195: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 159ms/step - loss: 0.0329 - accuracy: 0.9810 - val_loss: 0.4762 - val_accuracy: 0.9076\n","Epoch 196/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9837\n","Epoch 00196: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 159ms/step - loss: 0.0352 - accuracy: 0.9837 - val_loss: 0.4636 - val_accuracy: 0.9022\n","Epoch 197/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9878\n","Epoch 00197: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 156ms/step - loss: 0.0331 - accuracy: 0.9878 - val_loss: 0.4496 - val_accuracy: 0.9185\n","Epoch 198/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9837\n","Epoch 00198: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 156ms/step - loss: 0.0316 - accuracy: 0.9837 - val_loss: 0.4897 - val_accuracy: 0.8967\n","Epoch 199/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9783\n","Epoch 00199: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 160ms/step - loss: 0.0370 - accuracy: 0.9783 - val_loss: 0.4862 - val_accuracy: 0.9185\n","Epoch 200/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.9810\n","Epoch 00200: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 156ms/step - loss: 0.0446 - accuracy: 0.9810 - val_loss: 0.4367 - val_accuracy: 0.9130\n","Epoch 201/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9891\n","Epoch 00201: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 157ms/step - loss: 0.0326 - accuracy: 0.9891 - val_loss: 0.5449 - val_accuracy: 0.9076\n","Epoch 202/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9878\n","Epoch 00202: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 159ms/step - loss: 0.0340 - accuracy: 0.9878 - val_loss: 0.4694 - val_accuracy: 0.9293\n","Epoch 203/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9823\n","Epoch 00203: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 157ms/step - loss: 0.0332 - accuracy: 0.9823 - val_loss: 0.4999 - val_accuracy: 0.9022\n","Epoch 204/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9837\n","Epoch 00204: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 156ms/step - loss: 0.0284 - accuracy: 0.9837 - val_loss: 0.5339 - val_accuracy: 0.9022\n","Epoch 205/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9878\n","Epoch 00205: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 160ms/step - loss: 0.0292 - accuracy: 0.9878 - val_loss: 0.4675 - val_accuracy: 0.9076\n","Epoch 206/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9932\n","Epoch 00206: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 155ms/step - loss: 0.0227 - accuracy: 0.9932 - val_loss: 0.5110 - val_accuracy: 0.9022\n","Epoch 207/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9851\n","Epoch 00207: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 157ms/step - loss: 0.0310 - accuracy: 0.9851 - val_loss: 0.5568 - val_accuracy: 0.9076\n","Epoch 208/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9878\n","Epoch 00208: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 159ms/step - loss: 0.0276 - accuracy: 0.9878 - val_loss: 0.5244 - val_accuracy: 0.9130\n","Epoch 209/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.9918\n","Epoch 00209: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 168ms/step - loss: 0.0275 - accuracy: 0.9918 - val_loss: 0.5197 - val_accuracy: 0.9185\n","Epoch 210/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9864\n","Epoch 00210: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 176ms/step - loss: 0.0323 - accuracy: 0.9864 - val_loss: 0.5785 - val_accuracy: 0.9022\n","Epoch 211/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9864\n","Epoch 00211: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 154ms/step - loss: 0.0317 - accuracy: 0.9864 - val_loss: 0.5450 - val_accuracy: 0.9130\n","Epoch 212/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9837\n","Epoch 00212: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 154ms/step - loss: 0.0331 - accuracy: 0.9837 - val_loss: 0.4602 - val_accuracy: 0.9239\n","Epoch 213/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.9810\n","Epoch 00213: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 158ms/step - loss: 0.0416 - accuracy: 0.9810 - val_loss: 0.4683 - val_accuracy: 0.9239\n","Epoch 214/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.9796\n","Epoch 00214: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 158ms/step - loss: 0.0414 - accuracy: 0.9796 - val_loss: 0.6733 - val_accuracy: 0.8967\n","Epoch 215/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9783\n","Epoch 00215: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 157ms/step - loss: 0.0474 - accuracy: 0.9783 - val_loss: 0.5646 - val_accuracy: 0.9130\n","Epoch 216/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9878\n","Epoch 00216: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 152ms/step - loss: 0.0323 - accuracy: 0.9878 - val_loss: 0.4766 - val_accuracy: 0.9239\n","Epoch 217/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.9742\n","Epoch 00217: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 158ms/step - loss: 0.0604 - accuracy: 0.9742 - val_loss: 0.4532 - val_accuracy: 0.9185\n","Epoch 218/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.9769\n","Epoch 00218: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 158ms/step - loss: 0.0458 - accuracy: 0.9769 - val_loss: 0.5347 - val_accuracy: 0.9076\n","Epoch 219/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9823\n","Epoch 00219: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 154ms/step - loss: 0.0451 - accuracy: 0.9823 - val_loss: 0.5011 - val_accuracy: 0.9130\n","Epoch 220/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9837\n","Epoch 00220: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 153ms/step - loss: 0.0380 - accuracy: 0.9837 - val_loss: 0.4408 - val_accuracy: 0.9130\n","Epoch 221/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9905\n","Epoch 00221: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 156ms/step - loss: 0.0298 - accuracy: 0.9905 - val_loss: 0.4582 - val_accuracy: 0.9076\n","Epoch 222/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9878\n","Epoch 00222: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 158ms/step - loss: 0.0269 - accuracy: 0.9878 - val_loss: 0.4165 - val_accuracy: 0.9185\n","Epoch 223/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 0.9810\n","Epoch 00223: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 155ms/step - loss: 0.0283 - accuracy: 0.9810 - val_loss: 0.4807 - val_accuracy: 0.9076\n","Epoch 224/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9973\n","Epoch 00224: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 157ms/step - loss: 0.0235 - accuracy: 0.9973 - val_loss: 0.4693 - val_accuracy: 0.9130\n","Epoch 225/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9973\n","Epoch 00225: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 160ms/step - loss: 0.0191 - accuracy: 0.9973 - val_loss: 0.5166 - val_accuracy: 0.9130\n","Epoch 226/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9905\n","Epoch 00226: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 158ms/step - loss: 0.0264 - accuracy: 0.9905 - val_loss: 0.5029 - val_accuracy: 0.9185\n","Epoch 227/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9918\n","Epoch 00227: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 158ms/step - loss: 0.0226 - accuracy: 0.9918 - val_loss: 0.5277 - val_accuracy: 0.9130\n","Epoch 228/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9973\n","Epoch 00228: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 169ms/step - loss: 0.0165 - accuracy: 0.9973 - val_loss: 0.5156 - val_accuracy: 0.9130\n","Epoch 229/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9918\n","Epoch 00229: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 173ms/step - loss: 0.0215 - accuracy: 0.9918 - val_loss: 0.4684 - val_accuracy: 0.9185\n","Epoch 230/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9851\n","Epoch 00230: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 154ms/step - loss: 0.0316 - accuracy: 0.9851 - val_loss: 0.6585 - val_accuracy: 0.8913\n","Epoch 231/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9810\n","Epoch 00231: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 156ms/step - loss: 0.0334 - accuracy: 0.9810 - val_loss: 0.5350 - val_accuracy: 0.9185\n","Epoch 232/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9932\n","Epoch 00232: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 159ms/step - loss: 0.0209 - accuracy: 0.9932 - val_loss: 0.5785 - val_accuracy: 0.9076\n","Epoch 233/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0278 - accuracy: 0.9905\n","Epoch 00233: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 154ms/step - loss: 0.0278 - accuracy: 0.9905 - val_loss: 0.5186 - val_accuracy: 0.9130\n","Epoch 234/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9823\n","Epoch 00234: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 153ms/step - loss: 0.0298 - accuracy: 0.9823 - val_loss: 0.6153 - val_accuracy: 0.8967\n","Epoch 235/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.9918\n","Epoch 00235: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 161ms/step - loss: 0.0287 - accuracy: 0.9918 - val_loss: 0.4405 - val_accuracy: 0.9239\n","Epoch 236/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9796\n","Epoch 00236: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 161ms/step - loss: 0.0388 - accuracy: 0.9796 - val_loss: 0.4216 - val_accuracy: 0.9293\n","Epoch 237/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9837\n","Epoch 00237: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 158ms/step - loss: 0.0349 - accuracy: 0.9837 - val_loss: 0.7566 - val_accuracy: 0.8967\n","Epoch 238/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9715\n","Epoch 00238: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 157ms/step - loss: 0.0554 - accuracy: 0.9715 - val_loss: 0.4874 - val_accuracy: 0.9130\n","Epoch 239/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9755\n","Epoch 00239: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 161ms/step - loss: 0.0537 - accuracy: 0.9755 - val_loss: 0.4347 - val_accuracy: 0.9185\n","Epoch 240/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 0.9742\n","Epoch 00240: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 154ms/step - loss: 0.0594 - accuracy: 0.9742 - val_loss: 0.7303 - val_accuracy: 0.8967\n","Epoch 241/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 0.9701\n","Epoch 00241: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 159ms/step - loss: 0.0585 - accuracy: 0.9701 - val_loss: 0.4764 - val_accuracy: 0.9239\n","Epoch 242/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9769\n","Epoch 00242: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 161ms/step - loss: 0.0552 - accuracy: 0.9769 - val_loss: 0.5570 - val_accuracy: 0.9022\n","Epoch 243/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9769\n","Epoch 00243: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 157ms/step - loss: 0.0477 - accuracy: 0.9769 - val_loss: 0.5205 - val_accuracy: 0.8967\n","Epoch 244/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 0.9891\n","Epoch 00244: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 157ms/step - loss: 0.0393 - accuracy: 0.9891 - val_loss: 0.4746 - val_accuracy: 0.9076\n","Epoch 245/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9918\n","Epoch 00245: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 152ms/step - loss: 0.0277 - accuracy: 0.9918 - val_loss: 0.4761 - val_accuracy: 0.9130\n","Epoch 246/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9837\n","Epoch 00246: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 154ms/step - loss: 0.0333 - accuracy: 0.9837 - val_loss: 0.4801 - val_accuracy: 0.9185\n","Epoch 247/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9905\n","Epoch 00247: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 174ms/step - loss: 0.0257 - accuracy: 0.9905 - val_loss: 0.4694 - val_accuracy: 0.9239\n","Epoch 248/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9918\n","Epoch 00248: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 178ms/step - loss: 0.0249 - accuracy: 0.9918 - val_loss: 0.5095 - val_accuracy: 0.9130\n","Epoch 249/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9918\n","Epoch 00249: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 158ms/step - loss: 0.0211 - accuracy: 0.9918 - val_loss: 0.4719 - val_accuracy: 0.9239\n","Epoch 250/250\n","6/6 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.9905\n","Epoch 00250: val_accuracy did not improve from 0.94565\n","6/6 [==============================] - 1s 154ms/step - loss: 0.0231 - accuracy: 0.9905 - val_loss: 0.5301 - val_accuracy: 0.9130\n","Training completed in time:  0:04:48.950583\n","6/6 [==============================] - 0s 21ms/step - loss: 0.4350 - accuracy: 0.9130\n","Pre-training accuracy: 91.3043%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y6ERGhENFUWQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":205},"outputId":"6f2201d4-e212-45f3-e0c3-2a05cab06bcb","executionInfo":{"status":"ok","timestamp":1588535956424,"user_tz":300,"elapsed":517,"user":{"displayName":"Shu-Hao Yeh","photoUrl":"","userId":"02698211427086926082"}}},"source":["model_predictions = model.predict(x_test) \n","model_labels = model_predictions\n","#print(model_predictions[5])\n","for i in range(model_predictions.shape[0]):\n","  if model_predictions[i][0] > 0.5:\n","    model_labels[i][0] = 1\n","    model_labels[i][1] = 0\n","  else:\n","    model_labels[i][0] = 0\n","    model_labels[i][1] = 1\n","\n","#print(model_labels[5])\n","# print classification report \n","print(classification_report(y_test, model_predictions))\n","print(accuracy_score(y_test,model_predictions))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.80      0.48      0.60        25\n","           1       0.92      0.98      0.95       159\n","\n","   micro avg       0.91      0.91      0.91       184\n","   macro avg       0.86      0.73      0.78       184\n","weighted avg       0.91      0.91      0.90       184\n"," samples avg       0.91      0.91      0.91       184\n","\n","0.9130434782608695\n"],"name":"stdout"}]}]}