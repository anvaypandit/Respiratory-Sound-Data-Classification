{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Wavelet_SVM_XGB_ANN.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1dmUN16FXyVlPGh4Ejq-JGe0Gdq4Ql1Pr","authorship_tag":"ABX9TyO7xMnDKVUriL75iIUIp1nT"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"tMxSleMM_2A4","colab_type":"code","colab":{}},"source":["# wavelet transform\n","# Load per cycle data frame\n","# This only loaded to get the corresponding labels\n","import pickle\n","import pywt\n","import numpy as np\n","from skimage.transform import resize\n","\n","\n","folder = \"/content/drive/My Drive/respiratory-sound-database/\" \n","filename = folder + 'w_c_dataset.pickle'\n","infile = open(filename,'rb')\n","[sound,sr,lengths,times,labels] = pickle.load(infile)\n","infile.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GbGXjo1QAsO_","colab_type":"code","colab":{}},"source":["def split_sounds(sounds,times,labels):\n","    s=[]\n","    l=[]\n","    for i,sound in enumerate(sounds):\n","        for t,label in zip(times[i],labels[i]):\n","            s.append(sound[int(t[0]):int(t[1])])\n","            if label==0:\n","                a=np.array([1,0,0,0])\n","            if label==1:\n","                a=np.array([0,1,0,0])\n","            if label==2:\n","                a=np.array([0,0,1,0])    \n","            if label==3:\n","                a=np.array([0,0,0,1])\n","            l.append(a)\n","    return s,l"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RGu5_PGkA2cB","colab_type":"code","colab":{}},"source":["def wavelet_transform(d):\n","  scales = np.arange(1,41)\n","  wavelet = 'morl'\n","  coeffs, freqs = pywt.cwt(d, scales, wavelet = wavelet)\n","  rescale_coeffs = resize(coeffs, (40,40), mode = 'constant')\n","  mean_wavelet = np.mean(rescale_coeffs.T,axis=0)\n","  std_wavelet = np.std(rescale_coeffs.T,axis=0)\n","  vector = np.hstack((mean_wavelet,std_wavelet))\n","  return vector, rescale_coeffs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yfkIarX2A9HN","colab_type":"code","colab":{}},"source":["[data,label]=split_sounds(sound,times,labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o9az962vBDwv","colab_type":"code","colab":{}},"source":["wavelets = []; wavelet_matrices = []\n","for d in range(len(data)):\n","  print(d)\n","  v,m = wavelet_transform(data[d])\n","  wavelets.append(v)\n","  wavelet_matrices.append(m)\n","wavelets = np.concatenate(wavelets, axis=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jvQcdoNzFdcO","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import pickle\n","\n","data_dict = {}\n","pickle_out = open(\"/content/drive/My Drive/respiratory-sound-database/wavelet.pickle\",\"wb\")\n","d_dict = {}\n","d_dict['w'] = wavelets\n","d_dict['w_m'] = wavelet_matrices\n","pickle.dump(data_dict,pickle_out)\n","pickle_out.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kksbN4fjNSau","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import pickle\n","\n","pickle_in = open(\"/content/drive/My Drive/respiratory-sound-database/wavelet.pickle\",\"rb\")\n","data = pickle.load(pickle_in)\n","dfr = data['w']\n","df = pd.read_csv('/content/drive/My Drive/respiratory-sound-database/Respiratory_Data.csv')\n","pickle_in.close()\n","labels = dfr['Class'].to_numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ckklvW2QQWK","colab_type":"code","colab":{}},"source":["one=0; two=0;three=0;four=0;\n","for i in range(labels.shape[0]):\n","  if labels[i] == 0:\n","    one = one + 1\n","  elif labels[i] == 1:\n","    two = two + 1\n","  elif labels[i] == 2:\n","    three = three + 1\n","  else:\n","    four = four + 1\n","\n","le = LabelEncoder()\n","i_labels = le.fit_transform(labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FdVqTTgLQfmb","colab_type":"code","colab":{}},"source":["scaler=StandardScaler()\n","x_train,x_test,y_train,y_test = sklearn.model_selection.train_test_split(X,labels,test_size=0.3, random_state=42)\n","scaler.fit(x_train)\n","x_train=scaler.transform(x_train)\n","x_test=scaler.transform(x_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NmsNGudhQgMM","colab_type":"code","colab":{}},"source":["# Running SVM classifier\n","Cs = [2**(-2),2**(-1), 1,2**(1),2**(2),2**(3),2**(4),2**(5),2**(6),2**(7),2**(8),2**(9),2**(10)]\n","gamma = [2**(-7),2**(-6),2**(-5),2**(-4),2**(-3),2**(-2),2**(-1),2**(0),2**(1),2**(2),2**(3)]\n","\n","\n","param_grid = {'C': Cs,  \n","                'gamma': gamma, \n","                'kernel': ['rbf'],\n","                'decision_function_shape':['ovr'],\n","                'class_weight': ['balanced']}  \n","grid1 = GridSearchCV(SVC(), param_grid,cv=3,n_jobs=-1, verbose = 3) \n","\n","# fitting the model for grid search \n","grid1.fit(x_train, y_train)\n","\n","# print best parameter after tuning \n","print(grid1.best_params_) \n","# print how our model looks after hyper-parameter tuning \n","print(grid1.best_estimator_)\n","\n","grid_predictions = grid1.predict(x_test) \n","\n","# print classification report \n","print(classification_report(y_test, grid_predictions))\n","print(accuracy_score(y_test,grid_predictions))\n","\n","print(sklearn.metrics.confusion_matrix(y_test,grid_predictions))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z5Lqpwy6QgPC","colab_type":"code","colab":{}},"source":["# Running XgBoost\n","import xgboost as xgb\n","\n","print('Training XGB Classifier from new features:')\n","xgb_model = xgb.XGBClassifier(max_depth=3,num_class=2, n_estimators=15, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, objective='multi:softmax', eta=0.3, silent=0, subsample=0.8).fit(x_train, y_train)\n","\n","xgb_pred = xgb_model.predict(x_test)\n","print(accuracy_score(y_test,xgb_pred))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"coytWDvHQgR9","colab_type":"code","colab":{}},"source":["#Running ANN\n","# One hot the labels\n","le = LabelEncoder()\n","y_test = to_categorical(y_test)\n","y_train = to_categorical(y_train)\n","\n","\n","\n","# Custom model for classification\n","model = Sequential()\n","\n","model.add(Dense(24, activation='relu', input_shape=(24,),kernel_initializer='random_normal'))\n","\n","model.add(Dense(12, activation='relu'))\n","model.add(Dropout(0.2))\n","#model.add(Dense(300, activation='relu'))\n","\n","#model.add(Dense(150, activation='relu')) \n","#model.add(Dropout(0.2))\n","#model.add(Dense(75, activation='relu')) \n","#model.add(Dropout(0.2))\n","#model.add(Dense(64, activation='relu',kernel_initializer='random_normal')) \n","#model.add(Dropout(0.2))\n","\n","\n","#model.add(Dense(16, activation='relu') )\n","\n","model.add(Dense(2, activation='sigmoid')) \n","\n","# Compile the model\n","model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam') \n","\n","model.summary()\n","\n","\n","\n","# Load the trained model if required\n","#model_file = '/content/drive/My Drive/Respiratory_Sound_Database/Respiratory_Sound_Database/LogMel_MFCC_Chroma_CNN/Try6_Unlinked/model_40_230.h5'\n","#model.load_weights(model_file)\n","\n","# Calculate pre-training accuracy \n","score = model.evaluate(x_test, y_test, verbose=1)\n","accuracy = 100*score[1]\n","\n","print(\"Pre-training accuracy: %.4f%%\" % accuracy)"],"execution_count":0,"outputs":[]}]}